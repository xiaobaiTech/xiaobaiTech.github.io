{"meta":{"title":"小白debug","subtitle":"一起在知识的海洋里呛水","description":"有时骚话连篇，有时硬核图解","author":null,"url":"https://xiaobaidebug.top","root":"/"},"pages":[{"title":"分类","date":"2021-09-25T16:03:51.000Z","updated":"2022-04-19T12:18:17.488Z","comments":true,"path":"categories/index.html","permalink":"https://xiaobaidebug.top/categories/index.html","excerpt":"","text":""}],"posts":[{"title":"AI不会淘汰你，但会用AI的人会淘汰你","slug":"程序人生/AI不会淘汰你，但会用AI的人会淘汰你","date":"2023-03-29T14:57:55.000Z","updated":"2023-06-15T01:11:54.034Z","comments":true,"path":"2023/03/29/程序人生/AI不会淘汰你，但会用AI的人会淘汰你/","link":"","permalink":"https://xiaobaidebug.top/2023/03/29/%E7%A8%8B%E5%BA%8F%E4%BA%BA%E7%94%9F/AI%E4%B8%8D%E4%BC%9A%E6%B7%98%E6%B1%B0%E4%BD%A0%EF%BC%8C%E4%BD%86%E4%BC%9A%E7%94%A8AI%E7%9A%84%E4%BA%BA%E4%BC%9A%E6%B7%98%E6%B1%B0%E4%BD%A0/","excerpt":"","text":"如果你有一段代码写的又乱性能又差。现在你的老板让你重构它，你会怎么做。你可能需要仔细阅读代码，并且揣测代码的含义，然后开始改动，改动完成后可能还需要做各种逻辑微调。 运气不好的时候，半小时就过去了。这是以前的我会做的事情，而现在，我会直接把代码粘贴到chatGPT里，让它帮我重构下代码，我甚至都不需要告诉它怎么重构，它就能直接给出代码。然后我拿修改后的代码和源代码进行对比，就知道哪里需要被修改了。 整个过程不到5分钟。 这就是效率。 可能有些人会觉得不就快20分钟吗？没什么了不起的。 我举个简单的例子，你就明白了。 你为什么选择你现在这份工作，当个程序员，而不是在工厂里打螺丝。我猜大概率是因为程序员薪水更高。 也就是单位时间里赚💰的效率更高。 程序员工资10k，打螺丝3k，你干一个月，别人干三个月，你干10年，别人干30年。 都说互联网人到了35岁就得退休，但有没有想过，我们到了35岁就差不多赚了别人一辈子才能赚到的💰。 光看效率本身也许差距不大，但是乘上时间，差距就会变得巨大。这也是所谓的马太效应。 这让我想起了我大学的时候刚开始学编程，写水仙花数这道题的时候，盯着代码逻辑看半天，最后发现是英文逗号写成了中文逗号。 回过神来发现已经过去半小时了，类似的事情经常发生，有时候更离谱，一行代码调半天。 太浪费时间了。 我有那时间，还不如跟学姐多聊两句微信，说不定今天孩子都会打酱油了。 以前学习效率虽然低，但同时大环境就业竞争也没那么激烈。 而现在的编程小白，面临的是更少的就业机会和更卷的面试大环境。 如果还用以前的老方法去学习，那竞争力就显得稍微弱了些。 毕竟同时期你的竞争者在用chatGPT这种更高效的方式在学习。 如果你有chatGPT，就相当于有个私人编程家教。 做个leetcode题时，发现代码调不通，再也不需要将代码发给同学朋友，让他们帮你看下到底是哪里不对劲，只需要将它粘贴到chatgpt上，它就能告诉你代码错在哪？ 而且它也不是只能回答你一些简单的问题，对于一些复杂的问题，它甚至比google还好用，上次我在调用onnx模型的时候，遇到了下面这样的报错。 1[ONNXRuntimeError] : 1 : FAIL : CUDA failure 716: misaligned address ; GPU=0 ; cudaMemcpyAsync(dst_data, src_data, bytes, cudaMemcpyHostToDevice, static_cast&lt;cudaStream_t&gt;(stream.GetHandle())); 是不是一头雾水，我也是。 在google上搜了一遍就没看到什么有价值的信息。于是尝试问了一下chatGPT。 没想到竟然给出了一些非常有价值的信息，最后不仅解决了问题，还顺藤摸瓜发现了是因为 onnxruntime-gpu 这个库在1.14版本后引入了一些并发错误的bug。 快检查下你的代码库里有没有用到它 在比如我想写一段golang代码得到某个数组里的最大元素，很简单对不对？但我希望它能基于reflect包支持各种类型的数组或切片。不是写不出来，但就是要花点时间，用ctrl cv把所有类型考虑全都挺费时间的。 于是问了下newbing（基于3.5的chatGPT）. 结果它写出来了。看着没啥问题，我还让它顺便给我写个几个单测用例，结果也完全ok。 这感觉，怎么形容呢。 小时候你看多啦A梦的时候，是不是会很羡慕大雄，大雄遇到任何困难都可以找多啦A梦，我猜你肯定想象过身边有个多啦A梦的场景。而现在，chatGPT对我们而言，就像是大雄身边的多啦A梦，斗破苍穹里萧炎身边的药老，武动乾坤里林动身边的那只貂，遇到问题问问它，就算不能解决，也很可能可以给到一些灵光一闪的思路。 大家一定听说过各种AI取代人类工作的论调，然后再看到抖音上各种视频里chatGPT胡说八道后，就感觉这破玩意也没多了不起，不屑于去使用它。但是你要知道，GPT才刚到4.0版本，这才只是刚刚开始，就已经这么离谱了，我难以想象到了第九第十代的时候，它的能力能有多么逆天。 互联网人其实是对新事物最敏感的那帮人，但我身边依然有很多人都还没用过chatGPT，因为根本瞧不上。 有不少人的观点是这样的： “AI怎么能跟人比？” “小小AI，可笑可笑，人类的创造力，决策力是不可取代的，网上都是在贩卖焦虑。” “我堂堂p7，编程水平全方位吊打chatgpt，根本没必要用它” “人类的创造力和想象力是不可替代的，用ai还不如自己来” 。。。 但我不太认同，退一万步来说，大家为什么要去跟一个婴儿去比学识和经验？ 我相信大家都能看到这个婴儿的无限潜力。 蒸汽发动机刚出来的时候，大家也是跟现在一样的反应。瞧不上。 “我为什么要用蒸汽机车，我家的马车喂喂草就能跑。” 现在好多人都是这种赶着马车，嘲笑刚出现的蒸汽机的心态！ 我可以拒绝新事物，也可以抗拒chatGPT，但这根本无法阻挡它正在改变人类的生活。 虽然这话听起来有点离谱，但我们确实正在见证历史。 就像当年所有人都觉得实业才是yyds，互联网？太虚了，根本成不了气候。后来的事情大家都知道了，互联网将人类的生活方式进行了彻底的重构，现在的小孩根本没法想象以前没有网络的世界是怎么样的。 而且我最不认同的一句话就是，“人类的创造力和想象力是不可替代的”。 这个话，只针对极少数天才，放在我们这些普通人身上就多少有点胡闹了。 就我那点贫瘠的想象力，不过是我这几十年人生经历里训练得到的结果，而GPT拥有的可是全人类所有的历史文化，它看过所有我没看过的书，读过我所有读不懂的论文。 我们所谓的那点优势，不过就是那点所谓的经验和学识， 就我们这几十年空洞无聊的人生阅历，撑死也就看过几百本书，其中几十本都是爽文小说，是什么让你如此斗胆去跟这样的ai去做比较的。 而且它还只是一个非常早期的ai。 很多人积累了一生的经验和学识优势，就这样被抹平了。这样逆天的能力，如果你用得好，你就能超越大部分人。 注意，“用得好”这个词才是关键。 我相信不少人玩过ai画图。 为什么别人画出来的图就这么精致好看，而自己画出来的却连脸都是歪的。 同样的工具，在不同的人手上，却用出了不同的效果，这就是差距。 因此，我相信，AI不一定会淘汰我们，但会用AI的人一定会淘汰不会用AI的我们。 所以，我创建了一个知识星球【chatGPT副业指南】，用于分享chatGPT、ai绘图等相关的使用技巧，行业动态，以及一些可能的变现手段。欢迎大家趁早入局，在真正的ai红利到来之前提前做好准备。 社群里会有一帮志同道合的小伙伴，要相信，一个人虽然可以走得很快，但一群人才能走得更远！ 现在加入只要59，还送20元优惠券。随着社群人数不断变多，加入门槛也会不断提高。 早，确实就是优势。","categories":[{"name":"骚话连篇","slug":"骚话连篇","permalink":"https://xiaobaidebug.top/categories/%E9%AA%9A%E8%AF%9D%E8%BF%9E%E7%AF%87/"}],"tags":[]},{"title":"动图图解 | UDP就一定比TCP快吗？","slug":"图解网络/UDP就一定比TCP快吗","date":"2022-10-17T14:57:55.000Z","updated":"2022-10-30T02:50:27.575Z","comments":true,"path":"2022/10/17/图解网络/UDP就一定比TCP快吗/","link":"","permalink":"https://xiaobaidebug.top/2022/10/17/%E5%9B%BE%E8%A7%A3%E7%BD%91%E7%BB%9C/UDP%E5%B0%B1%E4%B8%80%E5%AE%9A%E6%AF%94TCP%E5%BF%AB%E5%90%97/","excerpt":"","text":"文章持续更新，可以微信搜一搜「小白debug」第一时间阅读，回复【面试】获面试题集。本文已经收录在GitHub https://github.com/xiaobaiTech/golangFamily , 有大厂面试完整考点和成长路线，欢迎Star。 话说，UDP比TCP快吗？ 相信就算不是八股文老手，也会下意识的脱口而出：”是“。 这要追问为什么，估计大家也能说出个大概。 但这也让人好奇，用UDP就一定比用TCP快吗？什么情况下用UDP会比用TCP慢？ 我们今天就来聊下这个话题。 使用socket进行数据传输作为一个程序员，假设我们需要在A电脑的进程发一段数据到B电脑的进程，我们一般会在代码里使用socket进行编程。 socket就像是一个电话或者邮箱（邮政的信箱）。当你想要发送消息的时候，拨通电话或者将信息塞到邮箱里，socket内核会自动完成将数据传给对方的这个过程。 基于socket我们可以选择使用TCP或UDP协议进行通信。 对于TCP这样的可靠性协议，每次消息发出后都能明确知道对方收没收到，就像打电话一样，只要”喂喂”两下就能知道对方有没有在听。 而UDP就像是给邮政的信箱寄信一样，你寄出去的信，根本就不知道对方有没有正常收到，丢了也是有可能的。 这让我想起了大概17年前，当时还没有现在这么发达的网购，想买一本《掌机迷》杂志，还得往信封里塞钱，然后一等就是一个月，好几次都怀疑信是不是丢了。我至今印象深刻，因为那是我和我哥攒了好久的钱。。。 回到socket编程的话题上。 创建socket的方式就像下面这样。 1fd = socket(AF_INET, 具体协议,0); 注意上面的”具体协议“，如果传入的是SOCK_STREAM，是指使用字节流传输数据，说白了就是TCP协议。 如果传入的是SOCK_DGRAM，是指使用数据报传输数据，也就是UDP协议。 返回的fd是指socket句柄，可以理解为socket的身份证号。通过这个fd你可以在内核中找到唯一的socket结构。 如果想要通过这个socket发消息，只需要操作这个fd就行了，比如执行 send(fd, msg, ...)，内核就会通过这个fd句柄找到socket然后进行发数据的操作。 如果一切顺利，此时对方执行接收消息的操作，也就是 recv(fd, msg, ...)，就能拿到你发的消息。 对于异常情况的处理但如果不顺利呢？ 比如消息发到一半，丢包了呢? 丢包的原因有很多，之前写过的《用了TCP协议，就一定不会丢包吗？》有详细聊到过，这里就不再展开。 那UDP和TCP的态度就不太一样了。 UDP表示，”哦，是吗？然后呢？关我x事” TCP态度就截然相反了，”啊？那可不行，是不是我发太快了呢？是不是链路太堵被别人影响到了呢？不过你放心，我肯定给你补发” TCP老实人石锤了。我们来看下这个老实人在背后都默默做了哪些事情。 重传机制对于TCP，它会给发出的消息打上一个编号（sequence），接收方收到后回一个**确认(ack)**。发送方可以通过ack的数值知道接收方收到了哪些sequence的包。 如果长时间等不到对方的确认，TCP就会重新发一次消息，这就是所谓的重传机制。 流量控制机制但重传这件事本身对性能影响是比较严重的，所以是下下策。 于是TCP就需要思考有没有办法可以尽量避免重传。 因为数据发送方和接收方处理数据能力可能不同，因此如果可以根据双方的能力去调整发送的数据量就好了，于是就有了发送和接收窗口，基本上从名字就能看出它的作用，比如接收窗口的大小就是指，接收方当前能接收的数据量大小，发送窗口的大小就指发送方当前能发的数据量大小。TCP根据窗口的大小去控制自己发送的数据量，这样就能大大减少丢包的概率。 滑动窗口机制接收方的接收到数据之后，会不断处理，处理能力也不是一成不变的，有时候处理的快些，那就可以收多点数据，处理的慢点那就希望对方能少发点数据。毕竟发多了就有可能处理不过来导致丢包，丢包会导致重传，这可是下下策。因此我们需要动态的去调节这个接收窗口的大小，于是就有了滑动窗口机制。 看到这里大家可能就有点迷了，流量控制和滑动窗口机制貌似很像，它们之间是啥关系？我总结一下。其实现在TCP是通过滑动窗口机制来实现流量控制机制的。 拥塞控制机制但这还不够，有时候发生丢包，并不是因为发送方和接收方的处理能力问题导致的。而是跟网络环境有关，大家可以将网络想象为一条公路。马路上可能堵满了别人家的车，只留下一辆车的空间。那就算你家有5辆车，目的地也正好有5个停车位，你也没办法同时全部一起上路。于是TCP希望能感知到外部的网络环境，根据网络环境及时调整自己的发包数量，比如马路只够两辆车跑，那我就只发两辆车。但外部环境这么复杂，TCP是怎么感知到的呢？ TCP会先慢慢试探的发数据，不断加码数据量，越发越多，先发一个，再发2个，4个…。直到出现丢包，这样TCP就知道现在当前网络大概吃得消几个包了，这既是所谓的拥塞控制机制。 不少人会疑惑流量控制和拥塞控制的关系。我这里小小的总结下。流量控制针对的是单个连接数据处理能力的控制，拥塞控制针对的是整个网络环境数据处理能力的控制。 分段机制但上面提到的都是怎么降低重传的概率，似乎重传这个事情就是无法避免的，那如果确实发生了，有没有办法降低它带来的影响呢？ 有。当我们需要发送一个超大的数据包时，如果这个数据包丢了，那就得重传同样大的数据包。但如果我能将其分成一小段一小段，那就算真丢了，那我也就只需要重传那一小段就好了，大大减小了重传的压力，这就是TCP的分段机制。 而这个所谓的一小段的长度，在传输层叫MSS（Maximum Segment Size），数据包长度大于MSS则会分成N个小于等于MSS的包。 而在网络层，如果数据包还大于MTU（Maximum Transmit Unit），那还会继续分包。 一般情况下，MSS=MTU-40Byte，所以TCP分段后，到了IP层大概率就不会再分片了。 乱序重排机制既然数据包会被分段，链路又这么复杂还会丢包，那数据包乱序也就显得不奇怪了。比如发数据包1,2,3。1号数据包走了其他网络路径，2和3数据包先到，1数据包后到，于是数据包顺序就成了2,3,1。这一点TCP也考虑到了，依靠数据包的sequence，接收方就能知道数据包的先后顺序。 后发的数据包先到是吧，那就先放到专门的乱序队列中，等数据都到齐后，重新整理好乱序队列的数据包顺序后再给到用户，这就是乱序重排机制。 连接机制前面提到，UDP是无连接的，而TCP是面向连接的。 这里提到的连接到底是啥？ TCP通过上面提到的各种机制实现了数据的可靠性。这些机制背后是通过一个个数据结构来实现的逻辑。而为了实现这套逻辑，操作系统内核需要在两端代码里维护一套复杂的状态机（三次握手，四次挥手，RST，closing等异常处理机制），这套状态机其实就是所谓的”连接”。这其实就是TCP的连接机制，而UDP用不上这套状态机，因此它是”无连接”的。 网络环境链路很长，还复杂，数据丢包是很常见的。 我们平常用TCP做各种数据传输，完全对这些事情无感知。 哪有什么岁月静好，是TCP替你负重前行。 这就是TCP三大特性”面向连接、可靠的、基于字节流”中”可靠“的含义。 不信你改用UDP试试，丢包那就是真丢了，丢到你怀疑人生。 用UDP就一定比用TCP快吗？这时候UDP就不服了：”正因为没有这些复杂的TCP可靠性机制，所以我很快啊“ 嗯，这也是大部分人认为UDP比TCP快的原因。 实际上大部分情况下也确实是这样的。这话没毛病。 那问题就来了。 有没有用了UDP但却比TCP慢的情况呢？ 其实也有。 在回答这个问题前，我需要先说下UDP的用途。 实际上，大部分人也不会尝试直接拿裸udp放到生产环境中去做项目。 那UDP的价值在哪？ 在我看来，UDP的存在，本质是内核提供的一个最小网络传输功能。 很多时候，大家虽然号称自己用了UDP，但实际上都很忌惮它的丢包问题，所以大部分情况下都会在UDP的基础上做各种不同程度的应用层可靠性保证。比如王者农药用的KCP，以及最近很火的QUIC（HTTP3.0），其实都在UDP的基础上做了重传逻辑，实现了一套类似TCP那样的可靠性机制。 教科书上最爱提UDP适合用于音视频传输，因为这些场景允许丢包。但其实也不是什么包都能丢的，比如重要的关键帧啥的，该重传还得重传。除此之外，还有一些乱序处理机制。举个例子吧。 打音视频电话的时候，你可能遇到过丢失中间某部分信息的情况，但应该从来没遇到过乱序的情况吧。 比如对方打网络电话给你，说了：”我好想给小白来个点赞在看！“ 这时候网络信号不好，你可能会听到”我….点赞在看”。 但却从来没遇到过”在看小白好想赞”这样的乱序场景吧？ 所以说，虽然选择了使用UDP，但一般还是会在应用层上做一些重传机制的。 于是问题就来了，如果现在我需要传一个特别大的数据包。 在TCP里，它内部会根据MSS的大小分段，这时候进入到IP层之后，每个包大小都不会超过MTU，因此IP层一般不会再进行分片。这时候发生丢包了，只需要重传每个MSS分段就够了。 但对于UDP，其本身并不会分段，如果数据过大，到了IP层，就会进行分片。此时发生丢包的话，再次重传，就会重传整个大数据包。 对于上面这种情况，使用UDP就比TCP要慢。 当然，解决起来也不复杂。这里的关键点在于是否实现了数据分段机制，使用UDP的应用层如果也实现了分段机制的话，那就不会出现上述的问题了。 总结 TCP为了实现可靠性，引入了重传机制、流量控制、滑动窗口、拥塞控制、分段以及乱序重排机制。而UDP则没有实现，因此一般来说TCP比UDP慢。 TCP是面向连接的协议，而UDP是无连接的协议。这里的”连接“其实是，操作系统内核在两端代码里维护的一套复杂状态机。 大部分项目，会在基于UDP的基础上，模仿TCP，实现不同程度的可靠性机制。比如王者农药用的KCP其实就在基于UDP在应用层里实现了一套重传机制。 对于UDP+重传的场景，如果要传超大数据包，并且没有实现分段机制的话，那数据就会在IP层分片，一旦丢包，那就需要重传整个超大数据包。而TCP则不需要考虑这个，内部会自动分段，丢包重传分段就行了。这种场景下，其实TCP更快。 最后最近原创更文的阅读量稳步下跌，思前想后，夜里辗转反侧。 我有个不成熟的请求。 离开广东好长时间了，好久没人叫我靓仔了。 大家可以在评论区里，叫我一靓仔吗？ 我这么善良质朴的愿望，能被满足吗？ 如果实在叫不出口的话，能帮我点下关注和右下角的点赞+收藏吗？ 如果评论区没人叫我靓仔，文章也没人点赞，我感觉我下篇文章要开始收费了，价钱我都想好了，8块8，毕竟男人都拒绝不了这种价格以8结尾的项目。 你说是吧，易峰。 别说了，一起在知识的海洋里呛水吧点击下方名片，关注公众号:【小白debug】 不满足于在留言区说骚话？ 加我，我们建了个划水吹牛皮群，在群里，你可以跟你下次跳槽可能遇到的同事或面试官聊点有意思的话题。就超！开！心！ 文章推荐： 程序员防猝死指南 TCP粘包 数据包：我只是犯了每个数据包都会犯的错 |硬核图解 动图图解！既然IP层会分片，为什么TCP层也还要分段？","categories":[{"name":"图解网络","slug":"图解网络","permalink":"https://xiaobaidebug.top/categories/%E5%9B%BE%E8%A7%A3%E7%BD%91%E7%BB%9C/"}],"tags":[]},{"title":"为什么有HTTP协议，还要有websocket协议","slug":"图解网络/为什么有HTTP协议，还要有websocket协议","date":"2022-09-18T14:57:55.000Z","updated":"2022-10-30T02:50:19.409Z","comments":true,"path":"2022/09/18/图解网络/为什么有HTTP协议，还要有websocket协议/","link":"","permalink":"https://xiaobaidebug.top/2022/09/18/%E5%9B%BE%E8%A7%A3%E7%BD%91%E7%BB%9C/%E4%B8%BA%E4%BB%80%E4%B9%88%E6%9C%89HTTP%E5%8D%8F%E8%AE%AE%EF%BC%8C%E8%BF%98%E8%A6%81%E6%9C%89websocket%E5%8D%8F%E8%AE%AE/","excerpt":"","text":"文章持续更新，可以微信搜一搜「小白debug」第一时间阅读，回复【面试】获面试题集。本文已经收录在GitHub https://github.com/xiaobaiTech/golangFamily , 有大厂面试完整考点和成长路线，欢迎Star。 平时我们打开网页，比如购物网站某宝。都是点一下列表商品，跳转一下网页就到了商品详情。 从HTTP协议的角度来看，就是点一下网页上的某个按钮，前端发一次HTTP请求，网站返回一次HTTP响应。 这种由客户端主动请求，服务器响应的方式也满足大部分网页的功能场景。 但有没有发现，这种情况下，服务器从来就不会主动给客户端发一次消息。 就像你喜欢的女生从来不会主动找你一样。 但如果现在，你在刷网页的时候右下角突然弹出一个小广告，提示你【一个人在家偷偷才能玩哦】。 求知，好学，勤奋，这些刻在你DNA里的东西都动起来了。 你点开后发现。 长相平平无奇的古某提示你”道士9条狗，全服横着走”。 影帝某辉老师跟你说”系兄弟就来砍我”。 来都来了，你就选了个角色进到了游戏界面里。 这时候，上来就是一个小怪，从远处走来，然后疯狂拿木棒子抽你。 你全程没点任何一次鼠标。服务器就自动将怪物的移动数据和攻击数据源源不断发给你了。 这….太暖心了。 感动之余，问题就来了， 像这种看起来服务器主动发消息给客户端的场景，是怎么做到的？ 在真正回答这个问题之前，我们先来聊下一些相关的知识背景。 使用HTTP不断轮询其实问题的痛点在于，怎么样才能在用户不做任何操作的情况下，网页能收到消息并发生变更。 最常见的解决方案是，网页的前端代码里不断定时发HTTP请求到服务器，服务器收到请求后给客户端响应消息。 这其实时一种伪服务器推的形式。 它其实并不是服务器主动发消息到客户端，而是客户端自己不断偷偷请求服务器，只是用户无感知而已。 用这种方式的场景也有很多，最常见的就是扫码登录。 比如某信公众号平台，登录页面二维码出现之后，前端网页根本不知道用户扫没扫，于是不断去向后端服务器询问，看有没有人扫过这个码。而且是以大概1到2秒的间隔去不断发出请求，这样可以保证用户在扫码后能在1到2s内得到及时的反馈，不至于等太久。 但这样，会有两个比较明显的问题 当你打开F12页面时，你会发现满屏的HTTP请求。虽然很小，但这其实也消耗带宽，同时也会增加下游服务器的负担。 最坏情况下，用户在扫码后，需要等个1~2s，正好才触发下一次http请求，然后才跳转页面，用户会感到明显的卡顿。 使用起来的体验就是，二维码出现后，手机扫一扫，然后在手机上点个确认，这时候卡顿等个1~2s，页面才跳转。 那么问题又来了，有没有更好的解决方案？ 有，而且实现起来成本还非常低。 长轮询我们知道，HTTP请求发出后，一般会给服务器留一定的时间做响应，比如3s，规定时间内没返回，就认为是超时。 如果我们的HTTP请求将超时设置的很大，比如30s，在这30s内只要服务器收到了扫码请求，就立马返回给客户端网页。如果超时，那就立马发起下一次请求。 这样就减少了HTTP请求的个数，并且由于大部分情况下，用户都会在某个30s的区间内做扫码操作，所以响应也是及时的。 比如，某度云网盘就是这么干的。所以你会发现一扫码，手机上点个确认，电脑端网页就秒跳转，体验很好。 真一举两得。 像这种发起一个请求，在较长时间内等待服务器响应的机制，就是所谓的长轮询机制。我们常用的消息队列RocketMQ中，消费者去取数据时，也用到了这种方式。 像这种，在用户不感知的情况下，服务器将数据推送给浏览器的技术，就是所谓的服务器推送技术，它还有个毫不沾边的英文名，comet技术，大家听过就好。 上面提到的两种解决方案，本质上，其实还是客户端主动去取数据。 对于像扫码登录这样的简单场景还能用用。 但如果是网页游戏呢，游戏一般会有大量的数据需要从服务器主动推送到客户端。 这就得说下websocket了。 websocket是什么我们知道TCP连接的两端，同一时间里，双方都可以主动向对方发送数据。这就是所谓的全双工。 而现在使用最广泛的HTTP1.1，也是基于TCP协议的，同一时间里，客户端和服务器只能有一方主动发数据，这就是所谓的半双工。 也就是说，好好的全双工TCP，被HTTP用成了半双工。 为什么？ 这是由于HTTP协议设计之初，考虑的是看看网页文本的场景，能做到客户端发起请求再由服务器响应，就够了，根本就没考虑网页游戏这种，客户端和服务器之间都要互相主动发大量数据的场景。 所以为了更好的支持这样的场景，我们需要另外一个基于TCP的新协议。 于是新的应用层协议websocket就被设计出来了。 大家别被这个名字给带偏了。虽然名字带了个socket，但其实socket和websocket之间，就跟雷峰和雷峰塔一样，二者接近毫无关系。 怎么建立websocket连接我们平时刷网页，一般都是在浏览器上刷的，一会刷刷图文，这时候用的是HTTP协议，一会打开网页游戏，这时候就得切换成我们新介绍的websocket协议。 为了兼容这些使用场景。浏览器在TCP三次握手建立连接之后，都统一使用HTTP协议先进行一次通信。 如果此时是普通的HTTP请求，那后续双方就还是老样子继续用普通HTTP协议进行交互，这点没啥疑问。 如果这时候是想建立websocket连接，就会在HTTP请求里带上一些特殊的header头。 123Connection: UpgradeUpgrade: websocketSec-WebSocket-Key: T2a6wZlAwhgQNqruZ2YUyg==\\r\\n 这些header头的意思是，浏览器想升级协议（Connection: Upgrade），并且想升级成websocket协议（Upgrade: websocket）。 同时带上一段随机生成的base64码（Sec-WebSocket-Key），发给服务器。 如果服务器正好支持升级成websocket协议。就会走websocket握手流程，同时根据客户端生成的base64码，用某个公开的算法变成另一段字符串，放在HTTP响应的 Sec-WebSocket-Accept 头里，同时带上101状态码，发回给浏览器。 1234HTTP/1.1 101 Switching Protocols\\r\\nSec-WebSocket-Accept: iBJKv/ALIW2DobfoA4dmr3JHBCY=\\r\\nUpgrade: websocket\\r\\nConnection: Upgrade\\r\\n http状态码=200（正常响应）的情况，大家见得多了。101确实不常见，它其实是指协议切换。 之后，浏览器也用同样的公开算法将base64码转成另一段字符串，如果这段字符串跟服务器传回来的字符串一致，那验证通过。 就这样经历了一来一回两次HTTP握手，websocket就建立完成了，后续双方就可以使用webscoket的数据格式进行通信了。 websocket抓包我们可以用wireshark抓个包，实际看下数据包的情况。 上面这张图，注意画了红框的第2445行报文，是websocket的第一次握手，意思是发起了一次带有特殊Header的HTTP请求。 上面这个图里画了红框的4714行报文，就是服务器在得到第一次握手后，响应的第二次握手，可以看到这也是个HTTP类型的报文，返回的状态码是101。同时可以看到返回的报文header中也带有各种websocket相关的信息，比如Sec-WebSocket-Accept。 上面这张图就是全貌了，从截图上的注释可以看出，websocket和HTTP一样都是基于TCP的协议。经历了三次TCP握手之后，利用HTTP协议升级为websocket协议。 你在网上可能会看到一种说法：”websocket是基于HTTP的新协议”，其实这并不对，因为websocket只有在建立连接时才用到了HTTP，升级完成之后就跟HTTP没有任何关系了。 这就好像你喜欢的女生通过你要到了你大学室友的微信，然后他们自己就聊起来了。你能说这个女生是通过你去跟你室友沟通的吗？不能。你跟HTTP一样，都只是个工具人。 这就有点”借壳生蛋“的那意思。 websocket的消息格式上面提到在完成协议升级之后，两端就会用webscoket的数据格式进行通信。 数据包在websocket中被叫做帧。 我们来看下它的数据格式长什么样子。 这里面字段很多，但我们只需要关注下面这几个。 opcode字段：这个是用来标志这是个什么类型的数据帧。比如。 等于1时是指text类型（string）的数据包 等于2是二进制数据类型（[]byte）的数据包 等于8是关闭连接的信号 payload字段：存放的是我们真正想要传输的数据的长度，单位是字节。比如你要发送的数据是字符串&quot;111&quot;，那它的长度就是3。 另外，可以看到，我们存放payload长度的字段有好几个，我们既可以用最前面的7bit, 也可以用后面的7+16bit或7+64bit。 那么问题就来了。 我们知道，在数据层面，大家都是01二进制流。我怎么知道什么情况下应该读7bit，什么情况下应该读7+16bit呢？ websocket会用最开始的7bit做标志位。不管接下来的数据有多大，都先读最先的7个bit，根据它的取值决定还要不要再读个16bit或64bit。 如果最开始的7bit的值是 0~125，那么它就表示了 payload 全部长度，只读最开始的7个bit就完事了。 如果是126（0x7E）。那它表示payload的长度范围在 126~65535 之间，接下来还需要再读16bit。这16bit会包含payload的真实长度。 如果是127（0x7F）。那它表示payload的长度范围&gt;=65536，接下来还需要再读64bit。这64bit会包含payload的长度。这能放2的64次方byte的数据，换算一下好多个TB，肯定够用了。 payload data字段：这里存放的就是真正要传输的数据，在知道了上面的payload长度后，就可以根据这个值去截取对应的数据。 大家有没有发现一个小细节，websocket的数据格式也是 数据头（内含payload长度） + payload data 的形式。 之前写的《既然有HTTP协议，为什么还要有RPC》提到过，TCP协议本身就是全双工，但直接使用纯裸TCP去传输数据，会有粘包的”问题”。为了解决这个问题，上层协议一般会用消息头+消息体的格式去重新包装要发的数据。 而消息头里一般含有消息体的长度，通过这个长度可以去截取真正的消息体。 HTTP协议和大部分RPC协议，以及我们今天介绍的websocket协议，都是这样设计的。 websocket的使用场景websocket完美继承了TCP协议的全双工能力，并且还贴心的提供了解决粘包的方案。它适用于需要服务器和客户端（浏览器）频繁交互的大部分场景。比如网页/小程序游戏，网页聊天室，以及一些类似飞书这样的网页协同办公软件。 回到文章开头的问题，在使用websocket协议的网页游戏里，怪物移动以及攻击玩家的行为是服务器逻辑产生的，对玩家产生的伤害等数据，都需要由服务器主动发送给客户端，客户端获得数据后展示对应的效果。 总结 TCP协议本身是全双工的，但我们最常用的HTTP1.1，虽然是基于TCP的协议，但它是半双工的，对于大部分需要服务器主动推送数据到客户端的场景，都不太友好，因此我们需要使用支持全双工的websocket协议。 在HTTP1.1里。只要客户端不问，服务端就不答。基于这样的特点，对于登录页面这样的简单场景，可以使用定时轮询或者长轮询的方式实现服务器推送(comet)的效果。 对于客户端和服务端之间需要频繁交互的复杂场景，比如网页游戏，都可以考虑使用websocket协议。 websocket和socket几乎没有任何关系，只是叫法相似。 正因为各个浏览器都支持HTTP协议，所以websocket会先利用HTTP协议加上一些特殊的header头进行握手升级操作，升级成功后就跟HTTP没有任何关系了，之后就用websocket的数据格式进行收发数据。 最后最近原创更文的阅读量稳步下跌，思前想后，夜里辗转反侧。 我有个不成熟的请求。 离开广东好长时间了，好久没人叫我靓仔了。 大家可以在评论区里，叫我一靓仔吗？ 我这么善良质朴的愿望，能被满足吗？ 如果实在叫不出口的话，能帮我点下关注和右下角的点赞+在看吗？ 别说了，一起在知识的海洋里呛水吧点击下方名片，关注公众号:【小白debug】 不满足于在留言区说骚话？ 加我，我们建了个划水吹牛皮群，在群里，你可以跟你下次跳槽可能遇到的同事或面试官聊点有意思的话题。就超！开！心！ 文章推荐： 程序员防猝死指南 TCP粘包 数据包：我只是犯了每个数据包都会犯的错 |硬核图解 动图图解！既然IP层会分片，为什么TCP层也还要分段？","categories":[{"name":"图解网络","slug":"图解网络","permalink":"https://xiaobaidebug.top/categories/%E5%9B%BE%E8%A7%A3%E7%BD%91%E7%BB%9C/"}],"tags":[]},{"title":"能ping通，TCP就一定能连通吗？","slug":"图解网络/能ping通，就代表TCP一定能连通吗？","date":"2022-08-18T14:57:55.000Z","updated":"2022-10-30T02:47:39.796Z","comments":true,"path":"2022/08/18/图解网络/能ping通，就代表TCP一定能连通吗？/","link":"","permalink":"https://xiaobaidebug.top/2022/08/18/%E5%9B%BE%E8%A7%A3%E7%BD%91%E7%BB%9C/%E8%83%BDping%E9%80%9A%EF%BC%8C%E5%B0%B1%E4%BB%A3%E8%A1%A8TCP%E4%B8%80%E5%AE%9A%E8%83%BD%E8%BF%9E%E9%80%9A%E5%90%97%EF%BC%9F/","excerpt":"","text":"文章持续更新，可以微信搜一搜「小白debug」第一时间阅读，回复【面试】获面试题集。本文已经收录在GitHub https://github.com/xiaobaiTech/golangFamily , 有大厂面试完整考点和成长路线，欢迎Star。 平时，我们想要知道，自己的机器到目的机器之间，网络通不通，一般会执行ping命令。 一般对于状况良好的网络来说，你能看到它对应的loss丢包率为0%，也就是所谓的能ping通。如果看到丢包率100%，也就是ping不通。 那么问题来了，假设我能ping通某台机器，那这时候如果我改用TCP协议去发数据到目的机器，也一定能通吗？ 或者换个问法，ping和tcp协议走的网络路径是一样的吗？ 这时候第一反应就是不一定，因为ping完之后中间链路里的某个路由器可能会挂了（断电了），再用TCP去连就会走别的路径。 也没错。但假设，中间链路没发生任何变化呢？ 我先直接说答案。 不一定，走的网络路径还是有可能是不同的。 今天就来聊聊为什么。 我之前写过一篇《断网了，还能ping通 127.0.0.1 吗？》,里面提到过ping数据包和tcp数据包的区别。 我们知道网络是分层的，每一层都有对应协议。 而这网络层就像搭积木一样，上层协议都是基于下层协议搭出来的。 不管是ping（用了ICMP协议）还是tcp本质上都是基于网络层IP协议的数据包，而到了物理层，都是二进制01串，都走网卡发出去了。 如果网络环境没发生变化，目的地又一样，那按道理说他们走的网络路径应该是一样的，什么情况下会不同呢？ 我们就从路由这个话题聊起吧。 网络路径在我们的想象中，当我们想在两台机器之间传输数据。本机和目的机器之间会建立一条连接，像一条管道一样，数据从这头到那头。这条管道其实是我们为了方便理解而抽象出来的概念。 实际上，我们将数据包从本地网卡发出之后，会经过各种路由器（或者交换机），才能到达目的机器。 这些路由器数量众多，相互之间可以互连，连起来之后就像是一张大网，所以叫**”网络”**可以说是非常的形象。 考虑到交换机有的功能，路由器基本上都支持，所以我们这边只讨论路由器。 那么现在问题来了，路由器收到数据后，怎么知道应该走哪条路径，传给哪个路由器？ 路径由什么决定？在上面的那么大一张网络中，随便一个路由器都有可能走任何一个路径，将数据发到另外一个路由器上， 但路由和路由之间距离，带宽啥的可能都不同。 于是就很需要知道，两点之间走哪条路才是最优路径。 于是问题就变成了这样一个图状结构。每条边都带有成本或权重，算这上面任意两点的最短距离。 这时候想必大家回忆压不住要上来了。 这题我熟，这就是大学时候刷的Dijkstra算法。菊花厂的OJ笔试题集里也经常出现，现在终于明白为什么他们家的笔试题里图类题目比别的大厂貌似要多一些了吧，因为菊花厂就是搞通信的，做路由器的老玩家了。 路由表的生成基于Dijkstra算法，封装出了一个新的协议，OSPF协议（Open Shortest Path First, 开放最短路径优先）。 有了OSPF，路由器就得到了网络图里自己到其他点之间的最短距离，于是就知道了数据包要到某个点，该走哪条最优路径。 将这些信息汇成一张表，也就是我们常说的路由表。 路由表里记录了到什么IP需要走什么端口，以及走这条路径的成本（metric）。 可以通过 route 命令查看到。 路由表决定数据包路径数据包在发送的过程中，会在网络层加入目标地址IP。 路由器会根据这个IP跟路由表去做匹配。 然后路由表，会告诉路由器，什么样的消息该转发到什么端口。 举个例子。 假设A要发消息到D。也就是192.168.0.105/24要发消息到192.168.1.11/24。 那么A会把消息经发到路由器。 路由器已知目的地IP192.168.1.11/24 ，去跟路由表做匹配，发现192.168.1.0/24, 就在e2端口，那么就会把消息从e2端口发出，（可能还会经过交换机）最后把消息打到目的机器。 当然，如果路由表里找不到，那就打到默认网关吧，也就是从e1口发出，发到IP192.0.2.1。这个路由器的路由表不知道该去哪，说不定其他路由器知道。 路由表的匹配规则上面的例子里，是只匹配上了路由表里的一项，所以只能是它了。 但是，条条大路通罗马。实际上能到目的地的路径肯定有很多。 如果路由表里有很多项都被匹配上了，会怎么选？ 如果多个路由项都能到目的地，那就优先选匹配长度更长的那个。比如，还是目的地192.168.1.11，发现路由表里的192.168.1.0/24 和 192.168.0.0/16都能匹配上，但明显前者匹配长度更长，所以最后会走 192.168.1.0/24对应的转发端口。 但如果两个表项的匹配长度都一样呢？ 那就会看生成这个路由表项的协议是啥，选优先级高的，优先级越高也就是所谓的管理距离（AD，AdministrativeDistance）越小。比如说优先选手动配的静态（static）路由，次优选OSPF动态学习过来的表项。 如果还是相同，就看度量值metrics，其实也就是路径成本cost，成本越小，越容易被选中。 路由器能选的路线有很多，但按道理，最优的只有”一条”，所以到这里为止，我们都可以认为，对于同一个目的地，ping和TCP走的路径是相同的。 但是。 如果连路径成本都一样呢？也就是说有多条最优路径呢。 那就都用。 这也就是所谓的等价多路径，ECMP（Equal Cost MultiPath）。 我们可以通过traceroute看下链路是否存在等价多路径的情况。 可以看到，中间某几行，有好几个IP，也就是说这一跳里同时可以选好几个目的机器，说明这段路径支持ECMP。 ECMP有什么用利用等价多路径，我们可以增加链路带宽。 举个例子。 从A点到B点，如果这两条路径成本不同，带宽都是1千兆。那数据包肯定就选成本低的那条路了，如果这条路出故障了，就走下面那条路。但不管怎么样，同一时间，只用到了一条路径。另外一条闲置就有些浪费了，有没有办法可以利用起来呢？ 有，将它们两条路径的成本设置成一样，那它们就成了等价路由，然后中间的路由器开启ECMP特性，就可以同时利用这两条链路了。带宽就从原来的1千兆变成了2千兆。数据就可以在两条路径中随意选择了。 但这也带来了另外一个问题。加剧了数据包乱序。 原来我只使用一条网络路径，数据依次发出，如无意外，也是依次到达。 现在两个数据包走两条路径，先发的数据包可能后到。这就乱序了。 那么问题又又来了。 乱序会有什么问题？对于我们最最最常使用的TCP协议来说，它是个可靠性网络的协议，这里提到的可靠，不仅是保证数据要能送到目的地，还要保证数据顺序要跟原来发送端的一样。 实现也很简单，TCP为每个数据包（segment）做上编号。数据到了接收端后，根据数据包编号发现是乱序数据包，就会扔到乱序队列中对数据包进行排序。如果前面的数据包还没到，哪怕后面的数据包先到了，也得在乱序队列中一直等，到齐后才能被上层拿到。 举个例子，发送端发出三个数据包，编号1,2,3，假设在传输层2和3先到了，1还没到。那此时应用层是没办法拿到2和3的数据包的，必须得等1来了之后，应用层才能一次性拿到这三个包。因为这三个包原来可能表示的是一个完整的消息，少了1, 那么消息就不完整，应用层拿到了也毫无意义。 像这种，由于前面的数据丢失导致后面的数据没办法及时给到应用层的现象，就是我们常说的TCP队头阻塞。 乱序发生时2和3需要待在乱序队列中，而乱序队列其实用的也是接收缓冲区的内存，而接收缓冲区是有大小限制的。通过下面的命令可以看到接收缓冲区的大小。 1234# 查看接收缓冲区$ sysctl net.ipv4.tcp_rmemnet.ipv4.tcp_rmem = 4096(min) 87380(default) 6291456(max)# 缓冲区会在min和max之间动态调整 乱序的情况越多，接收缓冲区的内存就被占用的越多，对应的接收窗口就会变小，那正常能收的数据就变少了，网络吞吐就变差了，也就是性能变差了。 因此，我们需要尽量保证所有同一个TCP连接下的所有TCP包都走相同路径，这样才能最大程度避免丢包。 ECMP的路径选择策略当初开启ECMP就是为了提升性能，现在反而加重了乱序，降低了TCP传输性能。 这怎么能忍。 为了解决这个问题，我们需要有一个合理的路径选择策略。为了避免同一个连接里的数据包乱序，我们需要保证同一个连接里的数据包，都走同样的路径。 这好办。我们可以通过连接的五元组（发送方的IP和端口，接收方的IP和端口，以及通信协议）信息定位到唯一一条连接。 然后对五元组信息生成哈希键，让同一个哈希键的数据走同一条路径，问题就完美解决了。 TCP和Ping走的网络路径一样吗现在我们回到文章开头的问题。 对于同样的发送端和接收端，TCP和Ping走的网络路径一样吗？ 不一定一样，因为五元组里的信息里有一项是通信协议。ping用的是ICMP协议，跟TCP协议不同，并且ping不需要用到端口，所以五元组不同，生成的哈希键不同，通过ECMP选择到的路径也可能不同。 同样都用TCP协议，数据包走的网络路径一样吗还是同样的发送端和接收端，同样是TCP协议，不同TCP连接走的网络路径是一样的吗？ 跟上面的问题一样，其实还是五元组的问题，同样都是TCP协议，对于同样的发送端和接收端，他们的IP和接收端的端口肯定是一样的，但发送方的端口是可以随时变化的，因此通过ECMP走的路径也可能不同。 但问题又来了。 我知道这个有什么用呢？我做业务开发，又没有设置网络路由的权限。 利用这个知识点排查问题对于业务开发，这绝对不是个没用的知识点。 如果某天，你发现，你能ping通目的机器，但用TCP去连，却偶尔连不上目的机器。而且两端机器都挺空闲，没什么性能上的瓶颈。实在走投无路了。 你就可以想想，会不会是网络中用到了ECMP，其中一条链路有问题导致的。 排查方法也很简单。 你是知道本机的IP以及目的机器的IP和端口号的，也知道自己用的是TCP连接。 只要你在报错的时候打印下错误信息，你就知道了发送端的端口号了。 这样五元组是啥你就知道了。 下一步就是指定发送端的端口号重新发起TCP请求，同样的五元组，走同样的路径，按理说如果链路有问题，就肯定会复现。 如果不想改自己的代码，你可以用nc命令指定客户端端口看下能不能正常建立TCP连接。 1nc -p 6666 baidu.com 80 -p 6666是指定发出请求的客户端端口是6666，后面跟着的是连接的域名和80端口。 假设用了6666端口的五元组去连接总是失败，改用6667或其他端口却能成功，你可以带着这个信息去找找负责网络的同事。 总结 路由器可以通过OSPF协议生成路由表，利用数据包里的IP地址去跟路由表做匹配，选择最优路径后进行转发。 当路由表一个都匹配不上时会走默认网关。当匹配上多个的时候，会先看匹配长度，如果一样就看管理距离，还一样就看路径成本。如果连路径成本都一样，那等价路径。如果路由开启了ECMP，那就可以同时利用这几条路径做传输。 ECMP可以提高链路带宽，同时利用五元组做哈希键进行路径选择，保证了同一条连接的数据包走同一条路径，减少了乱序的情况。 可以通过traceroute命令查看到链路上是否有用到ECMP的情况。 开启了ECMP的网络链路中，TCP和ping命令可能走的路径不同，甚至同样是TCP，不同连接之间，走的路径也不同，因此出现了连接时好时坏的问题，实在是走投无路了，可以考虑下是不是跟ECMP有关。 当然，遇到问题多怀疑自己，要相信绝大部分时候真的跟ECMP无关。 参考资料《网络排查案例课》 ——极客时间 最后兄弟们。 按照惯例，我应该在这里唯唯诺诺的求大家叫我两声靓仔的。 但我今天不想。 因为越是这样，评论区里叫我diao毛的兄弟就越多。 上海快40°的天气，你们竟然能说出如此冰冷的话。 但是。 只要你们还能给我文章右下角来个点赞和在看的话。 这口气，我还能忍。 别说了，一起在知识的海洋里呛水吧点击下方名片，关注公众号:【小白debug】 不满足于在留言区说骚话？ 加我，我们建了个划水吹牛皮群，在群里，你可以跟你下次跳槽可能遇到的同事或面试官聊点有意思的话题。就超！开！心！ 文章推荐： 程序员防猝死指南 TCP粘包 数据包：我只是犯了每个数据包都会犯的错 |硬核图解 动图图解！既然IP层会分片，为什么TCP层也还要分段？","categories":[{"name":"图解网络","slug":"图解网络","permalink":"https://xiaobaidebug.top/categories/%E5%9B%BE%E8%A7%A3%E7%BD%91%E7%BB%9C/"}],"tags":[]},{"title":"TCP四次挥手中如果服务端没收到第四次挥手请求，服务端会一直等待吗？","slug":"图解网络/TCP四次挥手中如果服务端没收到第四次挥手请求，服务端会一直等待吗？","date":"2022-08-13T14:57:55.000Z","updated":"2022-10-30T02:45:50.190Z","comments":true,"path":"2022/08/13/图解网络/TCP四次挥手中如果服务端没收到第四次挥手请求，服务端会一直等待吗？/","link":"","permalink":"https://xiaobaidebug.top/2022/08/13/%E5%9B%BE%E8%A7%A3%E7%BD%91%E7%BB%9C/TCP%E5%9B%9B%E6%AC%A1%E6%8C%A5%E6%89%8B%E4%B8%AD%E5%A6%82%E6%9E%9C%E6%9C%8D%E5%8A%A1%E7%AB%AF%E6%B2%A1%E6%94%B6%E5%88%B0%E7%AC%AC%E5%9B%9B%E6%AC%A1%E6%8C%A5%E6%89%8B%E8%AF%B7%E6%B1%82%EF%BC%8C%E6%9C%8D%E5%8A%A1%E7%AB%AF%E4%BC%9A%E4%B8%80%E7%9B%B4%E7%AD%89%E5%BE%85%E5%90%97%EF%BC%9F/","excerpt":"","text":"文章持续更新，可以微信搜一搜「小白debug」第一时间阅读，回复【面试】获面试题集。本文已经收录在GitHub https://github.com/xiaobaiTech/golangFamily , 有大厂面试完整考点和成长路线，欢迎Star。 搬运一个在某乎的回答，水一篇文章吧。 正常情况下。只要数据传输完了，不管是客户端还是服务端，都可以主动发起四次挥手，释放连接。 就跟上图画的一样，假设，这次四次挥手是由客户端主动发起的，那它就是主动方。服务器是被动接收客户端的挥手请求的，叫被动方。 客户端和服务器，一开始，都是处于ESTABLISHED状态。 第一次挥手：一般情况下，主动方执行close()或 shutdown()方法，会发个FIN报文出来，表示”我不再发送数据了“。 第二次挥手：在收到主动方的FIN报文后，被动方立马回应一个ACK，意思是”我收到你的FIN了，也知道你不再发数据了”。 上面提到的是主动方不再发送数据了。但如果这时候，被动方还有数据要发，那就继续发。注意，虽然第二次和第三次挥手之间，被动方是能发数据到主动方的，但主动方能不能正常收就不一定了，这个待会说。 第三次挥手：在被动方在感知到第二次挥手之后，会做了一系列的收尾工作，最后也调用一个 close(), 这时候就会发出第三次挥手的 FIN-ACK。 第四次挥手：主动方回一个ACK，意思是收到了。 其中第一次挥手和第三次挥手，都是我们在应用程序中主动触发的（比如调用close()方法），也就是我们平时写代码需要关注的地方。 第二和第四次挥手，都是内核协议栈自动帮我们完成的，我们写代码的时候碰不到这地方，因此也不需要太关心。 另外不管是主动还是被动，每方发出了一个 FIN 和一个ACK 。也收到了一个 FIN 和一个ACK 。 回到题主的问题。 TCP四次挥手中如果服务端没收到第四次挥手请求，服务端会一直等待吗？ 第四次挥手是第三次挥手触发的。如果第四次挥手服务端一直没收到，那服务端会认为是不是自己的第三次挥手丢了，于是服务端不断重试发第三次挥手（FIN）.重发次数由系统的tcp_orphan_retries参数控制。重试多次还没成功，服务端直接断开链接。所以结论是服务端不会一直等待第四次挥手。 12# cat /proc/sys/net/ipv4/tcp_orphan_retries0 另外，你会发现tcp_orphan_retries参数是0，但其实并不是不重试的意思。为0时，默认值为8. 也就是重试8次。 12345678910111213141516/* Calculate maximal number or retries on an orphaned socket. */static int tcp_orphan_retries(struct sock *sk, int alive)&#123; int retries = sysctl_tcp_orphan_retries; /* May be zero. */ /* We know from an ICMP that something is wrong. */ if (sk-&gt;sk_err_soft &amp;&amp; !alive) retries = 0; /* However, if socket sent something recently, select some safe * number of retries. 8 corresponds to &gt;100 seconds with minimal * RTO of 200msec. */ if (retries == 0 &amp;&amp; alive) retries = 8; return retries;&#125; 当然如果服务端重试发第三次挥手FIN的过程中，还是同样的端口和IP,起了个新的客户端，这时候服务端重试的FIN被收到后，客户端就会认为是不正常的数据包，直接发个RST给服务端，这时候两端连接也会断开。 参考资料查资料的时候发现小林大佬已经写过，而且写的巨好，感兴趣的可以看下他的这篇文章。 《 如何优化 TCP?》https://xiaolincoding.com/network/3_tcp/tcp_optimize.html#%E4%B8%BB%E5%8A%A8%E6%96%B9%E7%9A%84%E4%BC%98%E5%8C%96 链接太长，懒得复制的话，点击阅读原文可以直接跳转。 最后新的文章快写好了，就缺个开头了。 我有个不成熟的请求。 离开广东好长时间了，好久没人叫我靓仔了。 大家可以在评论区里，叫我一靓仔吗？ 我这么善良质朴的愿望，能被满足吗？ 如果实在叫不出口的话，能帮我点下右下角的点赞和在看吗？ 别说了，一起在知识的海洋里呛水吧点击下方名片，关注公众号:【小白debug】 不满足于在留言区说骚话？ 加我，我们建了个划水吹牛皮群，在群里，你可以跟你下次跳槽可能遇到的同事或面试官聊点有意思的话题。就超！开！心！ 文章推荐： 程序员防猝死指南 TCP粘包 数据包：我只是犯了每个数据包都会犯的错 |硬核图解 动图图解！既然IP层会分片，为什么TCP层也还要分段？","categories":[{"name":"图解网络","slug":"图解网络","permalink":"https://xiaobaidebug.top/categories/%E5%9B%BE%E8%A7%A3%E7%BD%91%E7%BB%9C/"}],"tags":[]},{"title":"用了TCP协议，就一定不会丢包吗？","slug":"图解网络/不是我不回你消息，是因为网络会丢包","date":"2022-08-01T14:57:55.000Z","updated":"2022-10-30T02:48:24.324Z","comments":true,"path":"2022/08/01/图解网络/不是我不回你消息，是因为网络会丢包/","link":"","permalink":"https://xiaobaidebug.top/2022/08/01/%E5%9B%BE%E8%A7%A3%E7%BD%91%E7%BB%9C/%E4%B8%8D%E6%98%AF%E6%88%91%E4%B8%8D%E5%9B%9E%E4%BD%A0%E6%B6%88%E6%81%AF%EF%BC%8C%E6%98%AF%E5%9B%A0%E4%B8%BA%E7%BD%91%E7%BB%9C%E4%BC%9A%E4%B8%A2%E5%8C%85/","excerpt":"","text":"文章持续更新，可以微信搜一搜「小白debug」第一时间阅读，回复【面试】获面试题集。本文已经收录在GitHub https://github.com/xiaobaiTech/golangFamily , 有大厂面试完整考点和成长路线，欢迎Star。 表面上我是个技术博主。 但没想到今天成了个情感博主。 我是没想到有一天，我会通过技术知识，来挽救粉丝即将破碎的感情。 掏心窝子的说。这件事情多少是沾点功德无量了。 事情是这样的。 最近就有个读者加了我的绿皮聊天软件，女生，头像挺好看的，就在我以为她要我拉她进群发成人专升本广告的时候。 画风突然不对劲。 她说她男朋友也是个程序员，异地恋，也关注了我，天天研究什么TCP，UDP网络。一研究就是一晚上，一晚上都不回她消息的那种。 话里有话，懂。 不出意外的出了意外，她发出了灵魂拷问 “你们程序员真的有那么忙吗？忙到连消息都不知道回。” 没想到上来就是一记直拳。 但是，这一拳，我接住了。 我很想告诉她”分了吧，下一题“。 但我不能。因为这样我就伤害了我的读者兄弟。 沉默了一下。 单核cpu都快转冒烟了，才颤颤巍巍在九宫格键盘上发出消息。 再回慢一点，我就感觉，我要对不起我这全日制本科学历了。 “其实，他已经回了你消息了，但你知道吗？网络是会丢包的。” “我来帮他解释下，这个话题就要从数据包的发送流程聊起” 数据包的发送流程首先，我们两个手机的绿皮聊天软件客户端，要通信，中间会通过它们家服务器。大概长这样。 但为了简化模型，我们把中间的服务器给省略掉，假设这是个端到端的通信。且为了保证消息的可靠性，我们盲猜它们之间用的是TCP协议进行通信。 为了发送数据包，两端首先会通过三次握手，建立TCP连接。 一个数据包，从聊天框里发出，消息会从聊天软件所在的用户空间拷贝到内核空间的发送缓冲区（send buffer），数据包就这样顺着传输层、网络层，进入到数据链路层，在这里数据包会经过流控（qdisc），再通过RingBuffer发到物理层的网卡。数据就这样顺着网卡发到了纷繁复杂的网络世界里。这里头数据会经过n多个路由器和交换机之间的跳转，最后到达目的机器的网卡处。 此时目的机器的网卡会通知DMA将数据包信息放到RingBuffer中，再触发一个硬中断给CPU，CPU触发软中断让ksoftirqd去RingBuffer收包，于是一个数据包就这样顺着物理层，数据链路层，网络层，传输层，最后从内核空间拷贝到用户空间里的聊天软件里。 画了那么大一张图，只水了200字做解释，我多少是有些心痛的。 到这里，抛开一些细节，大家大概知道了一个数据包从发送到接收的宏观过程。 可以看到，这上面全是密密麻麻的名词。 整条链路下来，有不少地方可能会发生丢包。 但为了不让大家保持蹲姿太久影响身体健康，我这边只重点讲下几个常见容易发生丢包的场景。 建立连接时丢包TCP协议会通过三次握手建立连接。大概长下面这样。 在服务端，第一次握手之后，会先建立个半连接，然后再发出第二次握手。这时候需要有个地方可以暂存这些半连接。这个地方就叫半连接队列。 如果之后第三次握手来了，半连接就会升级为全连接，然后暂存到另外一个叫全连接队列的地方，坐等程序执行accept()方法将其取走使用。 是队列就有长度，有长度就有可能会满，如果它们满了，那新来的包就会被丢弃。 可以通过下面的方式查看是否存在这种丢包行为。 1234567# 全连接队列溢出次数# netstat -s | grep overflowed 4343 times the listen queue of a socket overflowed # 半连接队列溢出次数# netstat -s | grep -i &quot;SYNs to LISTEN sockets dropped&quot; 109 times the listen queue of a socket overflowed 从现象来看就是连接建立失败。 这个话题在之前写的《没有accept，能建立TCP连接吗？》有更详细的聊过，感兴趣的可以回去看下。 流量控制丢包应用层能发网络数据包的软件有那么多，如果所有数据不加控制一股脑冲入到网卡，网卡会吃不消，那怎么办？让数据按一定的规则排个队依次处理，也就是所谓的qdisc(Queueing Disciplines，排队规则)，这也是我们常说的流量控制机制。 排队，得先有个队列，而队列有个长度。 我们可以通过下面的ifconfig命令查看到，里面涉及到的txqueuelen后面的数字1000，其实就是流控队列的长度。 当发送数据过快，流控队列长度txqueuelen又不够大时，就容易出现丢包现象。 可以通过下面的ifconfig命令，查看TX下的dropped字段，当它大于0时，则有可能是发生了流控丢包。 123456789# ifconfig eth0eth0: flags=4163&lt;UP,BROADCAST,RUNNING,MULTICAST&gt; mtu 1500 inet 172.21.66.69 netmask 255.255.240.0 broadcast 172.21.79.255 inet6 fe80::216:3eff:fe25:269f prefixlen 64 scopeid 0x20&lt;link&gt; ether 00:16:3e:25:26:9f txqueuelen 1000 (Ethernet) RX packets 6962682 bytes 1119047079 (1.0 GiB) RX errors 0 dropped 0 overruns 0 frame 0 TX packets 9688919 bytes 2072511384 (1.9 GiB) TX errors 0 dropped 0 overruns 0 carrier 0 collisions 0 当遇到这种情况时，我们可以尝试修改下流控队列的长度。比如像下面这样将eth0网卡的流控队列长度从1000提升为1500. 1# ifconfig eth0 txqueuelen 1500 网卡丢包网卡和它的驱动导致丢包的场景也比较常见，原因很多，比如网线质量差，接触不良。除此之外，我们来聊几个常见的场景。 RingBuffer过小导致丢包上面提到，在接收数据时，会将数据暂存到RingBuffer接收缓冲区中，然后等着内核触发软中断慢慢收走。如果这个缓冲区过小，而这时候发送的数据又过快，就有可能发生溢出，此时也会产生丢包。 我们可以通过下面的命令去查看是否发生过这样的事情。 12# ifconfigeth0: RX errors 0 dropped 0 overruns 0 frame 0 查看上面的overruns指标，它记录了由于RingBuffer长度不足导致的溢出次数。 当然，用ethtool命令也能查看。 1# ethtool -S eth0|grep rx_queue_0_drops 但这里需要注意的是，因为一个网卡里是可以有多个RingBuffer的，所以上面的rx_queue_0_drops里的0代表的是第0个RingBuffer的丢包数，对于多队列的网卡，这个0还可以改成其他数字。但我的家庭条件不允许我看其他队列的丢包数，所以上面的命令对我来说是够用了。。。 当发现有这类型丢包的时候，可以通过下面的命令查看当前网卡的配置。 123456789101112#ethtool -g eth0Ring parameters for eth0:Pre-set maximums:RX: 4096RX Mini: 0RX Jumbo: 0TX: 4096Current hardware settings:RX: 1024RX Mini: 0RX Jumbo: 0TX: 1024 上面的输出内容，含义是RingBuffer最大支持4096的长度，但现在实际只用了1024。 想要修改这个长度可以执行ethtool -G eth1 rx 4096 tx 4096将发送和接收RingBuffer的长度都改为4096。 RingBuffer增大之后，可以减少因为容量小而导致的丢包情况。 网卡性能不足网卡作为硬件，传输速度是有上限的。当网络传输速度过大，达到网卡上限时，就会发生丢包。这种情况一般常见于压测场景。 我们可以通过ethtool加网卡名，获得当前网卡支持的最大速度。 123# ethtool eth0Settings for eth0: Speed: 10000Mb/s 可以看到，我这边用的网卡能支持的最大传输速度speed=1000Mb/s。 也就是俗称的千兆网卡，但注意这里的单位是Mb，这里的b是指bit，而不是Byte。1Byte=8bit。所以10000Mb/s还要除以8，也就是理论上网卡最大传输速度是1000/8 = 125MB/s。 我们可以通过sar命令从网络接口层面来分析数据包的收发情况。 12345# sar -n DEV 1Linux 3.10.0-1127.19.1.el7.x86_64 2022年07月27日 _x86_64_ (1 CPU)08时35分39秒 IFACE rxpck/s txpck/s rxkB/s txkB/s rxcmp/s txcmp/s rxmcst/s08时35分40秒 eth0 6.06 4.04 0.35 121682.33 0.00 0.00 0.00 其中 txkB/s是指当前每秒发送的字节（byte）总数，rxkB/s是指每秒接收的字节（byte）总数。 当两者加起来的值约等于12~13w字节的时候，也就对应大概125MB/s的传输速度。此时达到网卡性能极限，就会开始丢包。 遇到这个问题，优先看下你的服务是不是真有这么大的真实流量，如果是的话可以考虑下拆分服务，或者就忍痛充钱升级下配置吧。 接收缓冲区丢包我们一般使用TCP socket进行网络编程的时候，内核都会分配一个发送缓冲区和一个接收缓冲区。 当我们想要发一个数据包，会在代码里执行send(msg)，这时候数据包并不是一把梭直接就走网卡飞出去的。而是将数据拷贝到内核发送缓冲区就完事返回了，至于什么时候发数据，发多少数据，这个后续由内核自己做决定。之前写过的《代码执行send成功后，数据就发出去了吗？》里有比较详细的介绍。 而接收缓冲区作用也类似，从外部网络收到的数据包就暂存在这个地方，然后坐等用户空间的应用程序将数据包取走。 这两个缓冲区是有大小限制的，可以通过下面的命令去查看。 1234567# 查看接收缓冲区# sysctl net.ipv4.tcp_rmemnet.ipv4.tcp_rmem = 4096 87380 6291456# 查看发送缓冲区# sysctl net.ipv4.tcp_wmemnet.ipv4.tcp_wmem = 4096 16384 4194304 不管是接收缓冲区还是发送缓冲区，都能看到三个数值，分别对应缓冲区的最小值，默认值和最大值 （min、default、max）。缓冲区会在min和max之间动态调整。 那么问题来了，如果缓冲区设置过小会怎么样？ 对于发送缓冲区，执行send的时候，如果是阻塞调用，那就会等，等到缓冲区有空位可以发数据。 如果是非阻塞调用，就会立刻返回一个 EAGAIN 错误信息，意思是 Try again 。让应用程序下次再重试。这种情况下一般不会发生丢包。 当接受缓冲区满了，事情就不一样了，它的TCP接收窗口会变为0，也就是所谓的零窗口，并且会通过数据包里的win=0，告诉发送端，”球球了，顶不住了，别发了”。一般这种情况下，发送端就该停止发消息了，但如果这时候确实还有数据发来，就会发生丢包。 我们可以通过下面的命令里的TCPRcvQDrop查看到有没有发生过这种丢包现象。 123cat /proc/net/netstatTcpExt: SyncookiesSent TCPRcvQDrop SyncookiesFailedTcpExt: 0 157 60116 但是说个伤心的事情，我们一般也看不到这个TCPRcvQDrop，因为这个是5.9版本里引入的打点，而我们的服务器用的一般是2.x~3.x左右版本。你可以通过下面的命令查看下你用的是什么版本的linux内核。 12# cat /proc/versionLinux version 3.10.0-1127.19.1.el7.x86_64 两端之间的网络丢包前面提到的是两端机器内部的网络丢包，除此之外，两端之间那么长的一条链路都属于外部网络，这中间有各种路由器和交换机还有光缆啥的，丢包也是很经常发生的。 这些丢包行为发生在中间链路的某些个机器上，我们当然是没权限去登录这些机器。但我们可以通过一些命令观察整个链路的连通情况。 ping命令查看丢包比如我们知道目的地的域名是 baidu.com。想知道你的机器到baidu服务器之间，有没有产生丢包行为。可以使用ping命令。 倒数第二行里有个100% packet loss，意思是**丢包率100%**。 但这样其实你只能知道你的机器和目的机器之间有没有丢包。 那如果你想知道你和目的机器之间的这条链路，哪个节点丢包了，有没有办法呢? 有。 mtr命令mtr命令可以查看到你的机器和目的机器之间的每个节点的丢包情况。 像下面这样执行命令。 其中**-r是指report**，以报告的形式打印结果。 可以看到Host那一列，出现的都是链路中间每一跳的机器，Loss的那一列就是指这一跳对应的丢包率。 需要注意的是，中间有一些是host是???，那个是因为mtr默认用的是ICMP包，有些节点限制了ICMP包，导致不能正常展示。 我们可以在mtr命令里加个-u，也就是使用udp包，就能看到**部分???**对应的IP。 把ICMP包和UDP包的结果拼在一起看，就是比较完整的链路图了。 还有个小细节，Loss那一列，我们在icmp的场景下，关注最后一行，如果是0%，那不管前面loss是100%还是80%都无所谓，那些都是节点限制导致的虚报。 但如果最后一行是20%，再往前几行都是20%左右，那说明丢包就是从最接近的那一行开始产生的，长时间是这样，那很可能这一跳出了点问题。如果是公司内网的话，你可以带着这条线索去找对应的网络同事。如果是外网的话，那耐心点等等吧，别人家的开发会比你更着急。 发生丢包了怎么办说了这么多。只是想告诉大家，丢包是很常见的，几乎不可避免的一件事情。 但问题来了，发生丢包了怎么办？ 这个好办，用TCP协议去做传输。 建立了TCP连接的两端，发送端在发出数据后会等待接收端回复ack包，ack包的目的是为了告诉对方自己确实收到了数据，但如果中间链路发生了丢包，那发送端会迟迟收不到确认ack，于是就会进行重传。以此来保证每个数据包都确确实实到达了接收端。 假设现在网断了，我们还用聊天软件发消息，聊天软件会使用TCP不断尝试重传数据，如果重传期间网络恢复了，那数据就能正常发过去。但如果多次重试直到超时都还是失败，这时候你将收获一个红色感叹号。 这时候问题又来了。 假设某绿皮聊天软件用的就是TCP协议。 那文章开头提到的女生，她男朋友回她的消息时为什么还会丢包？毕竟丢包了会重试，重试失败了还会出现红色感叹号。 于是乎，问题就变成了，用了TCP协议，就一定不会丢包吗？ 用了TCP协议就一定不会丢包吗我们知道TCP位于传输层，在它的上面还有各种应用层协议，比如常见的HTTP或者各类RPC协议。 TCP保证的可靠性，是传输层的可靠性。也就是说，TCP只保证数据从A机器的传输层可靠地发到B机器的传输层。 至于数据到了接收端的传输层之后，能不能保证到应用层，TCP并不管。 假设现在，我们输入一条消息，从聊天框发出，走到传输层TCP协议的发送缓冲区，不管中间有没有丢包，最后通过重传都保证发到了对方的传输层TCP接收缓冲区，此时接收端回复了一个ack，发送端收到这个ack后就会将自己发送缓冲区里的消息给扔掉。到这里TCP的任务就结束了。 TCP任务是结束了，但聊天软件的任务没结束。 聊天软件还需要将数据从TCP的接收缓冲区里读出来，如果在读出来这一刻，手机由于内存不足或其他各种原因，导致软件崩溃闪退了。 发送端以为自己发的消息已经发给对方了，但接收端却并没有收到这条消息。 于是乎，消息就丢了。 虽然概率很小，但它就是发生了。 合情合理，逻辑自洽。 所以从这里，我铿锵有力的得出结论，我的读者已经回了这位女生消息了，只是因为发生了丢包所以女生才没能收到，而丢包的原因是女生的手机聊天软件在接收消息的那一刻发生了闪退。 到这里。女生知道自己错怪她男朋友了，哭着表示，一定要让她男朋友给她买一台不闪退的最新款iphone。 额。。。 兄弟们觉得我做得对的，请在评论区扣个”正能量“。 这类丢包问题怎么解决？故事到这里也到尾声了，感动之余，我们来聊点掏心窝子的话。 其实前面说的都对，没有一句是假话。 但某绿皮聊天软件这么成熟，怎么可能没考虑过这一点呢。 大家应该还记得我们文章开头提到过，为了简单，就将服务器那一方给省略了，从三端通信变成了两端通信，所以才有了这个丢包问题。 现在我们重新将服务器加回来。 大家有没有发现，有时候我们在手机里聊了一大堆内容，然后登录电脑版，它能将最近的聊天记录都同步到电脑版上。也就是说服务器可能记录了我们最近发过什么数据，假设每条消息都有个id，服务器和聊天软件每次都拿最新消息的id进行对比，就能知道两端消息是否一致，就像对账一样。 对于发送方，只要定时跟服务端的内容对账一下，就知道哪条消息没发送成功，直接重发就好了。 如果接收方的聊天软件崩溃了，重启后跟服务器稍微通信一下就知道少了哪条数据，同步上来就是了，所以也不存在上面提到的丢包情况。 可以看出，TCP只保证传输层的消息可靠性，并不保证应用层的消息可靠性。如果我们还想保证应用层的消息可靠性，就需要应用层自己去实现逻辑做保证。 那么问题叒来了，两端通信的时候也能对账，为什么还要引入第三端服务器？ 主要有三个原因。 第一，如果是两端通信，你聊天软件里有1000个好友，你就得建立1000个连接。但如果引入服务端，你只需要跟服务器建立1个连接就够了，聊天软件消耗的资源越少，手机就越省电。 第二，就是安全问题，如果还是两端通信，随便一个人找你对账一下，你就把聊天记录给同步过去了，这并不合适吧。如果对方别有用心，信息就泄露了。引入第三方服务端就可以很方便的做各种鉴权校验。 第三，是软件版本问题。软件装到用户手机之后，软件更不更新就是由用户说了算了。如果还是两端通信，且两端的软件版本跨度太大，很容易产生各种兼容性问题，但引入第三端服务器，就可以强制部分过低版本升级，否则不能使用软件。但对于大部分兼容性问题，给服务端加兼容逻辑就好了，不需要强制用户更新软件。 所以看到这里大家应该明白了，我把服务端去掉，并不单纯是为了简单。 总结 数据从发送端到接收端，链路很长，任何一个地方都可能发生丢包，几乎可以说丢包不可避免。 平时没事也不用关注丢包，大部分时候TCP的重传机制保证了消息可靠性。 当你发现服务异常的时候，比如接口延时很高，总是失败的时候，可以用ping或者mtr命令看下是不是中间链路发生了丢包。 TCP只保证传输层的消息可靠性，并不保证应用层的消息可靠性。如果我们还想保证应用层的消息可靠性，就需要应用层自己去实现逻辑做保证。 最后给大家留个问题吧，mtr命令是怎么知道每一跳的IP地址的？ 参考资料《Linux 内核技术实战》– 极客时间 《云网络丢包故障定位全景指南》–极客重生 最后我一想到读者里还有不少兄弟还是单身，我就夜不能寐。 手心手背都是肉，一碗水要端平。 犹豫了很久，为她指了条明路。 “我读者里有很多微信不丢包的兄弟，他们都喜欢在我的文章底下点赞和再看。你可以考虑下他们” “还有经常在我评论区叫我靓仔的那些个兄弟，一看就是深情种，请重点考虑“。 只能帮到这里了，懂？ 我知道，这时候肯定就有兄弟要说我了，**”故事汇都不敢这么编！”** 嗯。 他们不敢，我敢。 别说了，一起在知识的海洋里呛水吧点击下方名片，关注公众号:【小白debug】 不满足于在留言区说骚话？ 加我，我们建了个划水吹牛皮群，在群里，你可以跟你下次跳槽可能遇到的同事或面试官聊点有意思的话题。就超！开！心！ 文章推荐： 程序员防猝死指南 TCP粘包 数据包：我只是犯了每个数据包都会犯的错 |硬核图解 动图图解！既然IP层会分片，为什么TCP层也还要分段？","categories":[{"name":"图解网络","slug":"图解网络","permalink":"https://xiaobaidebug.top/categories/%E5%9B%BE%E8%A7%A3%E7%BD%91%E7%BB%9C/"}],"tags":[]},{"title":"既然有HTTP协议，为什么还要有RPC","slug":"图解网络/既然有HTTP协议，为什么还要有RPC协议？","date":"2022-07-19T14:57:55.000Z","updated":"2022-10-30T02:47:53.292Z","comments":true,"path":"2022/07/19/图解网络/既然有HTTP协议，为什么还要有RPC协议？/","link":"","permalink":"https://xiaobaidebug.top/2022/07/19/%E5%9B%BE%E8%A7%A3%E7%BD%91%E7%BB%9C/%E6%97%A2%E7%84%B6%E6%9C%89HTTP%E5%8D%8F%E8%AE%AE%EF%BC%8C%E4%B8%BA%E4%BB%80%E4%B9%88%E8%BF%98%E8%A6%81%E6%9C%89RPC%E5%8D%8F%E8%AE%AE%EF%BC%9F/","excerpt":"","text":"文章持续更新，可以微信搜一搜「小白debug」第一时间阅读，回复【面试】获面试题集。本文已经收录在GitHub https://github.com/xiaobaiTech/golangFamily , 有大厂面试完整考点和成长路线，欢迎Star。 我想起了我刚工作的时候，第一次接触RPC协议，当时就很懵，我HTTP协议用的好好的，为什么还要用RPC协议？ 于是就到网上去搜。 不少解释显得非常官方，我相信大家在各种平台上也都看到过，解释了又好像没解释，都在用一个我们不认识的概念去解释另外一个我们不认识的概念，懂的人不需要看，不懂的人看了还是不懂。 这种看了，又好像没看的感觉，云里雾里的很难受，我懂。 为了避免大家有强烈的审丑疲劳，今天我们来尝试重新换个方式讲一讲。 从TCP聊起作为一个程序员，假设我们需要在A电脑的进程发一段数据到B电脑的进程，我们一般会在代码里使用socket进行编程。 这时候，我们可选项一般也就TCP和UDP二选一。TCP可靠，UDP不可靠。除非是马总这种神级程序员（早期QQ大量使用UDP），否则，只要稍微对可靠性有些要求，普通人一般无脑选TCP就对了。 类似下面这样。 1fd = socket(AF_INET,SOCK_STREAM,0); 其中SOCK_STREAM，是指使用字节流传输数据，说白了就是TCP协议。 在定义了socket之后，我们就可以愉快的对这个socket进行操作，比如用bind()绑定IP端口，用connect()发起建连。 在连接建立之后，我们就可以使用send()发送数据，recv()接收数据。 光这样一个纯裸的TCP连接，就可以做到收发数据了，那是不是就够了？ 不行，这么用会有问题。 使用纯裸TCP会有什么问题八股文常背，TCP是有三个特点，面向连接、可靠、基于字节流。 这三个特点真的概括的非常精辟，这个八股文我们没白背。 每个特点展开都能聊一篇文章，而今天我们需要关注的是基于字节流这一点。 字节流可以理解为一个双向的通道里流淌的数据，这个数据其实就是我们常说的二进制数据，简单来说就是一大堆 01 串。纯裸TCP收发的这些 01 串之间是没有任何边界的，你根本不知道到哪个地方才算一条完整消息。 正因为这个没有任何边界的特点，所以当我们选择使用TCP发送**”夏洛”和”特烦恼”的时候，接收端收到的就是“夏洛特烦恼”，这时候接收端没发区分你是想要表达“夏洛”+”特烦恼”还是“夏洛特”+”烦恼”**。 这就是所谓的粘包问题，之前也写过一篇专门的文章聊过这个问题。 说这个的目的是为了告诉大家，纯裸TCP是不能直接拿来用的，你需要在这个基础上加入一些自定义的规则，用于区分消息边界。 于是我们会把每条要发送的数据都包装一下，比如加入消息头，消息头里写清楚一个完整的包长度是多少，根据这个长度可以继续接收数据，截取出来后它们就是我们真正要传输的消息体。 而这里头提到的消息头，还可以放各种东西，比如消息体是否被压缩过和消息体格式之类的，只要上下游都约定好了，互相都认就可以了，这就是所谓的协议。 每个使用TCP的项目都可能会定义一套类似这样的协议解析标准，他们可能有区别，但原理都类似。 于是基于TCP，就衍生了非常多的协议，比如HTTP和RPC。 HTTP和RPC我们回过头来看网络的分层图。 TCP是传输层的协议，而基于TCP造出来的HTTP和各类RPC协议，它们都只是定义了不同消息格式的应用层协议而已。 HTTP协议（Hyper Text Transfer Protocol），又叫做超文本传输协议。我们用的比较多，平时上网在浏览器上敲个网址就能访问网页，这里用到的就是HTTP协议。 而RPC（Remote Procedure Call），又叫做远程过程调用。它本身并不是一个具体的协议，而是一种调用方式。 举个例子，我们平时调用一个本地方法就像下面这样。 1res = localFunc(req) 如果现在这不是个本地方法，而是个远端服务器暴露出来的一个方法remoteFunc，如果我们还能像调用本地方法那样去调用它，这样就可以屏蔽掉一些网络细节，用起来更方便，岂不美哉？ 1res = remoteFunc(req) 基于这个思路，大佬们造出了非常多款式的RPC协议，比如比较有名的gRPC，thrift。 值得注意的是，虽然大部分RPC协议底层使用TCP，但实际上它们不一定非得使用TCP，改用UDP或者HTTP，其实也可以做到类似的功能。 到这里，我们回到文章标题的问题。 既然有HTTP协议，为什么还要有RPC？ 其实，TCP是70年代出来的协议，而HTTP是90年代才开始流行的。而直接使用裸TCP会有问题，可想而知，这中间这么多年有多少自定义的协议，而这里面就有80年代出来的RPC。 所以我们该问的不是既然有HTTP协议为什么要有RPC，而是为什么有RPC还要有HTTP协议。 那既然有RPC了，为什么还要有HTTP呢？现在电脑上装的各种联网软件，比如xx管家，xx卫士，它们都作为客户端（client）需要跟服务端（server）建立连接收发消息，此时都会用到应用层协议，在这种**client/server (c/s)**架构下，它们可以使用自家造的RPC协议，因为它只管连自己公司的服务器就ok了。 但有个软件不同，浏览器（browser），不管是chrome还是IE，它们不仅要能访问自家公司的服务器（server），还需要访问其他公司的网站服务器，因此它们需要有个统一的标准，不然大家没法交流。于是，HTTP就是那个时代用于统一 browser/server (b/s) 的协议。 也就是说在多年以前，HTTP主要用于b/s架构，而RPC更多用于c/s架构。但现在其实已经没分那么清了，b/s和c/s在慢慢融合。很多软件同时支持多端，比如某度云盘，既要支持网页版，还要支持手机端和pc端，如果通信协议都用HTTP的话，那服务器只用同一套就够了。而RPC就开始退居幕后，一般用于公司内部集群里，各个微服务之间的通讯。 那这么说的话，都用HTTP得了，还用什么RPC？ 仿佛又回到了文章开头的样子，那这就要从它们之间的区别开始说起。 HTTP和RPC有什么区别我们来看看RPC和HTTP区别比较明显的几个点。 服务发现首先要向某个服务器发起请求，你得先建立连接，而建立连接的前提是，你得知道IP地址和端口。这个找到服务对应的IP端口的过程，其实就是服务发现。 在HTTP中，你知道服务的域名，就可以通过DNS服务去解析得到它背后的IP地址，默认80端口。 而RPC的话，就有些区别，一般会有专门的中间服务去保存服务名和IP信息，比如consul或者etcd，甚至是redis。想要访问某个服务，就去这些中间服务去获得IP和端口信息。由于dns也是服务发现的一种，所以也有基于dns去做服务发现的组件，比如CoreDNS。 可以看出服务发现这一块，两者是有些区别，但不太能分高低。 底层连接形式以主流的HTTP1.1协议为例，其默认在建立底层TCP连接之后会一直保持这个连接（keep alive），之后的请求和响应都会复用这条连接。 而RPC协议，也跟HTTP类似，也是通过建立TCP长链接进行数据交互，但不同的地方在于，RPC协议一般还会再建个连接池，在请求量大的时候，建立多条连接放在池内，要发数据的时候就从池里取一条连接出来，用完放回去，下次再复用，可以说非常环保。 由于连接池有利于提升网络请求性能，所以不少编程语言的网络库里都会给HTTP加个连接池，比如go就是这么干的。 可以看出这一块两者也没太大区别，所以也不是关键。 传输的内容基于TCP传输的消息，说到底，无非都是消息头header和消息体body。 header是用于标记一些特殊信息，其中最重要的是消息体长度。 body则是放我们真正需要传输的内容，而这些内容只能是二进制01串，毕竟计算机只认识这玩意。所以TCP传字符串和数字都问题不大，因为字符串可以转成编码再变成01串，而数字本身也能直接转为二进制。但结构体呢，我们得想个办法将它也转为二进制01串，这样的方案现在也有很多现成的，比如json，protobuf。 这个将结构体转为二进制数组的过程就叫序列化，反过来将二进制数组复原成结构体的过程叫反序列化。 对于主流的HTTP1.1，虽然它现在叫超文本协议，支持音频视频，但HTTP设计初是用于做网页文本展示的，所以它传的内容以字符串为主。header和body都是如此。在body这块，它使用json来序列化结构体数据。 我们可以随便截个图直观看下。 可以看到这里面的内容非常多的冗余，显得非常啰嗦。最明显的，像header里的那些信息，其实如果我们约定好头部的第几位是content-type，就不需要每次都真的把”content-type”这个字段都传过来，类似的情况其实在body的json结构里也特别明显。 而RPC，因为它定制化程度更高，可以采用体积更小的protobuf或其他序列化协议去保存结构体数据，同时也不需要像HTTP那样考虑各种浏览器行为，比如302重定向跳转啥的。因此性能也会更好一些，这也是在公司内部微服务中抛弃HTTP，选择使用RPC的最主要原因。 当然上面说的HTTP，其实特指的是现在主流使用的HTTP1.1，HTTP2在前者的基础上做了很多改进，所以性能可能比很多RPC协议还要好，甚至连gRPC底层都直接用的HTTP2。 那么问题又来了。 为什么既然有了HTTP2，还要有RPC协议？这个是由于HTTP2是2015年出来的。那时候很多公司内部的RPC协议都已经跑了好些年了，基于历史原因，一般也没必要去换了。 总结 纯裸TCP是能收发数据，但它是个无边界的数据流，上层需要定义消息格式用于定义消息边界。于是就有了各种协议，HTTP和各类RPC协议就是在TCP之上定义的应用层协议。 RPC本质上不算是协议，而是一种调用方式，而像gRPC和thrift这样的具体实现，才是协议，它们是实现了RPC调用的协议。目的是希望程序员能像调用本地方法那样去调用远端的服务方法。同时RPC有很多种实现方式，不一定非得基于TCP协议。 从发展历史来说，HTTP主要用于b/s架构，而RPC更多用于c/s架构。但现在其实已经没分那么清了，b/s和c/s在慢慢融合。很多软件同时支持多端，所以对外一般用HTTP协议，而内部集群的微服务之间则采用RPC协议进行通讯。 RPC其实比HTTP出现的要早，且比目前主流的HTTP1.1性能要更好，所以大部分公司内部都还在使用RPC。 HTTP2.0在HTTP1.1的基础上做了优化，性能可能比很多RPC协议都要好，但由于是这几年才出来的，所以也不太可能取代掉RPC。 最后留个问题吧，大家有没有发现，不管是HTTP还是RPC，它们都有个特点，那就是消息都是客户端请求，服务端响应。客户端没问，服务端肯定就不答，这就有点僵了，但现实中肯定有需要下游主动发送消息给上游的场景，比如打个网页游戏，站在那啥也不操作，怪也会主动攻击我，这种情况该怎么办呢？ 参考资料https://www.zhihu.com/question/41609070 最后按照惯例，我应该在这里唯唯诺诺的求大家叫我两声靓仔的。 但还是算了。因为我最近一直在想一个问题，希望兄弟们能在评论区告诉我答案。 最近手机借给别人玩了一下午，现在老是给我推荐练习时长两年半的练习生视频。 每个视频都在声嘶力竭的告诉我，鸡你太美。 所以我很想问，兄弟们。 鸡，到底美不美？ 头疼。 右下角的点赞和再看还是可以走一波的。 先这样。 我是小白，我们下期见。 别说了，一起在知识的海洋里呛水吧点击下方名片，关注公众号:【小白debug】 不满足于在留言区说骚话？ 加我，我们建了个划水吹牛皮群，在群里，你可以跟你下次跳槽可能遇到的同事或面试官聊点有意思的话题。就超！开！心！ 文章推荐： 程序员防猝死指南 TCP粘包 数据包：我只是犯了每个数据包都会犯的错 |硬核图解 动图图解！既然IP层会分片，为什么TCP层也还要分段？","categories":[{"name":"图解网络","slug":"图解网络","permalink":"https://xiaobaidebug.top/categories/%E5%9B%BE%E8%A7%A3%E7%BD%91%E7%BB%9C/"}],"tags":[]},{"title":"什么情况下你该考虑离职","slug":"程序人生/什么情况下你该考虑离职","date":"2022-07-04T14:57:55.000Z","updated":"2022-10-30T02:43:47.447Z","comments":true,"path":"2022/07/04/程序人生/什么情况下你该考虑离职/","link":"","permalink":"https://xiaobaidebug.top/2022/07/04/%E7%A8%8B%E5%BA%8F%E4%BA%BA%E7%94%9F/%E4%BB%80%E4%B9%88%E6%83%85%E5%86%B5%E4%B8%8B%E4%BD%A0%E8%AF%A5%E8%80%83%E8%99%91%E7%A6%BB%E8%81%8C/","excerpt":"","text":"文章持续更新，可以微信搜一搜「小白debug」第一时间阅读，回复【面试】获面试题集。本文已经收录在GitHub https://github.com/xiaobaiTech/golangFamily , 有大厂面试完整考点和成长路线，欢迎Star。 兄弟们！ 出来讲骚话啊。 大家都是打工人，尤其是我们互联网打工人，一般很少在一家公司待十年八年的。 一两年一跳很正常。 尤其是现在很多公司都没有普调，薪水入职即巅峰，所以在很长一段时间里，要涨薪只能靠跳槽，这话没啥毛病。 但问题来了。 什么情况下你该考虑离职？ 之前听马老师提到过，一般离职就两个原因，钱给少了和心受委屈了。 可以说概括的相当精辟了，但这个偏主观因素多一点。 今天我想说的是离职的第三个原因：见势不妙。这个偏客观因素多一点。 很多时候，如果业务越做越凉，是有迹可循的。今天我们就来沉浸式体验一下这个过程。 看完你大概能知道什么情况下你该考虑离职了。 业务起步很多公司在某些业务上小赚了一笔之后，都会考虑开辟新的业务线，以期待这个新的业务线会成为新的收入增长点。而这时候，老板们就会观察当前行业的风口，大一点的公司还会有专门的部门做各种研究。 在多次ppt会议之后，最后也不知道是谁成功忽悠了谁。总之，老板显得有些深思熟虑，并在ppt的某页上重点画了一个圈，你以为这是个重点经济增长圈？ 但其实，它只是个饼，圆一点的饼。 于是，一个新的业务线就这样，带着宏伟使命和伟大愿景来了。 干活，首先得先摇人，新的事业线放出了大量的HC（head count，人头数），那段时间，HR电话都打爆了。 而你也是在这次摇人中，加入到了这个具有伟大使命和宏大愿景的业务线里。 这之后，老板开了好几次动员会，一遍又一遍的重复着他做这番事业的初心，这个事情的社会价值，以及你们未来会是一个有多少万个小目标的公司。 老板这么说不要紧，那关键是你看到的网页新闻也是这么说。 公司放出更多HC疯狂扩招，显示出他们的决心。 各种晨会周会上，老板不断强调我们要加强内推，多搞点简历过来，太缺人了。 “这件事，太有搞头了！” 你心想，你就是下一个风口上的猪。闭上眼睛，你都能看到，自己以后跟各界互联网大佬手搭着肩，在ktv里哭着唱朋友一生一起走的画面了。 业务中期搞钱的事，怎么能在一棵树上干吊着呢？要多搞几棵树吊吊。 于是本着养蛊的思路，公司开了更多同类型的细分业务，比如教育还能细分为小学教育，初中教育，再细分还能分为语文数学英语。这时候你会发现，业务变得越来越多了，你手上的需求也越来越多了。 你每天都在多线程切换，除了写代码，等待你的还有开不完的会，搞不完的oncall，有时候新来的产品还会天真无邪的找你一对一咨询各种产品细节。白天一晃而过，晚上8点之后，你才能开始安心写代码。 在这种高压环境下待个一年，恍如隔世，照个镜子，原来人间已经过了三年。相对论诚不欺我，爱因斯坦棺材板的压不住了。 一般这种时候，你负责的老服务会越来越多，但新服务和新需求还在不停开发中。你在写新需求的同时还得处理各种老服务的问题和咨询。 产品开始吐槽你们开发越来越慢，为了加快需求的吞吐量，项目组从双周迭代改为了单周迭代。 这直接就是煽风点火了。 只要老服务出啥问题了，你原本绷紧的开发排期就得变得更脆。只要有一个需求延期了，那你后面就等着加班到天明吧。 很多项目在不断试错的过程中，过程中需要查看各种业务指标数据，产品、运营都会轮番要你写脚本算数据，只为说明他们拍大腿想出来的需求，是有数据支撑的，是reasonable的。 教育行业就更古怪，连教研老师都能给你提需求。 这种情况，在每个季度结束的时候会变得特别严重，你在用生命在为他们完成kpi，你可真是互联网活雷锋。 雷锋做好事还知道写日记，你做的这些个事情，到底要不要写进周报好呢？ 下班的路上，你拖着疲惫的身体，背着个电脑，开着小电瓶，在路灯的晃射下，你看到了路边的狗，你都一度怀疑，是不是连它，都能给你提需求。 你回想起，刚毕业的那会，那时候你虽然很穷，但你很快乐，现在不一样了，你还是很穷，但你不快乐了。 你总有开不完的会，做不完的需求，你一度想着要不离职算了。但每次这种时候，大老板就正好调整一波组织架构，然后发表下他这次调整架构的思考和决心，会议的最后再次回到诉说初心，然后展望愿景和理想的环节。 这是这一年里，第4次调整组织架构和方向了，你开始在想老板是不是连自己都没想清楚，但你看老板回答各种问题时，那笃定睿智的神情，你又感觉你行了，坚持下吧，说不定这次真的能行呢！ 业务后期古人说，公司内的消息要在公司外的八卦平台上才能看到。 古人诚不欺你，某天，你在某知名互联网茶水间app某脉上看到了自家公司正在裁员的消息，而裁员的对象，正好是你所在的业务线方向。 虽然身边陆续有同事在开始慢慢离职，之前合作对接过的几个开发老哥内部账号也变成了离职状态。 甚至连竞品的股价都开始在暴跌。 但你都没在意，因为你现在做的事情挺多的，哪有时间管这些。 唯一让你感到痛心疾首的是，坐门口的爱穿黑丝的小姐姐，突然有天也不见了。 那天傍晚，你的领导找组里的小伙伴们出去吃顿饭。吃到一半，你左手韭菜，右手羊腰子，领导却站起来说他要离职的事情，你突然愣神。反应过来时，大家正说着祝福的话，举起酒杯，好言相送，你看着杯子里的加多宝，又再一次陷入了慌神。 老领导走了，新领导上来第一件事就是盘点项目组的资源使用情况，每个服务使用了多少cpu和内存，能缩容就缩容。是的，他要搞降本提效。 降着降着，可能发现原来人才是最大的支出。于是你发现，不少业务线都消失了，不少人也走了。你手上接了越来越多别人交接过来的项目，从前五个人干的活，现在让你一个人干，你有些吃不消。老板说后面肯定会招人。但你很清楚，很长时间部门好像都没有面试了，以前周会每次都会提一下让大家内推一些简历，现在也不再提了。再后来，你听说业务线HC被锁了，不再招人，甚至连转岗都不让转了。 再后来，你发现业务的需求越来越少了，你以为终于可以闲下来摸鱼了，但这时候你的新领导开始推大家开始重构服务了，他说”之前我们跑太快了，一直在堆屎山，现在业务的活少了，正是我们重新思考架构，降本提效的好时候！”。 于是你们又开始了一轮新的折腾，你听老员工说: “以前完成业务的需求，给业务提供价值就是老板的KPI，那现在业务都没了，老板不折腾下重构，那哪来的kpi“。 知道真相的你眼泪掉下来。 这时候，你终于想走了，可一想到再坚持下就发年终奖了，这么辛苦都过来了，再忍几个月吧。 发年终奖可是个大开支啊，降本提效可是老板的kpi啊，于是你发现身边的同事慢慢变少。 直到那天你收到老板发来的消息：”空吗？我们来聊下绩效“。 如无意外，他觉得你绩效不好，要你签一份**PIP协议，你很清楚这玩意签了就等于承认自己不行，离职连N+x都没有**。但你也无力反抗，你很清楚什么叫”欲加之罪，何患无辞”。 什么时候该离职你开始脑袋放空，过往发生的每一件事都像碎片那样串联了起来。明明有那么多迹象告诉你，快跑。但你都视而不见。 “早知道我半年前就跑了” 可是问题来了。 如果再让你回到半年前，你身处在一个温水煮青蛙的环境，你怎么知道该不该跑。 我们重新梳理一遍过往发生的事情。 大环境舆论热议风口 → 开新业务，领导鼓励拉人内推 → 业务变多，开发很累但人员不断在补充 → 架构不断调整 → 工作主要以完成需求支持业务为主 → 大环境变差，政策变更，竞品或自家股票暴跌 → 业务可见的萎缩 ，不再强调内推 → 架构调整，信心鼓励 → 活很多，但就是不招人 → hc锁死，人员只出不进→ 领导跑路，换新领导 → 资源盘点，提倡降本提效 → 业务量变少，重构之类的活排上日程 → 身边的人陆续离职 → 年终奖将近，身边出现大批人员离职 → 轮到你了 → 留下来的人接手离职人员的活，过得更苦了 → 团队裁员或部门打包转岗。 这里其实涉及到一个业务线从0到0.7再到0的完整过程，任何一个时间节点，在会议上都是一片欣欣向荣的场面，就算是最后团队裁员，说的也是充满信心的话。 但你不必看老板们说什么，你看老板们做什么就够了，行动永远比话语诚实。 公司业务组织架构疯狂调整，一年能折腾个三四次，说明老板都没想清楚一件事要怎么做，所以想要拍大腿疯狂试错。不赚钱的业务才会不断折腾，赚钱的业务永远以稳定盈利为主要目标。这时候你就该明白这个业务线大概率不太能做出来了，如果你加入这个公司的目的是妄想暴富的话，那该醒过来了，该考虑刷题了。 领导离职。这个要分情况，如果项目赚钱了，那可能只是宫斗，这种情况不考虑。但如果是不赚钱的项目，不管是领导是主动还是被动离职，这都不是什么好事情。如果是主动离职，如果一件事有搞头，你会想要跑吗？领导永远比你更接近第一手消息，而且能做到领导位置，那肯定目光和判断力要比你更强，连他都觉得没搞头，那你还不快跑？被动离职，这个更明显，搞事业，最忌讳中途换帅，但凡有点希望，也不至于这么搞。这时候你该明白，老板的老板已经慢慢失去耐心。这时候，八股文该背起来了。 HC锁死，说明从公司层面上，就不会再继续加大投入人力，对这个业务已经慢慢失去信心。如果现在离年终奖还远，简历改起来啊，你该考虑转岗或跑路了。 锁死转岗，这种时候多发生在后半年，大部分有求生经验的人，不想失去年终奖，于是选择活水到其他业务线，这样还能保住年终奖，走不走明年再做打算。但这样的转岗太多了，会导致原来就可能要凉的业务线凉的更快，于是大老板就会选择冻结转岗。这时候如果离年终还远，那球球了，投简历吧。如果临近年终，那我劝你苟住，但如果不得不得跑，对面公司出于人道主义关怀，可能会有一笔签字费作为损失年终奖的激励or补偿，记得谈一谈。 如果你在转岗锁死前，能成功转岗或离职，那你一般损失会小一些。在这之后，走运些的老哥能被辞退拿个N+X赔偿，体面离开，但这个纯纯看运气。不走运的，等待你的只有超多离职老哥留下的活，以及老板的PUA或PIP关怀套餐。 最后我之前写过一篇关于PIP的文章，发在了某乎上，让我意外的是，最近时不时会有老哥看到后私信问我该怎么办，貌似最近大行情变差了，用这种方式劝退的公司越来越多了。 这是个屁股决定脑袋的世界，在老板视角里，用pip劝退员工可以省下赔款，如果他不能辞退足够多的人，他的绩效和年终就不好看，自己的利益当然比他人的利益重要。在员工视角里，用pip劝退员工的老板真实丧良心，但记住，没有人可以逼你签任何协议。大家做的都没错，都是各自系统的最优解。 很多行业，你去之前都说是风口，去了之后就凉了，你以为你拿的是主角的剧本，结果连跑龙套都算不上。你也不想当行业冥灯，可人生如戏。 还真是应了《桃花扇》里的那句唱词 “眼看他起高楼，眼看他宴宾客，眼看他楼塌了”。 深夜网抑云，破防了兄弟们。 但发牢骚并不能解决问题，该想想自己能从这次经历中学到什么？ 一个要凉的业务，它总是会有一些苗头和规律的。今天这篇文章就是讲的这个，不过我相信，就算我告诉你，你也不会信的，每个人都总觉得自己是例外，每个人都觉得自己不会在厕所里边吃边哭。 就像每个舔狗追女神的时候，总感觉自己在她心里是不一样的。这里涉及到一个叫沉没成本的概念，不再展开。 你执意要去山的对面看看海，我很想告诉你山的对面没有海，但我知道，就算我说了，你也是不会信的，你需要亲自去看看。 多说两句按照惯例，我应该在这里唯唯诺诺的求大家叫我两声靓仔的。 但我今天不想。 点一个赞，愿世界和平。 点一个在看，愿所有的伤痛都由发pip的那个人承担。 我是小白，我们下期见。 别说了，一起在知识的海洋里呛水吧点击下方名片，关注公众号:【小白debug】 不满足于在留言区说骚话？ 加我，我们建了个划水吹牛皮群，在群里，你可以跟你下次跳槽可能遇到的同事或面试官聊点有意思的话题。就超！开！心！ 文章推荐： 程序员防猝死指南 TCP粘包 数据包：我只是犯了每个数据包都会犯的错 |硬核图解 动图图解！既然IP层会分片，为什么TCP层也还要分段？","categories":[{"name":"骚话连篇","slug":"骚话连篇","permalink":"https://xiaobaidebug.top/categories/%E9%AA%9A%E8%AF%9D%E8%BF%9E%E7%AF%87/"}],"tags":[]},{"title":"为什么mysql的count()方法这么慢？","slug":"图解mysql/为什么mysql的count()方法这么慢？","date":"2022-06-30T14:57:55.000Z","updated":"2022-10-30T02:50:37.183Z","comments":true,"path":"2022/06/30/图解mysql/为什么mysql的count()方法这么慢？/","link":"","permalink":"https://xiaobaidebug.top/2022/06/30/%E5%9B%BE%E8%A7%A3mysql/%E4%B8%BA%E4%BB%80%E4%B9%88mysql%E7%9A%84count()%E6%96%B9%E6%B3%95%E8%BF%99%E4%B9%88%E6%85%A2%EF%BC%9F/","excerpt":"","text":"文章持续更新，可以微信搜一搜「小白debug」第一时间阅读，回复【面试】获面试题集。本文已经收录在GitHub https://github.com/xiaobaiTech/golangFamily , 有大厂面试完整考点和成长路线，欢迎Star。 兄弟们。 浅浅的炫个富吧。 说出来你们可能不信。 手机你们有吗？我有。 短信，知道吧？一条一毛钱，我天天发。 你敢想吗？ 所以说，年轻人，有钱是真的好。 今天，我们就以短信为话题聊起。 短信，它又叫SMS。 比如说，你有一张**短信表(sms)**，里面放了各种需要发送的短信信息。 需要注意的是state字段，为0的时候说明这时候短信还未发送。 此时还会有一个异步线程不断的捞起未发送（state=0）的短信数据，执行发短信操作，发送成功之后state字段会被置为1（已发送）。也就是说未发送的数据会不断变少。 假设由于某些原因，你现在需要做一些监控，比如监控的内容是，你的sms数据表里还有没有state=0（未发送）的短信，方便判断一下堆积的未发送短信大概在什么样的一个量级。 为了获取满足某些条件的行数是多少，我们一般会使用count()方法。 这时候为了获取未发送的短信数据，我们很自然就想到了使用下面的sql语句进行查询。 1select count(*) from sms where state = 0; 然后再把获得数据作为打点发给监控服务。 当数据表小的时候，这是没问题的，但当数据量大的时候，比如未发送的短信到了百万量级的时候，你就会发现，上面的sql查询时间会变得很长，最后timeout报错，查不出结果了。 为什么？ 我们先从count()方法的原理聊起。 count()的原理count()方法的目的是计算当前sql语句查询得到的非NULL的行数。 我们知道mysql是分为server层和存储引擎层的。 存储引擎层里可以选择各种引擎进行存储，最常见的是innodb、myisam。具体使用哪个存储引擎，可以通过建表sql里的ENGINE字段进行指定。比如这篇文章开头的建表sql里用了ENGINE=InnoDB，那这张表用的就是innodb引擎。 虽然在server层都叫count()方法，但在不同的存储引擎下，它们的实现方式是有区别的。 比如同样是读全表数据 select count(*) from sms；语句。 使用 myisam引擎的数据表里有个记录当前表里有几行数据的字段，直接读这个字段返回就好了，因此速度快得飞起。 而使用innodb引擎的数据表，则会选择体积最小的索引树，然后通过遍历叶子节点的个数挨个加起来，这样也能得到全表数据。 因此回到文章开头的问题里，当数据表行数变大后，单次count就需要扫描大量的数据，因此很可能就会出现超时报错。 那么问题就来了。 为什么innodb不能像myisam那样实现count()方法myisam和innodb这两个引擎，有几个比较明显的区别，这个是八股文常考了。 其中最大的区别在于myisam不支持事务，而innodb支持事务。 而事务，有四层隔离级别，其中默认隔离级别就是可重复读隔离级别（RR）。 innodb引擎通过MVCC实现了可重复隔离级别，事务开启后，多次执行同样的select快照读，要能读到同样的数据。 于是我们看个例子。 对于两个事务A和B，一开始sms表假设就2条数据，那事务A一开始确实是读到2条数据。事务B在这期间插入了1条数据，按道理数据库其实有3条数据了，但由于可重复读的隔离级别，事务A依然还是只能读到2条数据。 因此由于事务隔离级别的存在，不同的事务在同一时间下，看到的表内数据行数是不一致的，因此innodb，没办法，也没必要像myisam那样单纯的加个count字段信息在数据表上。 那如果不可避免要使用count()，有没有办法让它快一点？ 各种count()方法的原理count()的括号里，可以放各种奇奇怪怪的东西，想必大家应该看过，比如放个星号*，放个1，放个索引列啥的。 我们来分析下他们的执行流程。 count方法的大原则是server层会从innodb存储引擎里读来一行行数据，并且只累计非null的值。但这个过程，根据count()方法括号内的传参，有略有不同。 count(*)server层拿到innodb返回的行数据，不对里面的行数据做任何解析和判断，默认取出的值肯定都不是null，直接行数+1。 count(1)server层拿到innodb返回的行数据，每行放个1进去，默认不可能为null，直接行数+1. count(某个列字段)由于指明了要count某个字段，innodb在取数据的时候，会把这个字段解析出来返回给server层，所以会比count(1)和count(*)多了个解析字段出来的流程。 如果这个列字段是主键id，主键是不可能为null的，所以server层也不用判断是否为null，innodb每返回一行，行数结果就+1. 如果这个列是普通索引字段，innodb一般会走普通索引，每返回一行数据，server层就会判断这个字段是否为null，不是null的情况下+1。当然如果建表sql里字段定义为not null的话，那就不用做这一步判断直接+1。 如果这个列没有加过索引，那innodb可能会全表扫描，返回的每一行数据，server层都会判断这个字段是否为null，不是null的情况下+1。同上面的情况一样，字段加了not null也就省下这一步判断了。 理解了原理后我们大概可以知道他们的性能排序是 1count(*) ≈ count(1) &gt; count(主键id) &gt; count(普通索引列) &gt; count(未加索引列) 所以说count(*)，已经是最快的了。 知道真相的我眼泪掉下来。 那有没有其他更好的办法？ 允许粗略估计行数的场景我们回过头来细品下文章开头的需求，我们只是希望知道数据库里还有多少短信是堆积在那没发的，具体是1k还是2k其实都是差不多量级，等到了百万以上，具体数值已经不重要了，我们知道它现在堆积得很离谱，就够了。 因此这个场景，其实是允许使用比较粗略的估计的。 那怎么样才能获得粗略的数值呢？ 还记得我们平时为了查看sql执行计划用的explain命令不。 其中有个rows，会用来估计接下来执行这条sql需要扫描和检查多少行。它是通过采样的方式计算出来的，虽然会有一定的偏差，但它能反映一定的数量级。 有些语言的orm里可能没有专门的explain语法，但是肯定有执行raw sql的功能，你可以把explain语句当做raw sql传入，从返回的结果里将rows那一列读出来使用。 一般情况下，explain的sql如果能走索引，那会比不走索引的情况更准 。单个字段的索引会比多个字段组成的复合索引要准。索引区分度越高，rows的值也会越准。 这种情况几乎满足大部分的监控场景。但总有一些场景，它要求必须得到精确的行数，这种情况该怎么办呢？ 必须精确估计行数的场景这种场景就比较头疼了，但也不是不能做。 我们可以单独拉一张新的数据库表，只为保存各种场景下的count。 1234567CREATE TABLE `count_table` ( `id` int NOT NULL AUTO_INCREMENT COMMENT &#x27;主键&#x27;, `cnt_what` char(20) NOT NULL DEFAULT &#x27;&#x27; COMMENT &#x27;各种需要计算的指标&#x27;, `cnt` tinyint NOT NULL COMMENT &#x27;cnt指标值&#x27;, PRIMARY KEY (`id`), KEY `idx_cnt_what` (`cnt_what`)) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4; 当需要获取某个场景下的cout值时，可以使用下面的sql进行直接读取，快得飞起。 1select cnt from count_table where cnt_what = &quot;未发送的短信数量&quot;; 那这些count的结果值从哪来呢？ 这里分成两种情况。 实时性要求较高的场景如果你对这个cnt计算结果的实时性要求很高，那你需要将更新cnt的sql加入到对应变更行数的事务中。 比如我们有两个事务A和B，分别是增加未发送短信和减少未发送短信。 这样做的好处是事务内的cnt行数依然符合隔离级别，事务回滚的时候，cnt的值也会跟着回滚。 坏处也比较明显，多个线程对同一个cnt进行写操作，会触发悲观锁，多个线程之间需要互相等待。对于高频写的场景，性能会有折损。 实时性没那么高的场景如果实时性要求不高的话，比如可以一天一次，那你可以通过全表扫描后做计算。 举个例子，比如上面的短信表，可以按id排序，每次取出1w条数据，记下这一批里最大的id，然后下次从最大id开始再拿1w条数据出来，不断循环。 对于未发送的短信，就只需要在捞出的那1w条数据里，筛选出state=0的条数。 当然如果有条件，这种场景最好的方式还是消费binlog将数据导入到hive里，然后在hive里做查询，不少公司也已经有现成的组件可以做这种事情，不用自己写脚本，岂不美哉。 总结 mysql用count方法查全表数据，在不同的存储引擎里实现不同，myisam有专门字段记录全表的行数，直接读这个字段就好了。而innodb则需要一行行去算。 性能方面 count(*) ≈ count(1) &gt; count(主键id) &gt; count(普通索引列) &gt; count(未加索引列)，但哪怕是性能最好的count(*)，由于实现上就需要一行行去算，所以数据量大的时候就是不给力。 如果确实需要获取行数，且可以接受不那么精确的行数（只需要判断大概的量级）的话，那可以用explain里的rows，这可以满足大部分的监控场景，实现简单。 如果要求行数准确，可以建个新表，里面专门放表行数的信息。 如果对实时性要求比较高的话，可以将更新行数的sql放入到对应事务里，这样既能满足事务隔离性，还能快速读取到行数信息。 如果对实时性要求不高，接受一小时或者一天的更新频率，那既可以自己写脚本遍历全表后更新行数信息。也可以将通过监听binlog将数据导入hive，需要数据时直接通过hive计算得出。 参考资料《丁奇mysql45讲》 最后兄弟们，最近有点没出息，沉迷在刘亦菲的新剧里，都快忘了写文这件事了。 按照惯例，我应该在这里唯唯诺诺的求大家叫我两声靓仔的。 但今天，我感觉我不配。 所以先这样。 但右下角的点赞和再看还是可以走一波的。 我是小白，我们下期见。 别说了，一起在知识的海洋里呛水吧点击下方名片，关注公众号:【小白debug】 不满足于在留言区说骚话？ 加我，我们建了个划水吹牛皮群，在群里，你可以跟你下次跳槽可能遇到的同事或面试官聊点有意思的话题。就超！开！心！ 文章推荐： 程序员防猝死指南 TCP粘包 数据包：我只是犯了每个数据包都会犯的错 |硬核图解 动图图解！既然IP层会分片，为什么TCP层也还要分段？","categories":[{"name":"图解mysql","slug":"图解mysql","permalink":"https://xiaobaidebug.top/categories/%E5%9B%BE%E8%A7%A3mysql/"}],"tags":[]},{"title":"数据库主键一定要自增的吗？有哪些场景下不建议自增？","slug":"图解mysql/数据库主键一定要自增的吗？不自增行不行？有哪些场景下不建议自增？","date":"2022-06-14T14:57:55.000Z","updated":"2022-10-30T02:44:18.870Z","comments":true,"path":"2022/06/14/图解mysql/数据库主键一定要自增的吗？不自增行不行？有哪些场景下不建议自增？/","link":"","permalink":"https://xiaobaidebug.top/2022/06/14/%E5%9B%BE%E8%A7%A3mysql/%E6%95%B0%E6%8D%AE%E5%BA%93%E4%B8%BB%E9%94%AE%E4%B8%80%E5%AE%9A%E8%A6%81%E8%87%AA%E5%A2%9E%E7%9A%84%E5%90%97%EF%BC%9F%E4%B8%8D%E8%87%AA%E5%A2%9E%E8%A1%8C%E4%B8%8D%E8%A1%8C%EF%BC%9F%E6%9C%89%E5%93%AA%E4%BA%9B%E5%9C%BA%E6%99%AF%E4%B8%8B%E4%B8%8D%E5%BB%BA%E8%AE%AE%E8%87%AA%E5%A2%9E%EF%BC%9F/","excerpt":"","text":"文章持续更新，可以微信搜一搜「小白debug」第一时间阅读，回复【面试】获面试题集。本文已经收录在GitHub https://github.com/xiaobaiTech/golangFamily , 有大厂面试完整考点和成长路线，欢迎Star。 我们平时建表的时候，一般会像下面这样。 12345CREATE TABLE `user` ( `id` int NOT NULL AUTO_INCREMENT COMMENT &#x27;主键&#x27;, `name` char(10) NOT NULL DEFAULT &#x27;&#x27; COMMENT &#x27;名字&#x27;, PRIMARY KEY (`id`)) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4; 出于习惯，我们一般会加一列id作为主键，而这个主键一般边上都有个AUTO_INCREMENT, 意思是这个主键是自增的。自增就是i++，也就是每次都加1。 但问题来了。 主键id不自增行不行？ 为什么要用自增id做主键？ 离谱点，没有主键可以吗？ 什么情况下不应该自增？ 被这么一波追问，念头都不通达了？ 这篇文章，我会尝试回答这几个问题。 主键不自增行不行当然是可以的。比如我们可以把建表sql里的AUTO_INCREMENT去掉。 12345CREATE TABLE `user` ( `id` int NOT NULL COMMENT &#x27;主键&#x27;, `name` char(10) NOT NULL DEFAULT &#x27;&#x27; COMMENT &#x27;名字&#x27;, PRIMARY KEY (`id`)) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4; 然后执行 1INSERT INTO `user` (`name`) VALUES (&#x27;debug&#x27;); 这时候会报错Field &#39;id&#39; doesn&#39;t have a default value。也就是说如果你不让主键自增的话，那你在写数据的时候需要自己指定id的值是多少，想要主键id是多少就写多少进去，不写就报错。 改成下面这样就好了 1INSERT INTO `user` (`id`,`name`) VALUES (10, &#x27;debug&#x27;); 为什么要用自增主键我们在数据库里保存的数据就跟excel表一样，一行行似的。 而在底层，这一行行数据，就是保存在一个个16k大小的页里。 每次都去遍历所有的行性能会不好，于是为了加速搜索，我们可以根据主键id，从小到大排列这些行数据，将这些数据页用双向链表的形式组织起来，再将这些页里的部分信息提取出来放到一个新的16kb的数据页里，再加入层级的概念。于是，一个个数据页就被组织起来了，成为了一棵B+树索引。 而当我们在建表sql里声明了PRIMARY KEY (id)时，mysql的innodb引擎，就会为主键id生成一个主键索引，里面就是通过B+树的形式来维护这套索引。 到这里，我们有两个点是需要关注的： 数据页大小是固定16k 数据页内，以及数据页之间，数据主键id都是从小到大排序的 由于数据页大小固定了是16k，当我们需要插入一条新的数据，数据页会被慢慢放满，当超过16k时，这个数据页就有可能会进行分裂。 针对B+树叶子节点，如果主键是自增的，那它产生的id每次都比前一次要大，所以每次都会将数据加在B+树尾部，B+树的叶子节点本质上是双向链表，查找它的首部和尾部，**时间复杂度O(1)**。而如果此时最末尾的数据页满了，那创建个新的页就好。 如果主键不是自增的，比方说上次分配了id=7，这次分配了id=3，为了让新加入数据后B+树的叶子节点还能保持有序，它就需要往叶子结点的中间找，查找过程的时间复杂度是O(lgn)，如果这个页正好也满了，这时候就需要进行页分裂了。并且页分裂操作本身是需要加悲观锁的。总体看下来，自增的主键遇到页分裂的可能性更少，因此性能也会更高。 没有主键可以吗mysql表如果没有主键索引，查个数据都得全表扫描，那既然它这么重要，我今天就不当人了，不声明主键，可以吗？ 嗯，你完全可以不声明主键。 你确实可以在建表sql里写成这样。 123CREATE TABLE `user` ( `name` char(10) NOT NULL DEFAULT &#x27;&#x27; COMMENT &#x27;名字&#x27;) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4; 看起来确实是没有主键的样子。然而实际上，mysql的innodb引擎内部会帮你生成一个名为ROW_ID列，它是个6字节的隐藏列，你平时也看不到它，但实际上，它也是自增的。有了这层兜底机制保证，数据表肯定会有主键和主键索引。 跟ROW_ID被隐藏的列还有trx_id字段，用于记录当前这一行数据行是被哪个事务修改的，和一个roll_pointer字段，这个字段是用来指向当前这个数据行的上一个版本，通过这个字段，可以为这行数据形成一条版本链，从而实现多版本并发控制（MVCC）。有没有很眼熟，这个在之前写的文章里出现过。 有没有建议主键不自增的场景前面提到了主键自增可以带来很多好处，事实上大部分场景下，我们都建议主键设为自增。 那有没有不建议主键自增的场景呢？ mysql分库分表下的id聊到分库分表，那我就需要说明下，递增和自增的区别了，自增就是每次都+1，而递增则是新的id比上一个id要大就行了，具体大多少，没关系。 之前写过一篇文章提到过，mysql在水平分库分表时，一般有两种方式。 一种分表方式是通过对id取模进行分表，这种要求递增就好，不要求严格自增，因为取模后数据会被分散到多个分表中，就算id是严格自增的，在分散之后，都只能保证每个分表里id只能是递增的。 另一种分表方式是根据id的范围进行分表（分片），它会划出一定的范围，比如以2kw为一个分表的大小，那02kw就放在这张分表中，2kw4kw放在另一张分表中，数据不断增加，分表也可以不断增加，非常适合动态扩容，但它要求id自增，如果id递增，数据则会出现大量空洞。举个例子，比如第一次分配id=2，第二次分配id=2kw，这时候第一张表的范围就被打满了，后面再分配一个id，比如是3kw，就只能存到2kw4kw（第二张）的分表中。那我在02kw这个范围的分表，也就存了两条数据，这太浪费了。 但不管哪种分表方式，一般是不可能继续用原来表里的自增主键的，原因也比较好理解，原来的每个表如果都从0开始自增的话，那好几个表就会出现好几次重复的id，根据id唯一的原则，这显然不合理。 所以我们在分库分表的场景下，插入的id都是专门的id服务生成的，如果是要严格自增的话，那一般会通过redis来获得，当然不会是一个id请求获取一次，一般会按批次去获得，比如一次性获得100个。快用完了再去获取下一批100个。 但这个方案有个问题，它严重依赖redis，如果redis挂了，那整个功能就傻了。 有没有不依赖于其他第三方组件的方法呢？ 雪花算法有，比如Twitter开源的雪花算法。 雪花算法通过64位有特殊含义的数字来组成id。 首先第0位不用。 接下来的41位是时间戳。精度是毫秒，这个大小大概能表示个69年左右，因为时间戳随着时间流逝肯定是越来越大的，所以这部分决定了生成的id肯定是越来越大的。 再接下来的10位是指产生这些雪花算法的工作机器id，这样就可以让每个机器产生的id都具有相应的标识。 再接下来的12位，序列号，就是指这个工作机器里生成的递增数字。 可以看出，只要处于同一毫秒内，所有的雪花算法id的前42位的值都是一样的，因此在这一毫秒内，能产生的id数量就是 2的10次方✖️2的12次方，大概400w，肯定是够用了，甚至有点多了。 但是！ 细心的兄弟们肯定也发现了，雪花算法它算出的数字动不动就比上次的数字多个几百几万的，也就是它生成的id是趋势递增的，并不是严格**+1自增**的，也就是说它并不太适合于根据范围来分表的场景。这是个非常疼的问题。 还有个小问题是，那10位工作机器id，我每次扩容一个工作机器，这个机器怎么知道自己的id是多少呢？是不是得从某个地方读过来。 那有没有一种生成id生成方案，既能让分库分表能做到很好的支持动态扩容，又能像雪花算法那样并不依赖redis这样的第三方服务。 有。这就是这篇文章的重点了。 适合分库分表的uuid算法我们可以参考雪花算法的实现，设计成下面这样。注意下面的每一位，都是十进制，而不是二进制。 开头的12位依然是时间，但并不是时间戳，雪花算法的时间戳精确到毫秒，我们用不上这么细，我们改为yyMMddHHmmss，注意开头的yy是两位，也就是这个方案能保证到2099年之前，id都不会重复，能用到重复，那也是真·百年企业。同样由于最前面是时间，随着时间流逝，也能保证id趋势递增。 接下来的10位，用十进制的方式表示工作机器的ip，就可以把12位的ip转为10位的数字，它可以保证全局唯一，只要服务起来了，也就知道自己的ip是多少了，不需要像雪花算法那样从别的地方去读取worker id了，又是一个小细节。 在接下来的6位，就用于生成序列号，它能支持每秒钟生成100w个id。 最后的4位，也是这个id算法最妙的部分。它前2位代表分库id，后2位代表分表id。也就是支持一共100*100=1w张分表。 举个例子，假设我只用了1个分库，当我一开始只有3张分表的情况下，那我可以通过配置，要求生成的uuid最后面的2位，取值只能是[0,1,2]，分别对应三个表。这样我生成出来的id，就能非常均匀的落到三个分表中，这还顺带解决了单个分表热点写入的问题。 如果随着业务不断发展，需要新加入两张新的表(3和4)，同时第0张表有点满了，不希望再被写了，那就将配置改为[1,2,3,4]，这样生成的id就不会再插入到对应的0表中。同时还可以加入生成id的概率和权重来调整哪个分表落更多数据。 有了这个新的uuid方案，我们既可以保证生成的数据趋势递增，同时也能非常方便扩展分表。非常nice。 数据库有那么多种，mysql只是其中一种，那其他数据库也是要求主键自增吗？ tidb的主键id不建议自增tidb是一款分布式数据库，作为mysql分库分表场景下的替代产品，可以更好的对数据进行分片。 它通过引入Range的概念进行数据表分片，比如第一个分片表的id在02kw，第二个分片表的id在2kw4kw。这其实就是根据id范围进行数据库分表。 它的语法几乎跟mysql一致，用起来大部分时候是无感的。 但跟mysql有一点很不一样的就是，mysql建议id自增，但tidb却建议使用随机的uuid。原因是如果id自增的话，根据范围分片的规则，一段时间内生成的id几乎都会落到同一个分片上，比如下图，从3kw开始的自增uuid，几乎都落到range 1这个分片中，而其他表却几乎不会有写入，性能没有被利用起来。出现一表有难，多表围观的场面，这种情况又叫写热点问题。 所以为了充分的利用多个分表的写入能力，tidb建议我们写入时使用随机id，这样数据就能被均匀分散到多个分片中。 用户id不建议用自增id前面提到的不建议使用自增id的场景，都是技术原因导致的，而下面介绍的这个，单纯是因为业务。 举个例子吧。 如果你能知道一个产品每个月，新增的用户数有多少，这个对你来说会是有用的信息吗？ 对程序员来说，可能这个信息价值不大。 但如果你是做投资的呢，或者是分析竞争对手呢？ 那反过来。 如果你发现你的竞争对手，总能非常清晰的知道你的产品每个月新进的注册用户是多少人，你会不会心里毛毛的？ 如果真出现了这问题，先不要想是不是有内鬼，先检查下你的用户表主键是不是自增的。 如果用户id是自增的，那别人只要每个月都注册一个新用户，然后抓包得到这个用户的user_id，然后跟上个月的值减一下，就知道这个月新进多少用户了。 同样的场景有很多，有时候你去小店吃饭，发票上就写了你是今天的第几单，那大概就能估计今天店家做了多少单。你是店家，你心里也不舒服吧。 再比如说一些小app的商品订单id，如果也做成自增的，那就很容易可以知道这个月成了多少单。 类似的事情有很多，这些场景都建议使用趋势递增的uuid作为主键。 当然，主键保持自增，但是不暴露给前端，那也行，那前面的话，你当我没说过。 总结 建表sql里主键边上的AUTO_INCREMENT，可以让主键自增，去掉它是可以的，但这就需要你在insert的时候自己设置主键的值。 建表sql里的 PRIMARY KEY 是用来声明主键的，如果去掉，那也能建表成功，但mysql内部会给你偷偷建一个 ROW_ID的隐藏列作为主键。 由于mysql使用B+树索引，叶子节点是从小到大排序的，如果使用自增id做主键，这样每次数据都加在B+树的最后，比起每次加在B+树中间的方式，加在最后可以有效减少页分裂的问题。 在分库分表的场景下，我们可以通过redis等第三方组件来获得严格自增的主键id。如果不想依赖redis，可以参考雪花算法进行魔改，既能保证数据趋势递增，也能很好的满足分库分表的动态扩容。 并不是所有数据库都建议使用自增id作为主键，比如tidb就推荐使用随机id，这样可以有效避免写热点的问题。而对于一些敏感数据，比如用户id，订单id等，如果使用自增id作为主键的话，外部通过抓包，很容易可以知道新进用户量，成单量这些信息，所以需要谨慎考虑是否继续使用自增主键。 最后我比较记仇，最近有不少兄弟们在评论区叫我diao毛。 我都记住了。 但是，只要兄弟们还能给右下角的点赞和在看来上那么一下的话。 我觉得，这口气，也不是不能忍。 按照惯例，我应该在这里唯唯诺诺的求大家叫我两声靓仔的。 但我今天不想。 所以先这样。 我是小白，我们下期见。 别说了，一起在知识的海洋里呛水吧点击下方名片，关注公众号:【小白debug】 不满足于在留言区说骚话？ 加我，我们建了个划水吹牛皮群，在群里，你可以跟你下次跳槽可能遇到的同事或面试官聊点有意思的话题。就超！开！心！ 文章推荐： 程序员防猝死指南 TCP粘包 数据包：我只是犯了每个数据包都会犯的错 |硬核图解 动图图解！既然IP层会分片，为什么TCP层也还要分段？","categories":[{"name":"图解mysql","slug":"图解mysql","permalink":"https://xiaobaidebug.top/categories/%E5%9B%BE%E8%A7%A3mysql/"}],"tags":[]},{"title":"如何调用一个只支持batch_call的服务？","slug":"golang面试题/如何调用一个只支持batch_call的服务？","date":"2022-06-09T14:57:55.000Z","updated":"2022-10-30T02:34:18.768Z","comments":true,"path":"2022/06/09/golang面试题/如何调用一个只支持batch_call的服务？/","link":"","permalink":"https://xiaobaidebug.top/2022/06/09/golang%E9%9D%A2%E8%AF%95%E9%A2%98/%E5%A6%82%E4%BD%95%E8%B0%83%E7%94%A8%E4%B8%80%E4%B8%AA%E5%8F%AA%E6%94%AF%E6%8C%81batch_call%E7%9A%84%E6%9C%8D%E5%8A%A1%EF%BC%9F/","excerpt":"","text":"文章持续更新，可以微信搜一搜「小白debug」第一时间阅读，回复【教程】获golang免费视频教程。本文已经收录在GitHub https://github.com/xiaobaiTech/golangFamily , 有大厂面试完整考点和成长路线，欢迎Star。 我们先来说下标题是什么意思。 为了更好的理解我说的是啥，我们来举个例子。 假设你现在在做一个类似B站的系统，里面放了各种视频。 用户每天在里头上传各种视频。 按理说每个视频都要去审查一下有没有搞颜色，但总不能人眼挨个看吧。 毕竟唐老哥表示这玩意看多了，看太阳都是绿色的，所以会有专门训练过的算法服务去做检测。 但也不能上来就整个视频每一帧都拿去做审查吧，所以会在每个视频里根据时长和视频类型随机抽出好几张图片去做审查，比如视频标签是美女的，算法爱看，那多抽几张。标签是编程的，狗都不看，就少抽几张。 将这些抽出来的图片，送去审查。 为了实现这个功能，我们会以视频为维度去做审核，而每个视频里都会有N张数量不定的图片，下游服务是个使用GPU去检测图片的算法服务。 现在问题来了，下游服务的算法开发告诉你，这些个下游服务，它不支持很高的并发，但请求传参里给你加了个数组，你可以批量（batch）传入一个比较大的图片数组，通过这个方式可以提升点图片处理量。 于是，我们的场景就变成。 上游服务的入参是一个视频和它的N张图片，出参是这个视频是否审核通过。 下游服务的入参是N张图片的，出参是这个视频是否审核通过。 现在我们想要用上游服务接入下游服务。该怎么办？ 看上去挺好办的，一把梭不就完事了吗？ 当一个视频进来，就拿着视频的十多张图片作为一个batch去进行调用。 有几个视频进来，就开几个这样的并发。 这么做的结果就是，当并发大一点时，你会发现性能很差，并且性能非常不稳定，比如像下面的监控图一样一会3qps，一会15qps。处理的图片也只支持20qps左右。 狗看了都得摇头。 这可如何是好？ 为什么下游需要batch call本着先问是不是，再问为什么的精神，我们先看看为啥下游的要求会如此别致。 为什么同样都是处理多张图片，下游不搞成支持并发而要搞成批量调用（batch call）？ 这个设定有点奇怪？ 其实不奇怪，在算法服务中甚至很常见，举个例子你就明白了。 同样是处理多张图片，为了简单，我就假设是三张吧。如果是用单个cpu去处理的话。那不管是并发还是batch进来，由于cpu内部的计算单元有限，所以你可以简单理解为，这三张图片，就是串行去计算的。 我计算第一张图片是否能审核通过，跟第二张图片是否能审核通过，这两者没有逻辑关联，因此按道理两张图片是可以并行计算。 奈何我CPU计算单元有限啊，做不到啊。 但是。 如果我打破计算单元有限的这个条件，给CPU加入超多计算单元，并且弱化一些对于计算没啥用处的组件，比如cache和控制单元。那我们就有足够的算力可以让这些图片的计算并行起来了。 是的，把CPU这么一整，它其实就变成了GPU。 上面的讲解只是为了方便理解，实际上，gpu会以更细的粒度去做并发计算，比如可以细到图片里的像素级别。 这也是为什么如果我们跑一些3d游戏的时候，需要用到显卡，因为它可以快速的并行计算画面里每个地方的光影，远近效果啥的，然后渲染出画面。 回到为什么要搞成batch call的问题中。 其实一次算法服务调用中，在数据真正进入GPU前，其实也使用了CPU做一些前置处理。 因此，我们可以简单的将一次调用的时间理解成做了下面这些事情。 服务由CPU逻辑和GPU处理逻辑组成，调用进入服务后，会有一些前置逻辑，它需要CPU来完成，然后才使用GPU去进行并行计算，将结果返回后又有一些后置的CPU处理逻辑。中间的GPU部分，管是计算1张图，还是计算100张图，只要算力支持，那它们都是并行计算的，耗时都差不多。 如果把这多张图片拆开，并发去调用这个算法服务，那就有 N组这样的CPU+GPU的消耗，而中间的并行计算，其实没有利用到位。 并且还会多了前置和后置的CPU逻辑部分，算法服务一般都是python服务，主流的一些web框架几乎都是以多进程，而不是多线程的方式去处理外部请求，这就有可能导致额外的进程间切换消耗。 当并发的请求多了，请求处理不过来，后边来的请求就需要等前边的处理完才能被处理，后面的请求耗时看起来就会变得特别大。这也是上面图1里，接口延时（latency）像过山车那样往上涨的原因。 按理说减少并发，增大每次调用时的图片数量，就可以解决这个问题。 这就是推荐batch call的原因。 但问题又来了。 每次调用，上游服务输入的是一个视频以及它的几张图片，调用下游时，batch的数量按道理就只能是这几张图片的数量，怎么才能增大batch的数量呢？ 这里的调用，就需要分为同步调用和异步调用了。 同步调用和异步调用的区别同步调用，意思是上游发起请求后，阻塞等待，下游处理逻辑后返回结果给上游。常见的形式就像我们平时做的http调用一样。 异步调用，意思是上游发起请求后立马返回，下游收到消息后慢慢处理，处理完之后再通过某个形式通知上游。常见的形式是使用消息队列，也就是mq。将消息发给mq后，下游消费mq消息，触发处理逻辑，然后再把处理结果发到mq，上游消费mq的结果。 异步调用的形式接入 回到我们文章开头提到的例子，当上游服务收到一个请求（一个视频和它对应的图片），这时候上游服务作为生产者将这个数据写入到mq中，请求返回。然后新造一个C服务，负责批量消费mq里的消息。这时候服务C就可以根据下游服务的性能控制自己的消费速度，比如一次性消费10条数据（视频），每个数据下面挂了10个图片，那我一次batch的图片数量就是10*10=100张，原来的10次请求就变为了1次请求。这对下游就相当的友好了。 下游返回结果后，服务C将结果写入到mq的另外一个topic下，由上游去做消费，这样就结束了整个调用流程。 当然上面的方案，如果你把mq换成数据库，一样是ok的，这时候服务C就可以不断的定时轮询数据库表，看下哪些请求没处理，把没处理的请求批量捞出来再batch call下游。不管是mq还是数据库，它们的作用无非就是作为中转，暂存数据，让服务C根据下游的消费能力，去消费这些数据。 这样不管后续要加入多少个新服务，它们都可以在原来的基础上做扩展，如果是mq，加topic，如果是数据库，则加数据表，每个新服务都可以根据自己的消费能力去调整消费速度。 其实对于这种上下游服务处理性能不一致的场景，最适合用的就是异步调用。而且涉及到的服务性能差距越大，服务个数越多，这个方案的优势就越明显。 同步调用的方式接入虽然异步调用在这种场景下的优势很明显，但也有个缺点，就是它需要最上游的调用方能接受用异步的方式去消费结果。其实涉及到算法的服务调用链，都是比较耗时的，用异步接口非常合理。但合理归合理，有些最上游他不一定听你的，就是不能接受异步调用。 这就需要采用同步调用的方案，但怎么才能把同步接口改造得更适合这种调用场景，这也是这篇文章的重点。 限流如果直接将请求打到下游算法服务，下游根本吃不消，因此首先需要做的就是给在上游调用下游的地方，加入一个速率限制（rate limit）。 这样的组件一般也不需要你自己写，几乎任何一个语言里都会有现成的。 比如golang里可以用golang.org/x/time/rate库，它其实是用令牌桶算法实现的限流器。如果不知道令牌桶是啥也没关系，不影响理解。 当然，这个限制的是当前这个服务调用下游的qps，也就是所谓的单节点限流。如果是多个服务的话，网上也有不少现成的分布式限流框架。但是，还是那句话，够用就好。 限流只能保证下游算法服务不被压垮，并不能提升单次调用batch的图片数量，有没有什么办法可以解决这个问题呢？ 参考Nagle算法的做法我们熟悉的TCP协议里，有个算法叫Nagle算法，设计它的目的，就是为了避免一次传过少数据，提高数据包的有效数据负载。 当我们想要发送一些数据包时，数据包会被放入到一个缓冲区中，不立刻发送，那什么时候会发送呢？ 数据包会在以下两个情况被发送： 缓冲区的数据包长度达到某个长度（MSS）时。 或者等待超时（一般为200ms）。在超时之前，来的那么多个数据包，就是凑不齐MSS长度，现在超时了，不等了，立即发送。 这个思路就非常值得我们参考。我们完全可以自己在代码层实现一波，实现也非常简单。 1.我们定义一个带锁的全局队列（链表）。 2.当上游服务输入一个视频和它对应的N张图片时，就加锁将这N张图片数据和一个用来存放返回结果的结构体放入到全局队列中。然后死循环读这个结构体，直到它有结果。就有点像阻塞等待了。 3.同时在服务启动时就起一个线程A专门用于收集这个全局队列的图片数据。线程A负责发起调用下游服务的请求，但只有在下面两个情况下会发起请求 当收集的图片数量达到xx张的时候 距离上次发起请求过了xx毫秒（超时） 4.调用下游结束后，再根据一开始传入的数据，将调用结果拆开来，送回到刚刚提到的用于存放结果的结构体中。 5.第2步里的死循环因为存放返回结果的结构体，有值了，就可以跳出死循环，继续执行后面的逻辑。 这就像公交车站一样，公交车站不可能每来一个顾客就发一辆公交车，当然是希望车里顾客越多越好。上游每来一个请求，就把请求里的图片，也就是乘客，塞到公交车里，公交车要么到点发车（向下游服务发起请求），要么车满了，也没必要等了，直接发车。这样就保证了每次发车的时候公交车里的顾客数量足够多，发车的次数尽量少。 大体思路就跟上面一样，如果是用go来实现的话，就会更加简单。 比如第1步里的加锁全局队列可以改成有缓冲长度的channel。第2步里的”用来存放结果的结构体“，也可以改成另一个无缓冲channel。执行 res := &lt;-ch， 就可以做到阻塞等待的效果。 而核心的仿Nagle的代码也大概长下面这样。当然不看也没关系，反正你已经知道思路了。 123456789101112131415161718192021222324252627282930313233343536373839func CallAPI() error &#123; size := 100 // 这个数组用于收集视频里的图片，每个 IVideoInfo 下都有N张图片 videoInfos := make([]IVideoInfo, 0, size) // 设置一个200ms定时器 tick := time.NewTicker(200 * time.Microsecond) defer tick.Stop() // 死循环 for &#123; select &#123; // 由于定时器，每200ms，都会执行到这一行 case &lt;-tick.C: if len(videoInfos) &gt; 0 &#123; // 200ms超时，去请求下游 limitStartFunc(videoInfos, true) // 请求结束后把之前收集的数据清空，重新开始收集。 videoInfos = make([]IVideoInfo, 0, size) &#125; // AddChan就是所谓的全局队列 case videoInfo, ok := &lt;-AddChan: if !ok &#123; // 通道关闭时，如果还有数据没有去发起请求，就请求一波下游服务 limitStartFunc(videoInfos, false) videoInfos = make([]IVideoInfo, 0, size) return nil &#125; else &#123; videoInfos = append(videoInfos, videoInfo) if videoInfos 内的图片满足xx数量 &#123; limitStartFunc(videoInfos, false) videoInfos = make([]IVideoInfo, 0, size) // 重置定时器 tick.Reset(200 * time.Microsecond) &#125; &#125; &#125; &#125; return nil&#125; 通过这一操作，上游每来一个请求，都会将视频里的图片收集起来，堆到一定张数的时候再统一请求，大大提升了每次batch call的图片数量，同时也减少了调用下游服务的次数。真·一举两得。 优化的效果也比较明显，上游服务支持的qps从原来不稳定的3q~15q变成稳定的90q。下游的接口耗时也变得稳定多了，从原来的过山车似的飙到15s变成稳定的500ms左右。处理的图片的速度也从原来20qps提升到350qps。 到这里就已经大大超过业务需求的预期（40qps）了，够用就好，多一个qps都是浪费。 可以了，下班吧。 总结 为了充分利用GPU并行计算的能力，不少算法服务会希望上游通过加大batch的同时减少并发的方式进行接口调用。 对于上下游性能差距明显的服务，建议配合mq采用异步调用的方式将服务串联起来。 如果非得使用同步调用的方式进行调用，建议模仿Nagle算法的形式，攒一批数据再发起请求，这样既可以增大batch，同时减少并发，真·一举两得，亲测有效。 最后讲了那么多可以提升性能的方式，现在需求来了，如果你资源充足，但时间不充足，那还是直接同步调用一把梭吧。 性能不够？下游加机器，gpu卡，买！ 然后下个季度再提起一个技术优化，性能提升xx%，cpu，gpu减少xx%。 有没有闻到？ 这是kpi的味道。 又是一个小细节，学到了的兄弟们评论区打个【学到了】。 最近原创更文的阅读量稳步下跌，思前想后，夜里辗转反侧。 我有个不成熟的请求。 离开广东好长时间了，好久没人叫我靓仔了。 大家可以在评论区里，叫我一靓仔吗？ 我这么善良质朴的愿望，能被满足吗？ 如果实在叫不出口的话，能帮我点下右下角的点赞和在看吗？ 别说了，一起在知识的海洋里呛水吧点击下方名片，关注公众号:【小白debug】 不满足于在留言区说骚话？ 加我，我们建了个划水吹牛皮群，在群里，你可以跟你下次跳槽可能遇到的同事或面试官聊点有意思的话题。就超！开！心！ 文章推荐： 程序员防猝死指南 TCP粘包 数据包：我只是犯了每个数据包都会犯的错 |硬核图解 动图图解！既然IP层会分片，为什么TCP层也还要分段？","categories":[{"name":"golang面试题","slug":"golang面试题","permalink":"https://xiaobaidebug.top/categories/golang%E9%9D%A2%E8%AF%95%E9%A2%98/"}],"tags":[]},{"title":"啥？分库分表会带来读扩散问题？怎么解决？？？","slug":"图解mysql/啥？分库分表会带来读扩散问题？怎么解决？？？","date":"2022-05-25T14:57:55.000Z","updated":"2022-10-30T02:23:15.205Z","comments":true,"path":"2022/05/25/图解mysql/啥？分库分表会带来读扩散问题？怎么解决？？？/","link":"","permalink":"https://xiaobaidebug.top/2022/05/25/%E5%9B%BE%E8%A7%A3mysql/%E5%95%A5%EF%BC%9F%E5%88%86%E5%BA%93%E5%88%86%E8%A1%A8%E4%BC%9A%E5%B8%A6%E6%9D%A5%E8%AF%BB%E6%89%A9%E6%95%A3%E9%97%AE%E9%A2%98%EF%BC%9F%E6%80%8E%E4%B9%88%E8%A7%A3%E5%86%B3%EF%BC%9F%EF%BC%9F%EF%BC%9F/","excerpt":"今天这篇文章，其实也是我曾经面试中遇到过的真题。 分库分表大家可能听得多了，但读扩散问题大家了解吗？ 这里涉及到几个问题。 分库分表是什么？ 读扩散问题是什么？ 分库分表为什么会引发读扩散问题？ 怎么解决读扩散问题？ 能不能不要在评论区叫我刁毛？ 不好意思，失态了。","text":"今天这篇文章，其实也是我曾经面试中遇到过的真题。 分库分表大家可能听得多了，但读扩散问题大家了解吗？ 这里涉及到几个问题。 分库分表是什么？ 读扩散问题是什么？ 分库分表为什么会引发读扩散问题？ 怎么解决读扩散问题？ 能不能不要在评论区叫我刁毛？ 不好意思，失态了。 这些问题还是比较有意思的。 相信兄弟们也一定有机会遇到哈哈哈。 我们先从分库分表的话题聊起吧。 分库分表我们平时做项目开发。一开始，通常都先用一张数据表，而一般来说数据表写到2kw条数据之后，底层B+树的层级结构就可能会变高，不同层级的数据页一般都放在磁盘里不同的地方，换言之，磁盘IO就会增多，带来的便是查询性能变差。如果对上面这句话有疑惑的话，可以去看下我之前写的文章。 于是，当我们单表需要管理的数据变得越来越多，就不得不考虑数据库分表。而这里的分表，分为水平分表和垂直分表。 垂直分表的原理比较简单，一般就是把某几列拆成一个新表，这样单行数据就会变小，B+树里的单个数据页（固定16kb）内能放入的行数就会变多，从而使单表能放入更多的数据。 垂直分表没有太多可以说的点。下面，我们重点说说最常见的水平分表。 水平分表有好几种做法，但不管是哪种，本质上都是将原来的 user 表，变成 user_0, user1, user2 .... uerN这样的N多张小表。 从读写一张user大表，变成读写 user_1 … userN 这样的N张小表。 每一张小表里，只保存一部分数据，但具体保存多少，这个自己定，一般就订个500w~2kw。 那分表具体怎么做？ 根据id范围分表我认为最好用的，是根据id范围进行分表。 我们假设每张分表能放2kw行数据。那user0就放主键id为1~2kw的数据。user1就放id为2kw+1 ~ 4kw，user2就放id为4kw+1 ~ 6kw， userN就放 2N kw+1 ~ 2(N+1)kw。 假设现在有条数据，id=3kw，将这个3kw除2kw = 1.5，向下取整得到1，那就可以得到这条数据属于user1表。于是去读写user1表就行了。这就完成了数据的路由逻辑，我们把这部分逻辑封装起来，放在数据库和业务代码之间。 这样。对于业务代码来说，它只知道自己在读写一张 user 表，根本不知道底下还分了那么多张小表。 对于数据库来说，它并不知道自己被分表了，它只知道有那么几张表，正好名字长得比较像而已。 这还只是在一个数据库里做分表，如果范围再搞大点，还能在多个数据库里做分表，这就是所谓的分库分表。 不管是单库分表还是分库分表，都可以通过这样一个中间层逻辑做路由。 还真的就应了那句话，没有什么是加中间层不能解决的。 如果有，就多加一层。 至于这个中间层的实现方式就更灵活了，它既可以像第三方orm库那样加在业务代码中。 也可以在mysql和业务代码之间加个proxy服务。 如果是通过第三方orm库的方式来做的话，那需要根据不同语言实现不同的代码库，所以不少厂都选择后者加个proxy的方式，这样就不需要关心上游服务用的是什么语言。 根据id取模分表这时候就有兄弟要提出问题了，”我看很多方案都对id取模，你这个方案是不是不完整？”。 取模的方案也是很常见的。 比如一个id=31进来，我们一共分了5张表，分别是user0到user4。对31%5=1，取模得1，于是就能知道应该读写user1表。 优点当然是比较简单。而且读写数据都可以很均匀的分摊到每个分表上。 但缺点也比较明显，如果想要扩展表的个数，比如从5张表变成8张表。那同样还是id=31的数据，31%8 = 7，就需要读写user7这张表。跟原来就对不上了。 这就需要考虑数据迁移的问题。很头秃。 为了避免后续扩展的问题，我见过一些业务一开始就将数据预估得很大，然后心一横，分成100张表，一张表如果存个2kw条，那也能存20亿数据了。 也不是说这样不行吧，就是这个业务直到最后放弃的时候，也就存了百万条数据，每次打开数据库表能看到茫茫多的user_xx，就是不太舒服，专业点，叫增加了程序员的心智负担。 而上面一种方式，根据id范围去分表，就能很好的解决这些问题，数据少的时候，表也少，随着数据增多，表会慢慢变多。而且这样表还可以无限扩展。 那是不是说取模的做法就用不上了呢？ 也不是。 将上面两种方式结合起来id取模的做法，最大的好处是，新写入的数据都是实实在在的分散到了多张表上。 而根据id范围去做分表，因为id是递增的，那新写入的数据一般都会落到某一张表上，如果你的业务场景写数据特别频繁，那这张表就会出现写热点的问题。 这时候就可以将id取模和id范围分表的方式结合起来。 我们可以在某个id范围里，引入取模的功能。比如 以前 2kw~4kw是user1表，现在可以在这个范围再分成5个表，也就是引入user1-0, user1-2到user1-4，在这5个表里取模。 举个例子，id=3kw，根据范围，会分到user1表，然后再进行取模 3kw % 5 = 0，也就是读写user1-0表。 这样就可以将写单表分摊为写多表。 这在分库的场景下优势会更明显，不同的库，可以把服务部署到不同的机器上，这样各个机器的性能都能被用起来。 读扩散问题我们上面提到的好几种分表方式，都用了id这一列作为分表的依据，这其实就是所谓的分片键。 实际上我们一般也是用的数据库主键作为分片键。 这样，理想情况下我们已知一个id，不管是根据哪种规则，我们都能很快定位到该读哪个分表。 但很多情况下，我们的查询又不是只查主键，如果我的数据库表有一列name，并且加了个普通索引。 这样我执行下面的sql 1select * from user where name = &quot;小白&quot;; 由于name并不是分片键，我们没法定位到具体要到哪个分表上去执行sql。 于是就会对所有分表都执行上面的sql，当然不会是串行执行sql，一般都是并发执行sql的。 如果我有100张表，就执行100次sql。 如果我有200张表，就执行200次sql。 随着我的表越来越多，次数会越来越多，这就是所谓的读扩散问题。 这是个比较有趣的问题，它确实是个问题，但大部分的业务不会去处理它，读100次怎么了，数据增长之后读的次数会不断增加又怎么了？但架不住我的业务不赚钱啊，也根本长不了那么多数据啊。 话是这么说没错，但面试官问你的时候，你得知道怎么处理啊。 引入新表来做分表问题的核心在于，主键是分片键，而普通索引列并不分片。 那好办，我们单独建个新的分片表，这个新表里的列就只有旧表的主键id和普通索引列，而这次换普通索引列来做分片键。 这样当我们要查询普通索引列时，先到这个新的分片表里做一次查询，就能迅速定位到对应的主键id，然后再拿主键id去旧的分片表里查一次数据。这样就从原来漫无目的的全表扩散查询，缩减为只查固定几个表了。 举个例子。比如我的表原本长下面这样，其中id列是主键，同时也是分片键，name列是非主键索引。为了简化，假设三条数据一张表。 此时分表里 id=1,4,6 的都有name=&quot;小白&quot; 的数据。 当我们执行 select * from user where name = &quot;小白&quot;; 则需要并发查3张表，随着表变多，查询次数会变得更多。 但如果我们为name列建个新表(nameX)，以name为新的分片键。 这样我们可以先执行 select id from nameX where name = &quot;小白&quot;; 再拿着结果里的ids去查询 select * from user where id in (ids); 这样就算表变多了，也可以迅速定位到某几张具体的表，减少了查询次数。 但这个做法的缺点也比较明显，你需要维护两套表，并且普通索引列更新时，要两张表同时进行更改。 有一定的开发量 有没有更简单的方案？ 使用其他更合适的存储我们常规的查询是通过id主键去查询对应的name列。而像上面的方案，则通过引入一个新表，倒过来，先用name查到对应的id，再拿id去获取具体的数据。这其实就像是建立了一个新的索引一样，像这种，通过name列反查原数据的思想，其实就很类似于倒排索引。 相当于我们是利用了倒排索引的思路去解决分表下的数据查询问题。 回想下，其实我们的原始需求无非就是在大量数据的场景下依然能提供普通索引列或其他更多维度的查询。 这种场合，更适合使用es，es天然分片，而且内部利用倒排索引的形式来加速数据查询。 哦？兄弟萌，又是它，倒排索引，又是个极小的细节，做好笔记。 举个例子，我同样是一行数据 id,name,age。在mysql里，你得根据id分片，如果要支持name和age的查询，为了防止读扩散，你得分别再建一个name的分片表和一个age的分片表。 而如果你用es，它会在它内部以id分片键进行分片，同时还能建一个name到id，和一个age到id的倒排索引。这是不是就跟上面做的事情没啥区别。 而且将mysql接入es也非常简单，我们可以通过开源工具 canal 监听mysql的binlog日志变更，再将数据解析后写入es，这样es就能提供近实时的查询能力。 觉得es+mysql还是繁琐？有没有其他更简洁的方案？ 有。 别用mysql了，改用tidb吧，相信大家多少也听说过这个名称，这是个分布式数据库。 它通过引入Range的概念进行数据表分片，比如第一个分片表的id在02kw，第二个分片表的id在2kw4kw。 哦？有没有很熟悉，这不就是文章开头提到的根据id范围进行数据库分表吗？ 它支持普通索引，并且普通索引也是分片的，这是不是又跟上面提到的倒排索引方案很类似。 又是个极小的细节。 并且tidb跟mysql的语法几乎一致，现在也有非常多现成的工具可以帮你把数据从mysql迁移到tidb。所以开发成本并不高。 总结 mysql在单表数据过大时，查询性能会变差，因此当数据量变得巨大时，需要考虑水平分表。 水平分表需要选定一个分片键，一般选择主键，然后根据id进行取模，或者根据id的范围进行分表。 mysql水平分表后，对于非分片键字段的查询会有读扩散的问题，可以用普通索引列作分片键建一个新表，先查新表拿到id后再回到原表再查一次原表。这本质上是借鉴了倒排索引的思路。 如果想要支持更多维度的查询，可以监听mysql的binlog，将数据写入到es，提供近实时的查询能力。 当然，用tidb替换mysql也是个思路。tidb属实是个好东西，不少厂都拿它换个皮贴个标，做成自己的自研数据库，非常推荐大家学习一波。 不要做过早的优化，没事别上来就分100个表，很多时候真用不上。 参考资料《图解分库分表》 https://mp.weixin.qq.com/s/OI5y4HMTuEZR1hoz9aOMxg 最后当年我还在某个游戏项目组里做开发的时候，从企鹅那边挖来的策划信誓旦旦的说，我们要做的这款游戏老少皆宜，肯定是爆款。要做成全球同服。上线至少过亿注册，十万人同时在线。要好好规划和设计。 我们算了下，信他能有个1亿注册。用了id范围的方式进行分片，分了4张表。 搞得我热血沸腾。 那天晚上下班，夏蝉鸣泣，从赤道吹来的热风阵阵拂过我的手臂，我听着泽野弘之的歌，就算是开电瓶车，我都感觉自己像是在开高达。 一年后。 游戏上线前一天通知运维加机器，怕顶不住，要整夜关注。 后来上线了，全球最高在线人数58人。其中有7个是项目组成员。 还是夏天，还是同样的下班路，想哭，但我不能哭，因为骑电瓶车的时候擦眼泪不安全。 最近原创更文的阅读量稳步下跌，思前想后，夜里辗转反侧。 我有个不成熟的请求。 离开广东好长时间了，好久没人叫我靓仔了。 大家可以在评论区里，叫我一靓仔吗？ 我这么善良质朴的愿望，能被满足吗？ 如果实在叫不出口的话，能帮我点下右下角的点赞和在看吗？ 别说了，一起在知识的海洋里呛水吧点击下方名片，关注公众号:【小白debug】 不满足于在留言区说骚话？ 加我，我们建了个划水吹牛皮群，在群里，你可以跟你下次跳槽可能遇到的同事或面试官聊点有意思的话题。就超！开！心！ 文章推荐： 程序员防猝死指南 TCP粘包 数据包：我只是犯了每个数据包都会犯的错 |硬核图解 动图图解！既然IP层会分片，为什么TCP层也还要分段？","categories":[{"name":"图解mysql","slug":"图解mysql","permalink":"https://xiaobaidebug.top/categories/%E5%9B%BE%E8%A7%A3mysql/"}],"tags":[]},{"title":"mysql插入数据会失败，为什么？","slug":"图解mysql/mysql插入数据会失败，为什么？","date":"2022-05-18T14:57:55.000Z","updated":"2022-10-30T02:28:13.643Z","comments":true,"path":"2022/05/18/图解mysql/mysql插入数据会失败，为什么？/","link":"","permalink":"https://xiaobaidebug.top/2022/05/18/%E5%9B%BE%E8%A7%A3mysql/mysql%E6%8F%92%E5%85%A5%E6%95%B0%E6%8D%AE%E4%BC%9A%E5%A4%B1%E8%B4%A5%EF%BC%8C%E4%B8%BA%E4%BB%80%E4%B9%88%EF%BC%9F/","excerpt":"那天，我还在外面吃成都六姐的冒菜。 牛肉丸裹上麻酱后，狠狠嘬一口，都要入嘴了。 产品经理突然发来消息。 “线上有些用户不能注册了” 心想着”关我x事，又不是我做的模块”，放下手机。 不对，那老哥上礼拜刚离职了，想到这里，夹住毛肚的手微微颤抖。 对面继续发：**”还有些用户不能改名”** “如果用上表情符号的话，问题必现”","text":"那天，我还在外面吃成都六姐的冒菜。 牛肉丸裹上麻酱后，狠狠嘬一口，都要入嘴了。 产品经理突然发来消息。 “线上有些用户不能注册了” 心想着”关我x事，又不是我做的模块”，放下手机。 不对，那老哥上礼拜刚离职了，想到这里，夹住毛肚的手微微颤抖。 对面继续发：**”还有些用户不能改名”** “如果用上表情符号的话，问题必现” 可以了，这下问题几乎直接定位了。 危，速归。 有经验的兄弟们很容易看出，这肯定是因为字符集的缘故。 复现问题我们来简单复现下这个问题。 如果你有一张数据库表，建表sql就像下面一样。 接下来如果你插入的数据是 能成功。一切正常。 但如果你插入的是 就会报错。 1Incorrect string value: &#x27;\\xF0\\x9F\\x98\\x81&#x27; for column &#x27;name&#x27; at row 1 区别在于后者多了个emoji表情。 明明也是字符串，为什么字符串里含有emoji表情，插入就会报错呢？ 我们从字符集编码这个话题开始聊起。 编码和字符集的关系虽然我们平时可以在编辑器上输入各种中文英文字母，但这些都是给人读的，不是给计算机读的，其实计算机真正保存和传输数据都是以二进制0101的格式进行的。 那么就需要有一个规则，把中文和英文字母转化为二进制，比如”debug”，计算机就需要把它转化为下图这样。 其中d对应十六进制下的64，它可以转换为01二进制的格式。 于是字母和数字就这样一一对应起来了，这就是ASCII编码格式。 它用一个字节，也就是8位来标识字符，基础符号有128个，扩展符号也是128个。 也就只能表示下英文字母和数字。 这哪里够用。 塞牙缝都不够。 于是为了标识中文，出现了GB2312的编码格式。为了标识希腊语，出现了greek编码格式，为了标识俄语，整了cp866编码格式。 这百花齐放的场面，显然不是一个爱写if else的程序员想看到的。 为了统一它们，于是出现了Unicode编码格式，它用了2~4个字节来表示字符，这样理论上所有符号都能被收录进去，并且完全兼容ASCII的编码，也就是说，同样是字母d，在ASCII用64表示，在Unicode里还是用64来表示。 但不同的地方是ASCII编码用1个字节来表示，而Unicode用则两个字节来表示。 比如下图，同样都是字母d，unicode比ascii多使用了一个字节。 我们可以注意到，上面的unicode编码，放在前面的都是0，其实用不上，但还占了个字节，有点浪费，完全能隐藏掉。如果我们能做到该隐藏时隐藏，这样就能省下不少空间，按这个思路，就是就有了UTF-8编码。 来总结下。 按照一定规则把符号和二进制码对应起来，这就是编码。而把n多这种已经编码的字符聚在一起，就是我们常说的字符集。 比如utf-8字符集就是所有utf-8编码格式的字符的合集。 mysql的字符集想看下mysql支持哪些字符集。可以执行 show charset; 上面这么多字符集，我们只需要关注utf8和utf8mb4就够了。 utf8和utf8mb4的区别上面提到utf-8是在unicode的基础上做的优化，既然unicode有办法表示所有字符，那utf-8也一样可以表示所有字符，为了避免混淆，我在后面叫它大utf8。 而从上面mysql支持的字符集的图里，我们看到了utf8和utf8mb4。 先说utf8mb4编码，mb4就是most bytes 4的意思，从上图最右边的Maxlen可以看到，它最大支持用4个字节来表示字符，它几乎可以用来表示目前已知的所有的字符。 再说mysql字符集里的utf8，它是数据库的默认字符集。但注意，此utf8非彼utf8，我们叫它小utf8字符集。为什么这么说，因为从Maxlen可以看出，它最多支持用3个字节去表示字符，按utf8mb4的命名方式，准确点应该叫它utf8mb3。 不好意思，有被严谨到的兄弟们，评论区扣个”严谨”。 它就像是阉割版的utf8mb4，只支持部分字符。比如emoji表情，它就不支持。 而mysql支持的字符集里，第三列，collation，它是指字符集的比较规则。 比如，**”debug”和”Debug”**是同一个单词，但它们大小写不同，该不该判为同一个单词呢。 这时候就需要用到collation了。 通过SHOW COLLATION WHERE Charset = &#39;utf8mb4&#39;;可以查看到utf8mb4下支持什么比较规则。 如果collation = utf8mb4_general_ci，是指使用utf8mb4字符集前提下，挨个字符进行比较（general），并且不区分大小写（_ci，case insensitice）。 这种情况下，**”debug”和”Debug”是同一个单词**。 如果改成collation=utf8mb4_bin，就是指挨个比较二进制位大小。 于是**”debug”和”Debug”就不是同一个单词。** 那utf8mb4对比utf8mb3有什么劣势吗？我们知道数据库表里，字段类型如果是char(2)的话，里面的2是指字符个数，也就是说不管这张表用的是什么字符集，都能放上2个字符。 而char又是固定长度，为了能放下2个utf8mb4的字符，char会默认保留2*4（maxlen=4）= 8个字节的空间。 如果是utf8mb3，则会默认保留 2 * 3 (maxlen=3) = 6个字节的空间。也就是说，在这种情况下，utf8mb4会比utf8mb3多使用一些空间。 但这真的无关紧要，如果我不用char，用varchar就好了，varchar不是固定长度，也就没有上面这些麻烦事了。 所以我个人认为，utf8mb4比起 utf8mb3 几乎没有劣势。 如何查看数据库表的字符集如果我们不知道自己的表是用的哪种字符集，可以通过下面的方式进行查看。 再看报错原因到这里，我们回到文章开头的问题。 因为数据库表在建表的时候使用 DEFAULT CHARSET=utf8， 相当于指定了utf8mb3字符集格式。 而在执行insert数据的时候，又不讲武德，加入了emoji表情这种utf8mb4才能支持的字符，mysql识别到这是utf8mb3不支持的字符，于是忍痛报错。 要修复也很简单，执行下面的sql语句，就可以把数据库表的字符集改成utf8mb4。 1ALTER TABLE user CONVERT TO CHARACTER SET utf8mb4 COLLATE utf8mb4_general_ci; 答应我，以后建表，我们都无脑选utf8mb4。 选utf8除了在char字段场景下会比utf8mb4稍微省一点空间外，几乎没任何好处。 这点空间省下来了能提高你的绩效吗？不能。 但如果因此炸雷了，那你号就没了。 总结 ASCII编码支持数字和字母。大佬们为了支持中文引入了GB2312编码格式，其他国家的大佬们为了支持更多语言和符号，也引入了相应的编码格式。为了统一这些各种编码格式，大佬们又引入了unicode编码格式，而utf-8则在unicode的基础上做了优化，压缩了空间。 mysql默认的utf8字符集，其实只是utf8mb3，并不完整，当插入emoji表情等特殊字符时，会报错，导致插入、更新数据失败。改成utf8mb4就好了，它能支持更多字符。 mysql建表时如果不知道该选什么字符集，无脑选utf8mb4就行了，你会感谢我的。 参考资料《从根儿上理解mysql》 最后原本A同学设计这张表的时候非常简单，也有字符串类型的字段，但字段含义决定了肯定不会有奇奇怪怪的字符，用utf8很合理，还省空间。 后来交接给了B同学，B同学在这基础上加过非常多的字段，离职前最后一个需求加的这个名称字段，所幸并没炸雷。最后到了我这里。 好一个击鼓传雷。 有点东西哦。 那么问题来了。 这样的一个事故，复盘会一开，会挂P几呢？ 最近原创更文的阅读量稳步下跌，思前想后，夜里辗转反侧。 我有个不成熟的请求。 离开广东好长时间了，好久没人叫我靓仔了。 大家可以在评论区里，叫我一靓仔吗？ 我这么善良质朴的愿望，能被满足吗？ 如果实在叫不出口的话，能帮我点下右下角的点赞和在看吗？ 别说了，一起在知识的海洋里呛水吧点击下方名片，关注公众号:【小白debug】 不满足于在留言区说骚话？ 加我，我们建了个划水吹牛皮群，在群里，你可以跟你下次跳槽可能遇到的同事或面试官聊点有意思的话题。就超！开！心！ 文章推荐： 程序员防猝死指南 TCP粘包 数据包：我只是犯了每个数据包都会犯的错 |硬核图解 动图图解！既然IP层会分片，为什么TCP层也还要分段？","categories":[{"name":"图解mysql","slug":"图解mysql","permalink":"https://xiaobaidebug.top/categories/%E5%9B%BE%E8%A7%A3mysql/"}],"tags":[]},{"title":"mysql查询 limit 1000,10 和limit 10 速度一样快吗？如果我要分页，我该怎么办？","slug":"图解mysql/mysql查询 limit 1000,10 和limit 10 速度一样快吗？如果我要分页，我该怎么办？","date":"2022-05-06T14:57:55.000Z","updated":"2022-10-30T02:28:13.643Z","comments":true,"path":"2022/05/06/图解mysql/mysql查询 limit 1000,10 和limit 10 速度一样快吗？如果我要分页，我该怎么办？/","link":"","permalink":"https://xiaobaidebug.top/2022/05/06/%E5%9B%BE%E8%A7%A3mysql/mysql%E6%9F%A5%E8%AF%A2%20limit%201000,10%20%E5%92%8Climit%2010%20%E9%80%9F%E5%BA%A6%E4%B8%80%E6%A0%B7%E5%BF%AB%E5%90%97%EF%BC%9F%E5%A6%82%E6%9E%9C%E6%88%91%E8%A6%81%E5%88%86%E9%A1%B5%EF%BC%8C%E6%88%91%E8%AF%A5%E6%80%8E%E4%B9%88%E5%8A%9E%EF%BC%9F/","excerpt":"刷网站的时候，我们经常会遇到需要分页查询的场景。 比如下图红框里的翻页功能。","text":"刷网站的时候，我们经常会遇到需要分页查询的场景。 比如下图红框里的翻页功能。 我们很容易能联想到可以用mysql实现。 假设我们的建表sql是这样的 建表sql大家也不用扣细节，只需要知道id是主键，并且在user_name建了个非主键索引就够了，其他都不重要。 为了实现分页。 很容易联想到下面这样的sql语句。 1select * from page order by id limit offset, size; 比如一页有10条数据。 第一页就是下面这样的sql语句。 1select * from page order by id limit 0, 10; 第一百页就是 1select * from page order by id limit 990, 10; 那么问题来了。 用这种方式，同样都是拿10条数据，查第一页和第一百页的查询速度是一样的吗？为什么？ 两种limit的执行过程上面的两种查询方式。对应 limit offset, size 和 limit size 两种方式。 而其实 limit size ，相当于 limit 0, size。也就是从0开始取size条数据。 也就是说，两种方式的区别在于offset是否为0。 我们先来看下limit sql的内部执行逻辑。 mysql内部分为server层和存储引擎层。一般情况下存储引擎都用innodb。 server层有很多模块，其中需要关注的是执行器是用于跟存储引擎打交道的组件。 执行器可以通过调用存储引擎提供的接口，将一行行数据取出，当这些数据完全符合要求（比如满足其他where条件），则会放到结果集中，最后返回给调用mysql的客户端（go、java写的应用程序）。 我们可以对下面的sql先执行下 explain。 1explain select * from page order by id limit 0, 10; 可以看到，explain中提示 key 那里，执行的是PRIMARY，也就是走的主键索引。 主键索引本质是一棵B+树，它是放在innodb中的一个数据结构。 我们可以回忆下，B+树大概长这样。 在这个树状结构里，我们需要关注的是，最下面一层节点，也就是叶子结点。而这个叶子结点里放的信息会根据当前的索引是主键还是非主键有所不同。 如果是主键索引，它的叶子节点会存放完整的行数据信息。 如果是非主键索引，那它的叶子节点则会存放主键，如果想获得行数据信息，则需要再跑到主键索引去拿一次数据，这叫回表。 比如执行 1select * from page where user_name = &quot;小白10&quot;; 会通过非主键索引去查询user_name为”小白10“的数据，然后在叶子结点里找到”小白10“的数据对应的主键为10。 此时回表到主键索引中做查询，最后定位到主键为10的行数据。 但不管是主键还是非主键索引，他们的叶子结点数据都是有序的。比如在主键索引中，这些数据是根据主键id的大小，从小到大，进行排序的。 基于主键索引的limit执行过程那么回到文章开头的问题里。 当我们去掉explain，执行这条sql。 1select * from page order by id limit 0, 10; 上面select后面带的是星号，也就是要求获得行数据的*所有字段信息。 server层会调用innodb的接口，在innodb里的主键索引中获取到第0到10条完整行数据，依次返回给server层，并放到server层的结果集中，返回给客户端。 而当我们把offset搞离谱点，比如执行的是 1select * from page order by id limit 6000000, 10; server层会调用innodb的接口，由于这次的offset=6000000，会在innodb里的主键索引中获取到第0到（6000000 + 10）条完整行数据，返回给server层之后根据offset的值挨个抛弃，最后只留下最后面的size条，也就是10条数据，放到server层的结果集中，返回给客户端。 可以看出，当offset非0时，server层会从引擎层获取到很多无用的数据，而获取的这些无用数据都是要耗时的。 因此，我们就知道了文章开头的问题的答案，mysql查询中 limit 1000,10 会比 limit 10 更慢。原因是 limit 1000,10 会取出1000+10条数据，并抛弃前1000条，这部分耗时更大 那这种case有办法优化吗？ 可以看出，当offset非0时，server层会从引擎层获取到很多无用的数据，而当select后面是*号时，就需要拷贝完整的行信息，拷贝完整数据跟只拷贝行数据里的其中一两个列字段耗时是不同的，这就让原本就耗时的操作变得更加离谱。 因为前面的offset条数据最后都是不要的，就算将完整字段都拷贝来了又有什么用呢，所以我们可以将sql语句修改成下面这样。 1select * from page where id &gt;=(select id from page order by id limit 6000000, 1) order by id limit 10; 上面这条sql语句，里面先执行子查询 select id from page order by id limit 6000000, 1, 这个操作，其实也是将在innodb中的主键索引中获取到6000000+1条数据，然后server层会抛弃前6000000条，只保留最后一条数据的id。 但不同的地方在于，在返回server层的过程中，只会拷贝数据行内的id这一列，而不会拷贝数据行的所有列，当数据量较大时，这部分的耗时还是比较明显的。 在拿到了上面的id之后，假设这个id正好等于6000000，那sql就变成了 1select * from page where id &gt;=(6000000) order by id limit 10; 这样innodb再走一次主键索引，通过B+树快速定位到id=6000000的行数据，时间复杂度是lg(n)，然后向后取10条数据。 这样性能确实是提升了，亲测能快一倍左右，属于那种耗时从3s变成1.5s的操作。 这······ 属实有些杯水车薪，有点搓，属于没办法中的办法。 基于非主键索引的limit执行过程上面提到的是主键索引的执行过程，我们再来看下基于非主键索引的limit执行过程。 比如下面的sql语句 1select * from page order by user_name limit 0, 10; server层会调用innodb的接口，在innodb里的非主键索引中获取到第0条数据对应的主键id后，回表到主键索引中找到对应的完整行数据，然后返回给server层，server层将其放到结果集中，返回给客户端。 而当offset&gt;0时，且offset的值较小时，逻辑也类似，区别在于，offset&gt;0时会丢弃前面的offset条数据。 也就是说非主键索引的limit过程，比主键索引的limit过程，多了个回表的消耗。 但当offset变得非常大时，比如600万，此时执行explain。 可以看到type那一栏显示的是ALL，也就是全表扫描。 这是因为server层的优化器，会在执行器执行sql语句前，判断下哪种执行计划的代价更小。 很明显，优化器在看到非主键索引的600w次回表之后，摇了摇头，还不如全表一条条记录去判断算了，于是选择了全表扫描。 因此，当limit offset过大时，非主键索引查询非常容易变成全表扫描。是真·性能杀手。 这种情况也能通过一些方式去优化。比如 1select * from page t1, (select id from page order by user_name limit 6000000, 100) t2 WHERE t1.id = t2.id; 通过select id from page order by user_name limit 6000000, 100。 先走innodb层的user_name非主键索引取出id，因为只拿主键id，不需要回表，所以这块性能会稍微快点，在返回server层之后，同样抛弃前600w条数据，保留最后的100个id。然后再用这100个id去跟t1表做id匹配，此时走的是主键索引，将匹配到的100条行数据返回。这样就绕开了之前的600w条数据的回表。 当然，跟上面的case一样，还是没有解决要白拿600w条数据然后抛弃的问题，这也是非常挫的优化。 像这种，当offset变得超大时，比如到了百万千万的量级，问题就突然变得严肃了。 这里就产生了个专门的术语，叫深度分页。 深度分页问题深度分页问题，是个很恶心的问题，恶心就恶心在，这个问题，它其实无解。 不管你是用mysql还是es，你都只能通过一些手段去”减缓”问题的严重性。 遇到这个问题，我们就该回过头来想想。 为什么我们的代码会产生深度分页问题？ 它背后的原始需求是什么，我们可以根据这个做一些规避。 如果你是想取出全表的数据有些需求是这样的，我们有一张数据库表，但我们希望将这个数据库表里的所有数据取出，异构到es，或者hive里，这时候如果直接执行 1select * from page; 这个sql一执行，狗看了都摇头。 因为数据量较大，mysql根本没办法一次性获取到全部数据，妥妥超时报错。 于是不少mysql小白会通过limit offset size分页的形式去分批获取，刚开始都是好的，等慢慢地，哪天数据表变得奇大无比，就有可能出现前面提到的深度分页问题。 这种场景是最好解决的。 我们可以将所有的数据根据id主键进行排序，然后分批次取，将当前批次的最大id作为下次筛选的条件进行查询。 可以看下伪代码 这个操作，可以通过主键索引，每次定位到id在哪，然后往后遍历100个数据，这样不管是多少万的数据，查询性能都很稳定。 如果是给用户做分页展示如果深度分页背后的原始需求只是产品经理希望做一个展示页的功能，比如商品展示页，那么我们就应该好好跟产品经理battle一下了。 什么样的翻页，需要翻到10多万以后，这明显是不合理的需求。 是不是可以改一下需求，让它更接近用户的使用行为？ 比如，我们在使用谷歌搜索时看到的翻页功能。 一般来说，谷歌搜索基本上都在20页以内，作为一个用户，我就很少会翻到第10页之后。 作为参考。 如果我们要做搜索或筛选类的页面的话，就别用mysql了，用es，并且也需要控制展示的结果数，比如一万以内，这样不至于让分页过深。 如果因为各种原因，必须使用mysql。那同样，也需要控制下返回结果数量，比如数量1k以内。 这样就能勉强支持各种翻页，跳页（比如突然跳到第6页然后再跳到第106页）。 但如果能从产品的形式上就做成不支持跳页会更好，比如只支持上一页或下一页。 这样我们就可以使用上面提到的start_id方式，采用分批获取，每批数据以start_id为起始位置。这个解法最大的好处是不管翻到多少页，查询速度永远稳定。 听起来很挫？ 怎么会呢，把这个功能包装一下。 变成像抖音那样只能上划或下划，专业点，叫瀑布流。 是不是就不挫了？ 总结 limit offset, size 比 limit size 要慢，且offset的值越大，sql的执行速度越慢。 当offset过大，会引发深度分页问题，目前不管是mysql还是es都没有很好的方法去解决这个问题。只能通过限制查询数量或分批获取的方式进行规避。 遇到深度分页的问题，多思考其原始需求，大部分时候是不应该出现深度分页的场景的，必要时多去影响产品经理。 如果数据量很少，比如1k的量级，且长期不太可能有巨大的增长，还是用limit offset, size 的方案吧，整挺好，能用就行。 参考资料《MySQL的Limit子句底层原理你不可不知》https://blog.csdn.net/qq_34115899/article/details/120727513 最后关于深度分页，如果大家有更好的想法，欢迎评论区说出来。 这道题，是我无能！ 告辞！！ 最近原创更文的阅读量稳步下跌，思前想后，夜里辗转反侧。 我有个不成熟的请求。 离开广东好长时间了，好久没人叫我靓仔了。 大家可以在评论区里，叫我一靓仔吗？ 我这么善良质朴的愿望，能被满足吗？ 如果实在叫不出口的话，能帮我点下右下角的点赞和在看吗？ 别说了，一起在知识的海洋里呛水吧点击下方名片，关注公众号:【小白debug】 不满足于在留言区说骚话？ 加我，我们建了个划水吹牛皮群，在群里，你可以跟你下次跳槽可能遇到的同事或面试官聊点有意思的话题。就超！开！心！ 文章推荐： 程序员防猝死指南 TCP粘包 数据包：我只是犯了每个数据包都会犯的错 |硬核图解 动图图解！既然IP层会分片，为什么TCP层也还要分段？","categories":[{"name":"图解mysql","slug":"图解mysql","permalink":"https://xiaobaidebug.top/categories/%E5%9B%BE%E8%A7%A3mysql/"}],"tags":[]},{"title":"都是同样条件的mysql select语句，为什么读到的内容却不一样？","slug":"图解mysql/都是同样条件的mysql select语句，为什么读到的内容却不一样？","date":"2022-04-26T14:57:55.000Z","updated":"2022-10-30T02:28:13.643Z","comments":true,"path":"2022/04/26/图解mysql/都是同样条件的mysql select语句，为什么读到的内容却不一样？/","link":"","permalink":"https://xiaobaidebug.top/2022/04/26/%E5%9B%BE%E8%A7%A3mysql/%E9%83%BD%E6%98%AF%E5%90%8C%E6%A0%B7%E6%9D%A1%E4%BB%B6%E7%9A%84mysql%20select%E8%AF%AD%E5%8F%A5%EF%BC%8C%E4%B8%BA%E4%BB%80%E4%B9%88%E8%AF%BB%E5%88%B0%E7%9A%84%E5%86%85%E5%AE%B9%E5%8D%B4%E4%B8%8D%E4%B8%80%E6%A0%B7%EF%BC%9F/","excerpt":"假设当前数据库里有下面这张表。 老规矩，以下内容还是默认发生在innodb引擎的可重复读隔离级别下。","text":"假设当前数据库里有下面这张表。 老规矩，以下内容还是默认发生在innodb引擎的可重复读隔离级别下。 大家可以看到，线程1，同样都是读 age &gt;= 3 的数据。第一次读到1条数据，这个是原始状态。这之后线程2将id=2的age字段也改成了3。 线程1此时再读两次，一次读到的结果还是原来的1条，另一次读的结果却是2条，区别在于加没加for update。 为什么同样条件下，都是读，读出来的数据却不一样呢？ 可重复读不是要求每次读出来的内容要一样吗？ 要回答这个问题。 我需要从盘古是怎么开天辟地这个话题开始聊起。 不好意思。 失态了。 那就从事务是怎么回滚的开始聊起吧。 事务的回滚是怎么实现的我们在执行事务的时候，一般都是下面这样的格式 1234567begin;操作1;操作2;操作3;xxxxx....commit; 在提交事务之前，会执行各种操作，里面可以包含各种逻辑。 只要是执行逻辑，那就有可能会报错。 回想下事务的ACID里有个A，原子性，整个事务就是个整体，要么一起成功，要么一起失败。 如果失败了的话，那就要让执行到一半的事务有能力回到没执行事务前的状态，这就是回滚。 执行事务的代码就类似写成下面这样。 12345678910begin;try: 操作1; 操作2; 操作3; xxxxx .... commit;except Exception: rollback; 如果执行rollback能回到事务执行前的状态的话，那说明mysql需要知道某些行，执行事务前的数据长什么样子。 那数据库是怎么做到的呢？ 这就要提到undo日志了，它记录了某一行数据，在执行事务前是怎么样的。 比如id=1那行数据，name字段从**”小白”更新成了“小白debug”**，那就会新增一个undo日志，用于记录之前的数据。 由于同时并发执行的事务可以有很多，于是可能会有很多undo日志，日志里加入事务的id（trx_id）字段，用于标明这是哪个事务下产生的undo日志。 同时将它们用链表的形式组织起来，在undo日志里加入一个指针（roll_pointer），指向上一个undo日志，于是就形成了一条版本链。 有了这个版本链，当某个事务执行到一半发现失败时，就直接回滚，这时候就可以顺着这个版本链，回到执行事务前的状态。 当前读和快照读是什么有了上面的undo日志版本链之后，我们可以看到最新的数据在表头，在这之后的都是一个个旧的数据版本。不管是最新的，还是旧的数据版本，我们都叫它数据快照。 当前读，读的就是版本链的表头，也就是最新的数据。 快照读，读的就是版本链里的其中一个快照，当然如果这个快照正好就是表头，那此时快照读和当前读的结果一样。 我们平时执行的普通select语句，比如下面这种，就是快照读。 1select * from user where phone_no=2； 而特殊的select语句，比如在select后面加上lock in share mode或for update，都属于当前读。 除此之外insert，update，delete操作都属于写操作，既然写，那必然是写最新的数据，所以都会引发当前读。 那么问题来了。 当前读，读的是版本链的表头，那么执行当前读的时候，有没有可能恰好有其他事务，生成更加新的快照，替代当前表头，成为新的表头呢，那这时候岂不是读的不是最新数据了？ 答案是不会，不管是select … for update这些（特殊的）读操作，还是insert、update这些写操作，都会对这行数据加锁。而生成undo日志快照，也是在写操作的情况下生成的，执行写操作前也需要获得锁。所以写操作需要阻塞等待当前读完成后，获得锁后才能更新版本链。 read view数据库里可以同时并发执行非常多的事务, 每个事务都会被分配一个事务ID, 这个 ID 是递增的，越新的事务，ID 越大。 而数据表里某行数据的undo日志版本链，每个undo日志上面也有一个事务id (trx_id)，它是创建这个undo日志的事务id。 并不是所有事务都会生成undo日志，也就是说某行数据的undo日志版本链上只有部分事务的id。但是，所有事务都有可能会访问这行数据对应的版本链。而且版本链上虽然有很多undo日志快照，但也不是所有undo日志都能被读，毕竟有些undo日志，创建它们的事务还没提交呢，人家随时可能失败并回滚。 现在的问题就成了，现在有一个事务，通过快照读的方式去读undo日志版本链，那它能读哪些快照？并且它应该读哪个快照？ 这里就要引入一个read view的概念。它就像是一个有上下边界的滑动窗口。 整个数据库里有那么多事务，这些事务分为已经提交（commit）的，和没提交的。没提交的，意味着这些事务还在进行中，也就是所谓的活跃事务。所有的活跃事务的id，组成m_ids。而这其中最小的事务id就是read view的下边界，叫min_trx_id。 产生read view的那一刻，所有事务里最大的事务id，加个1，就是这个read view的上边界，叫max_trx_id。 概念太多，有点乱？没事的，继续往下看，后面会有例子的。 事务能读哪些快照有了这些基础信息之后，我们先看下事务在read view下，他能读哪些快照呢？ 记住一个大前提：事务只能读到自己产生的undo日志数据（事务提不提交都行），或者是其他事务已经提交完成的数据。 现在事务（假设就叫事务A吧）有了read view之后，不管看哪个undo日志版本链，我们都可以把read view往版本链上一放。版本链就被分成了好几部分。 版本链快照的trx_id &lt; read view的min_trx_id 从上面的描述中，我们可以知道read view的m_ids来源于数据库所有活跃事务的id，而最小的min_trx_id就是read view的下边界，因为事务id是根据时间递增的，所以如果版本链快照的trx_id比 min_trx_id 还要小，那这些肯定都是非活跃（已经提交）的事务id，这些快照都能被事务A读到。 版本链快照的trx_id &gt;= read view的max_trx_id max_trx_id是在事务A创建read view的那一刻产生的，它比那时候所有数据库已知的事务id都还要大。所以如果undo日志版本链上的某个快照上含有比 max_trx_id 还要大的 trx_id，那说明这个快照已经超出事务A的”理解范围了”，它不该被读到。 read view的min_trx_id &lt;= 版本链快照的trx_id &lt; read view的max_trx_id 如果版本链快照的trx_id正好就是事务A的id，那正好是它自己生成的undo日志快照，那不管有没有提交，都能读。 如果版本链快照的trx_id正好在活跃事务m_ids中, 那这些事务数据都还没提交，所以事务A不能读到它们 除了上面两种情况外，剩下的都是已经提交的事务数据，可以放心读。 事务会读哪个快照上面提到，事务在read view的可见范围里，有机会能读到N多快照。但那么多快照版本，事务具体会读哪个快照呢？ 事务会从表头开始遍历这个undo日志版本链，它会拿每个undo日志里的trx_id去跟自己的read view的上下边界去做判断。第一个出现的小于max_trx_id的快照。 如果快照是自己产生，那提不提交都行，就决定是读它了。 如果快照是别人产生的，且已经提交完成了，那也行，决定读它了。 比如下图，undo日志1正好小于max_trx_id，且事务已经提交，那么就读它了。 MVCC是什么像上面这种，维护一个多快照的undo日志版本链，事务根据自己的read view去决定具体读那个undo日志快照，最理想的情况下是每个事务都读自己的一份快照，然后在这个快照上做自己的逻辑，只有在写数据的时候，才去操作最新的行数据，这样读和写就被分开了，比起单行数据没有快照的方式，它能更好的解决读写冲突，所以数据库并发性能也更好。其实这就是面试里常问的MVCC，全称Multi-Version Concurrency Control，即多版本并发控制。 四个隔离级别是怎么实现的之前的写的一篇文章最后留了个问题，四个隔离级别是怎么实现的。 知道了undo日志版本链和MVCC之后，我们再回过头来看下这个问题。 读未提交，每次读到的都是最新的数据，也不管数据行所在的事务是否提交。实现也很简单，只需要每次都读undo日志版本链的链表头（最新的快照）就行了。 与读未提交不同，读提交和可重复读隔离级别都是基于MVCC的read view实现的，反过来说, MVCC也只会出现在这两个隔离级别里。 读已提交隔离级别，每次执行普通select，都会重新生成一个新的read view，然后拿着这个最新的read view到某行数据的版本链上挨个遍历，找到第一个合适的数据。这样就能做到每次都读到其他事务最新已提交的数据。 可重复读隔离级别下的事务只会在第一次执行普通select时生成read view，后续不管执行几次普通select，都会复用这个 read view。这样就能保持每次读的时候都是在同一标准下进行读取，那读到的数据也会是一样的。 串行化目的就是让并发事务看起来就像单线程执行一样，那实现也很简单，和读未提交隔离级别一样，串行化隔离界别下事务只读undo日志链的链表头，也就是最新版本的快照，并且就算是普通select，也会在版本链的最新快照上加入读锁。这样其他事务想写，也得等这个读锁释放掉才行。所有对这行数据进行操作的事务，都老老实实地阻塞等待加锁，一个接一个进行处理，从效果上看就跟单线程处理一样。 再看文章开头的例子我们用上面提到的概念，重新回到文章开头的例子，梳理一遍。 我们假设数据库一开始的三条数据，都是由trx_id=1的事务insert生成的。 于是数据表一开始长下面这样。每行数据只有一个快照。注意快照里，trx_id填的是创建它们的事务id，也就是刚刚提到的事务1。roll_pointer原本应该指向insert产生的undo日志，为了简化，这里写为null（insert undo日志在事务提交后可以被清理掉）。 下面这个图，还是文章开头的图，这里放出来是为了方便大家，不用划回去看了。 在线程1启动事务，我们假设它的事务trx_id=2，第一次执行普通select，是快照读，在可重复读隔离级别，会生成一个read view。当前这个数据库，活跃事务只有它一个，那m_ids =[2]。 m_ids里最小的id，也就是min_trx_id=2。max_trx_id是当前最大数据库事务id（只有它自己，所以也是2），加个1，也就是max_trx_id=3 此时线程1的事务，拿着这个read view去读数据库表。 因为这三条数据的trx_id=1都小于min_trx_id=2，都属于可见范围，因此能读到这三条数据的所有快照，最后返回符合条件（age&gt;=3）的数据，有1条。 这时候事务2，假设它的事务trx_id=3，执行更新操作，生成新的undo日志快照。 此时线程1第二次执行普通select，还是快照读，由于是可重复读，会复用之前的read view，再执行一次读操作，这里重点关注id=2的那行数据，从版本链表头开始遍历，第一个快照trx_id=3 &gt;= read view的max_trx_id=3，因此不可读，遍历下一个快照trx_id=1 &lt; min_trx_id=2，可读。于是id=2的那行数据，还是拿到age=2，而不是更新后的age=3，因此快照读结果还是只有1条数据符合age&gt;=3。 但是线程1第三次读，执行select for update，就成了当前读了，直接读undo日志版本链里最新的那行快照，于是能读到id=2，age=3，所以最终结果返回符合age&gt;=3的数据有2条。 总的来说就是，由于快照读和当前读，读数据的规则不同，我们看到了不一样的结果。 看到这里，大家应该理解了，所谓的可重复读每次读都要读到一样的数据，这里头的**”读”，指的是快照读**。 如果下次面试官问你，可重复读隔离级别下每次读到的数据都是一样的吗？ 你该知道怎么回答了吧？ 总结 事务通过undo日志实现回滚的功能，从而实现事务的原子性（Atomicity）。 多个事务生成的undo日志构成一条版本链。快照读时事务根据read view来决定具体读哪个快照。当前读时事务直接读最新的快照版本。 mysql的innodb引擎通过MVCC提升了读写并发。 最后最近原创更文的阅读量稳步下跌，思前想后，夜里辗转反侧。 我有个不成熟的请求。 离开广东好长时间了，好久没人叫我靓仔了。 大家可以在评论区里，叫我一靓仔吗？ 我这么善良质朴的愿望，能被满足吗？ 如果实在叫不出口的话，能帮我点下右下角的点赞和在看吗？ 别说了，一起在知识的海洋里呛水吧点击下方名片，关注公众号:【小白debug】 不满足于在留言区说骚话？ 加我，我们建了个划水吹牛皮群，在群里，你可以跟你下次跳槽可能遇到的同事或面试官聊点有意思的话题。就超！开！心！ 文章推荐： 程序员防猝死指南 TCP粘包 数据包：我只是犯了每个数据包都会犯的错 |硬核图解 动图图解！既然IP层会分片，为什么TCP层也还要分段？","categories":[{"name":"图解mysql","slug":"图解mysql","permalink":"https://xiaobaidebug.top/categories/%E5%9B%BE%E8%A7%A3mysql/"}],"tags":[]},{"title":"Mysql的索引为什么使用B+树而不使用跳表？","slug":"图解mysql/Mysql的索引为什么使用B+树而不使用跳表？","date":"2022-04-16T14:57:55.000Z","updated":"2022-10-30T02:28:13.642Z","comments":true,"path":"2022/04/16/图解mysql/Mysql的索引为什么使用B+树而不使用跳表？/","link":"","permalink":"https://xiaobaidebug.top/2022/04/16/%E5%9B%BE%E8%A7%A3mysql/Mysql%E7%9A%84%E7%B4%A2%E5%BC%95%E4%B8%BA%E4%BB%80%E4%B9%88%E4%BD%BF%E7%94%A8B+%E6%A0%91%E8%80%8C%E4%B8%8D%E4%BD%BF%E7%94%A8%E8%B7%B3%E8%A1%A8%EF%BC%9F/","excerpt":"","text":"mysql的索引为什么使用B+树而不使用跳表？ 在我们的印象中，mysql数据表里无非就是存储一行行的数据。跟个excel似的。 直接遍历这一行行数据，性能就是O(n)，比较慢。为了加速查询，使用了B+树来做索引，将查询性能优化到了**O(lg(n))**。 但问题就来了，查询数据性能在 lg(n) 级别的数据结构有很多，比如redis的zset里用到的跳表，也是**lg(n)**，并且实现还贼简单。 那为什么mysql的索引，不使用跳表呢？ 我们今天就来聊聊这个话题。 B+树的结构之前的一篇文章里，已经提到过B+树的结构了。文章不长，如果没看过，建议先看下。 当然，不看也行。 在这里，为了混点字数，我简单总结下B+树的结构。 如上图，一般B+树是由多个页组成的多层级结构，每个页16Kb，对于主键索引来说，最末级的叶子结点放行数据，非叶子结点放的则是索引信息（主键id和页号），用于加速查询。 比方说我们想要查找行数据5。会先从顶层页的record们入手。record里包含了主键id和页号（页地址）。关注黄色的箭头，向左最小id是1，向右最小id是7。那id=5的数据如果存在，那必定在左边箭头。于是顺着的record的页地址就到了6号数据页里，再判断id=5&gt;4，所以肯定在右边的数据页里，于是加载105号数据页。 在105号数据页里，虽然有多行数据，但也不是挨个遍历的，数据页内还有个页目录的信息，它可以通过二分查找的方式加速查询行数据，于是找到id=5的数据行，完成查询。 从上面可以看出，B+树利用了空间换时间的方式（构造了一批非叶子结点用于存放索引信息），**将查询时间复杂度从O(n)优化为O(lg(n))**。 跳表的结构看完B+树，我们再来看下跳表是怎么来的。 同样的，还是为了存储一行行的数据。 我们可以将它们用链表串起来。 想要查询链表中的其中一个结点，时间复杂度是O(n)，这谁顶得住，于是将部分链表结点提出来，再构建出一个新的链表。 这样当我想要查询一个数据的时候，我先查上层的链表，就很容易知道数据落在哪个范围，然后跳到下一个层级里进行查询。这样就把搜索范围一下子缩小了一大半。 比如查询id=10的数据，我们先在上层遍历，依次判断1,6,12，很快就可以判断出10在6到12之间，然后往下一跳，就可以在遍历6,7,8,9,10之后，确定id=10的位置。直接将查询范围从原来的1到10，变成现在的1,6,7,8,9,10，算是砍半了。 既然两层链表就直接将查询范围砍半了，那我多加几层，岂不妙哉？ 于是跳表就这样变成了多层。 如果还是查询id=10的数据，就只需要查询1,6,9,10就能找到，比两层的时候更快一些。 可以看出，跳表也是通过牺牲空间换取时间的方式提升查询性能。**时间复杂度都是lg(n)**。 B+树和跳表的区别从上面可以看到，B+树和跳表的最下面一层，都包含了所有的数据，且都是顺序的，适合用于范围查询。往上的层级都是构建出来用于提升搜索性能的。这两者实在是太像了。但他们两者在新增和删除数据时，还是有些区别的。下面我们以新增数据为例聊一下。 B+树新增数据会怎么样B+树本质上是一种多叉平衡二叉树。关键在于”平衡“这两个字，对于多叉树结构来说，它的含义是子树们的高度层级尽量一致（一般最多差一个层级），这样在搜索的时候，不管是到哪个子树分支，搜索次数都差不了太多。 当数据库表不断插入新的数据时，为了维持B+树的平衡，B+树会不断分裂调整数据页。 我们知道B+树分为叶子结点和非叶子结点。 当插入一条数据时，叶子结点和它上层的索引结点（非叶子结点）最大容量都是16k，它们都有可能会满。 为了简化问题，我们假设一个数据页只能放三条行数据或索引。 加入一条数据，根据数据页会不会满，分为三种情况。 叶子结点和索引结点都没满。这种情况最简单，直接插入到叶子结点中就好了。 叶子结点满了，但索引结点没满。此时需要拆分叶子结点，同时索引结点要增加新的索引信息。 叶子结点满了，且索引结点也满了。叶子和索引结点都要拆分，同时往上还要再加一层索引。 从上面可以看到，只有在叶子和索引结点都满了的情况下，B+树才会考虑加入一层新的结点。 而从之前的文章知道，要把三层B+树塞满，那大概需要2kw左右的数据。 跳表新增数据跳表同样也是很多层，新增一个数据时，最底层的链表需要插入数据。 此时，是否需要在上面的几层中加入数据做索引呢？ 这个就纯靠随机函数了。 理论上为了达到二分的效果，每一层的结点数需要是下一层结点数的二分之一。 也就是说现在有一个新的数据插入了，它有50%的概率需要在第二层加入索引，有25%的概率需要在第三层加个索引，以此类推，直到最顶层。 举个例子，如果跳表中插入数据id=6，且随机函数返回第三层（有25%的概率），那就需要在跳表的最底层到第三层都插入数据。 如果这个随机函数设计成上面这样，当数据量样本足够大的时候，数据的分布就符合我们理想中的”二分”。 跟上面B+树不一样，跳表是否新增层数，纯粹靠随机函数，根本不关心前后上下结点。 好了，基础科普也结束了，我们可以进入正题了。 mysql的索引为什么使用B+树而不使用跳表？B+树是多叉树结构，每个结点都是一个16k的数据页，能存放较多索引信息，所以扇出很高。三层左右就可以存储2kw左右的数据（知道结论就行，想知道原因可以看之前的文章）。也就是说查询一次数据，如果这些数据页都在磁盘里，那么最多需要查询三次磁盘IO。 跳表是链表结构，一条数据一个结点，如果最底层要存放2kw数据，且每次查询都要能达到二分查找的效果，2kw大概在2的24次方左右，所以，跳表大概高度在24层左右。最坏情况下，这24层数据会分散在不同的数据页里，也即是查一次数据会经历24次磁盘IO。 因此存放同样量级的数据，B+树的高度比跳表的要少，如果放在mysql数据库上来说，就是磁盘IO次数更少，因此B+树查询更快。 而针对写操作，B+树需要拆分合并索引数据页，跳表则独立插入，并根据随机函数确定层数，没有旋转和维持平衡的开销，因此跳表的写入性能会比B+树要好。 其实，mysql的存储引擎是可以换的，以前是myisam，后来才有的innodb，它们底层索引用的都是B+树。也就是说，你完全可以造一个索引为跳表的存储引擎装到mysql里。事实上，facebook造了个rocksDB的存储引擎，里面就用了跳表。直接说结论，它的写入性能确实是比innodb要好，但读性能确实比innodb要差不少。感兴趣的话，可以在文章最后面的参考资料里看到他们的性能对比数据。 redis为什么使用跳表而不使用B+树或二叉树呢？redis支持多种数据结构，里面有个有序集合，也叫ZSET。内部实现就是跳表。那为什么要用跳表而不用B+树等结构呢？ 这个几乎每次面试都要被问一下。 虽然已经很熟了，但每次都要装作之前没想过，现场思考一下才知道答案。 真的，很考验演技。 大家知道，redis 是纯纯的内存数据库。 进行读写数据都是操作内存，跟磁盘没啥关系，因此也不存在磁盘IO了，所以层高就不再是跳表的劣势了。 并且前面也提到B+树是有一系列合并拆分操作的，换成红黑树或者其他AVL树的话也是各种旋转，目的也是为了保持树的平衡。 而跳表插入数据时，只需要随机一下，就知道自己要不要往上加索引，根本不用考虑前后结点的感受，也就少了旋转平衡的开销。 因此，redis选了跳表，而不是B+树。 总结 B+树是多叉平衡搜索树，扇出高，只需要3层左右就能存放2kw左右的数据，同样情况下跳表则需要24层左右，假设层高对应磁盘IO，那么B+树的读性能会比跳表要好，因此mysql选了B+树做索引。 redis的读写全在内存里进行操作，不涉及磁盘IO，同时跳表实现简单，相比B+树、AVL树、少了旋转树结构的开销，因此redis使用跳表来实现ZSET，而不是树结构。 存储引擎RocksDB内部使用了跳表，对比使用B+树的innodb，虽然写性能更好，但读性能属实差了些。在读多写少的场景下，B+树依旧YYDS。 参考资料《MYSQL内核：INNODB存储引擎 卷1》 《RocksDB和Innodb引擎性能PK胜负难料？》 https://cloud.tencent.com/developer/article/1813695 最后 最近在看《龙蛇演义》，剧情很一般，但我硬是一口气看到了最新一集，还很上头。 为啥？ 点开它，看到女主角的时候你就理解我了。 这么说吧，一个颜值出众，身材火辣的姐姐，还是个世界顶级的武术高手，穿着旗袍，踩着高跟，做着各种让牛顿棺材板都快要按不住的动作，只为手把手教会你武术基本功。 这时候，剧情还重要吗？ 不得不说，当我看到姐姐穿成这样用木棍顶起400斤的汞球时。 我可以肯定，导演根本不懂物理。 但是！ 导演很懂男人! 这不得不让我陷入沉思，到底什么才是好的内容? 难道现在有个大姐姐穿个黑丝高跟超短裙，教你变量的声明和定义这么基础的东西，你也会去看吗？ 我不知道你们会不会。 反正我会。 最近原创更文的阅读量稳步下跌，思前想后，夜里辗转反侧。 我有个不成熟的请求。 离开广东好长时间了，好久没人叫我靓仔了。 大家可以在评论区里，叫我一靓仔吗？ 我这么善良质朴的愿望，能被满足吗？ 如果实在叫不出口的话，能帮我点下右下角的点赞和在看吗？ 别说了，一起在知识的海洋里呛水吧点击下方名片，关注公众号:【小白debug】 不满足于在留言区说骚话？ 加我，我们建了个划水吹牛皮群，在群里，你可以跟你下次跳槽可能遇到的同事或面试官聊点有意思的话题。就超！开！心！ 文章推荐： 程序员防猝死指南 TCP粘包 数据包：我只是犯了每个数据包都会犯的错 |硬核图解 动图图解！既然IP层会分片，为什么TCP层也还要分段？","categories":[{"name":"图解mysql","slug":"图解mysql","permalink":"https://xiaobaidebug.top/categories/%E5%9B%BE%E8%A7%A3mysql/"}],"tags":[]},{"title":"为什么大家说mysql数据库单表最大两千万？依据是啥？","slug":"图解mysql/为什么大家说mysql数据库单表最大两千万？依据是啥？","date":"2022-04-05T14:57:55.000Z","updated":"2022-10-30T02:28:15.401Z","comments":true,"path":"2022/04/05/图解mysql/为什么大家说mysql数据库单表最大两千万？依据是啥？/","link":"","permalink":"https://xiaobaidebug.top/2022/04/05/%E5%9B%BE%E8%A7%A3mysql/%E4%B8%BA%E4%BB%80%E4%B9%88%E5%A4%A7%E5%AE%B6%E8%AF%B4mysql%E6%95%B0%E6%8D%AE%E5%BA%93%E5%8D%95%E8%A1%A8%E6%9C%80%E5%A4%A7%E4%B8%A4%E5%8D%83%E4%B8%87%EF%BC%9F%E4%BE%9D%E6%8D%AE%E6%98%AF%E5%95%A5%EF%BC%9F/","excerpt":"","text":"故事从好多年前说起。 想必大家也听说过数据库单表建议最大2kw条数据这个说法。如果超过了，性能就会下降得比较厉害。 巧了。 我也听说过。 但我不接受它的建议，硬是单表装了1亿条数据。 这时候，我们组里新来的实习生看到了之后，天真无邪的问我：”单表不是建议最大两千万吗？为什么这个表都放了1个亿还不分库分表“？ 我能说我是因为懒吗？我当初设计时哪里想到这表竟然能涨这么快。。。 我不能。 说了等于承认自己是开发组里的毒瘤，虽然我确实是，但我不能承认。 我如坐针毡，如芒刺背，如鲠在喉。 开始了一波骚操作。 “我这么做是有道理的” “虽然这个表很大，但你有没有发现它查询其实还是很快” “这个2kw是个建议值，我们要来看下这个2kw是怎么来的” 数据库单表行数最大多大？我们先看下单表行数理论最大值是多少。 建表的SQL是这么写的， 1234567CREATE TABLE `user` ( `id` int(10) unsigned NOT NULL AUTO_INCREMENT COMMENT &#x27;主键&#x27;, `name` varchar(100) NOT NULL DEFAULT &#x27;&#x27; COMMENT &#x27;名字&#x27;, `age` int(11) NOT NULL DEFAULT &#x27;0&#x27; COMMENT &#x27;年龄&#x27;, PRIMARY KEY (`id`), KEY `idx_age` (`age`)) ENGINE=InnoDB AUTO_INCREMENT=100037 DEFAULT CHARSET=utf8; 其中id就是主键。主键本身唯一，也就是说主键的大小可以限制表的上限。 如果主键声明为int大小，也就是32位，那么能支持2^32-1，也就是21个亿左右。 如果是bigint，那就是2^64-1，但这个数字太大，一般还没到这个限制之前，磁盘先受不了。 搞离谱点。 如果我把主键声明为 tinyint，一个字节，8位，最大2^8-1，也就是255。 1234567CREATE TABLE `user` ( `id` tinyint(2) unsigned NOT NULL AUTO_INCREMENT COMMENT &#x27;主键&#x27;, `name` varchar(100) NOT NULL DEFAULT &#x27;&#x27; COMMENT &#x27;名字&#x27;, `age` int(11) NOT NULL DEFAULT &#x27;0&#x27; COMMENT &#x27;年龄&#x27;, PRIMARY KEY (`id`), KEY `idx_age` (`age`)) ENGINE=InnoDB AUTO_INCREMENT=0 DEFAULT CHARSET=utf8; 如果我想插入一个id=256的数据，那就会报错。 12mysql&gt; INSERT INTO `tmp` (`id`, `name`, `age`) VALUES (256, &#x27;&#x27;, 60);ERROR 1264 (22003): Out of range value for column &#x27;id&#x27; at row 1 也就是说，tinyint主键限制表内最多255条数据。 那除了主键，还有哪些因素会影响行数？ 索引的结构索引内部是用的B+树，这个也是八股文老股了，大家估计也背得很熟了。 为了不让大家有过于强烈的审丑疲劳，今天我尝试从另外一个角度给大家讲讲这玩意。 页的结构假设我们有这么一张user数据表。 其中id是唯一主键。 这看起来的一行行数据，为了方便，我们后面就叫它们record吧。 这张表看起来就跟个excel表格一样。excel的数据在硬盘上是一个xx.excel的文件。 而上面user表数据，在硬盘上其实也是类似，放在了user.ibd文件下。含义是user表的innodb data文件，专业点，又叫表空间。 虽然在数据表里，它们看起来是挨在一起的。但实际上在user.ibd里他们被分成很多小份的数据页，每份大小16k。 类似于下面这样。 我们把视角聚焦一下，放到页上面。 整个页16k，不大，但record这么多，一页肯定放不下，所以会分开放到很多页里。并且这16k，也不可能全用来放record对吧。 因为record们被分成好多份，放到好多页里了，为了唯一标识具体是哪一页，那就需要引入页号（其实是一个表空间的地址偏移量）。同时为了把这些数据页给关联起来，于是引入了前后指针，用于指向前后的页。这些都被加到了页头里。 页是需要读写的，16k说小也不小，写一半电源线被拔了也是有可能发生的，所以为了保证数据页的正确性，还引入了校验码。这个被加到了页尾。 那剩下的空间，才是用来放我们的record的。而record如果行数特别多的话，进入到页内时挨个遍历，效率也不太行，所以为这些数据生成了一个页目录，具体实现细节不重要。只需要知道，它可以通过二分查找的方式将查找效率**从O(n) 变成O(lgn)**。 从页到索引如果想查一条record，我们可以把表空间里每一页都捞出来，再把里面的record捞出来挨个判断是不是我们要找的。 行数量小的时候，这么操作也没啥问题。 行数量大了，性能就慢了，于是为了加速搜索，我们可以在每个数据页里选出主键id最小的record，而且只需要它们的主键id和所在页的页号。组成新的record，放入到一个新生成的一个数据页中，这个新数据页跟之前的页结构没啥区别，而且大小还是16k。 但为了跟之前的数据页进行区分。数据页里加入了页层级（page level）的信息，从0开始往上算。于是页与页之间就有了上下层级的概念，就像下面这样。 突然页跟页之间看起来就像是一棵倒过来的树了。也就是我们常说的B+树索引。 最下面那一层，page level 为0，也就是所谓的叶子结点，其余都叫非叶子结点。 上面展示的是两层的树，如果数据变多了，我们还可以再通过类似的方法，再往上构建一层。就成了三层的树。 那现在我们就可以通过这样一棵B+树加速查询。举个例子。 比方说我们想要查找行数据5。会先从顶层页的record们入手。record里包含了主键id和页号（页地址）。看下图黄色的箭头，向左最小id是1，向右最小id是7。那id=5的数据如果存在，那必定在左边箭头。于是顺着的record的页地址就到了6号数据页里，再判断id=5&gt;4，所以肯定在右边的数据页里，于是加载105号数据页。在数据页里找到id=5的数据行，完成查询。 另外需要注意的是，上面的页的页号并不是连续的，它们在磁盘里也不一定是挨在一起的。 这个过程中查询了三个页，如果这三个页都在磁盘中（没有被提前加载到内存中），那么最多需要经历三次磁盘IO查询，它们才能被加载到内存中。 B+树承载的记录数量从上面的结构里可以看出B+树的最末级叶子结点里放了record数据。而非叶子结点里则放了用来加速查询的索引数据。 也就是说 同样一个16k的页，非叶子节点里每一条数据都指向一个新的页，而新的页有两种可能。 如果是末级叶子节点的话，那么里面放的就是一行行record数据。 如果是非叶子节点，那么就会循环继续指向新的数据页。 假设 非叶子结点内指向其他内存页的指针数量为x 叶子节点内能容纳的record数量为y B+树的层数为z 那这棵B+树放的行数据总量等于 (x ^ (z-1)) * y。 x怎么算我们回去看数据页的结构。 非叶子节点里主要放索引查询相关的数据，放的是主键和指向页号。 主键假设是bigint（8Byte），而页号在源码里叫FIL_PAGE_OFFSET（4Byte），那么非叶子节点里的一条数据是12Byte左右。 整个数据页16k， 页头页尾那部分数据全加起来大概128Byte，加上页目录毛估占1k吧。那剩下的15k除以12Byte，等于1280，也就是可以指向x=1280页。 我们常说的二叉树指的是一个结点可以发散出两个新的结点。m叉树一个节点能指向m个新的结点。这个指向新节点的操作就叫扇出（fanout）。 而上面的B+树，它能指向1280个新的节点，恐怖如斯，可以说扇出非常高了。 y的计算叶子节点和非叶子节点的数据结构是一样的，所以也假设剩下15kb可以发挥。 叶子节点里放的是真正的行数据。假设一条行数据1kb，所以一页里能放y=15行。 行总数计算回到 (x ^ (z-1)) * y 这个公式。 已知x=1280，y=15。 假设B+树是两层，那z=2。则是(1280 ^ (2-1)) * 15 ≈ 2w 假设B+树是三层，那z=3。则是(1280 ^ (3-1)) * 15 ≈ 2.5kw 这个2.5kw，就是我们常说的单表建议最大行数2kw的由来。毕竟再加一层，数据就大得有点离谱了。三层数据页对应最多三次磁盘IO，也比较合理。 行数超一亿就慢了吗？上面假设单行数据用了1kb，所以一个数据页能放个15行数据。 如果我单行数据用不了这么多，比如只用了250byte。那么单个数据页能放60行数据。 那同样是三层B+树，单表支持的行数就是 (1280 ^ (3-1)) * 60 ≈ 1个亿。 你看我一个亿的数据，其实也就三层B+树，在这个B+树里要查到某行数据，最多也是三次磁盘IO。所以并不慢。 这就很好的解释了文章开头，为什么我单表1个亿，但查询性能没啥大毛病。 B树承载的记录数量既然都聊到这里了，我们就顺着这个话题多聊一些吧。 我们都知道，现在mysql的索引都是B+树，而有一种树，跟B+树很像，叫B树，也叫B-树。 它跟B+树最大的区别在于，B+树只在末级叶子结点处放数据表行数据，而B树则会在叶子和非叶子结点上都放。 于是，B树的结构就类似这样 B树将行数据都存在非叶子节点上，假设每个数据页还是16kb，掐头去尾每页剩15kb，并且一条数据表行数据还是占1kb，就算不考虑各种页指针的情况下，也只能放个15条数据。数据页扇出明显变少了。 计算可承载的总行数的公式也变成了一个等比数列。 115 + 15^2 +15^3 + ... + 15^z 其中z还是层数的意思。 为了能放2kw左右的数据，需要z&gt;=6。也就是树需要有6层，查一次要访问6个页。假设这6个页并不连续，为了查询其中一条数据，最坏情况需要进行6次磁盘IO。 而B+树同样情况下放2kw数据左右，查一次最多是3次磁盘IO。 磁盘IO越多则越慢，这两者在性能上差距略大。 为此，B+树比B树更适合成为mysql的索引。 总结 B+树叶子和非叶子结点的数据页都是16k，且数据结构一致，区别在于叶子节点放的是真实的行数据，而非叶子结点放的是主键和下一个页的地址。 B+树一般有两到三层，由于其高扇出，三层就能支持2kw以上的数据，且一次查询最多1~3次磁盘IO，性能也还行。 存储同样量级的数据，B树比B+树层级更高，因此磁盘IO也更多，所以B+树更适合成为mysql索引。 索引结构不会影响单表最大行数，2kw也只是推荐值，超过了这个值可能会导致B+树层级更高，影响查询性能。 单表最大值还受主键大小和磁盘大小限制。 参考资料《MYSQL内核：INNODB存储引擎 卷1》 最后 虽然我在单表里塞了1亿条数据，但这个操作的前提是，我很清楚这不会太影响性能。 这波解释，毫无破绽，无懈可击。 到这里，连我自己都被自己说服了。想必实习生也是。 可恶，这该死的毒瘤竟然有些”知识渊博”。 最近原创更文的阅读量稳步下跌，思前想后，夜里辗转反侧。 我有个不成熟的请求。 离开广东好长时间了，好久没人叫我靓仔了。 大家可以在评论区里，叫我一靓仔吗？ 我这么善良质朴的愿望，能被满足吗？ 如果实在叫不出口的话，能帮我点下右下角的点赞和在看吗？ 别说了，一起在知识的海洋里呛水吧点击下方名片，关注公众号:【小白debug】 不满足于在留言区说骚话？ 加我，我们建了个划水吹牛皮群，在群里，你可以跟你下次跳槽可能遇到的同事或面试官聊点有意思的话题。就超！开！心！ 文章推荐： 程序员防猝死指南 TCP粘包 数据包：我只是犯了每个数据包都会犯的错 |硬核图解 动图图解！既然IP层会分片，为什么TCP层也还要分段？","categories":[{"name":"图解mysql","slug":"图解mysql","permalink":"https://xiaobaidebug.top/categories/%E5%9B%BE%E8%A7%A3mysql/"}],"tags":[]},{"title":"Mysql数据库查询好慢，除了索引，还能因为什么？","slug":"图解mysql/Mysql数据库查询好慢，除了索引，还能因为什么？","date":"2022-03-22T14:57:55.000Z","updated":"2022-10-30T02:28:13.642Z","comments":true,"path":"2022/03/22/图解mysql/Mysql数据库查询好慢，除了索引，还能因为什么？/","link":"","permalink":"https://xiaobaidebug.top/2022/03/22/%E5%9B%BE%E8%A7%A3mysql/Mysql%E6%95%B0%E6%8D%AE%E5%BA%93%E6%9F%A5%E8%AF%A2%E5%A5%BD%E6%85%A2%EF%BC%8C%E9%99%A4%E4%BA%86%E7%B4%A2%E5%BC%95%EF%BC%8C%E8%BF%98%E8%83%BD%E5%9B%A0%E4%B8%BA%E4%BB%80%E4%B9%88%EF%BC%9F/","excerpt":"我熟练应用ctrl c和ctrl v 开发curd代码好多年了。 mysql查询为什么会慢，关于这个问题，在实际开发经常会遇到，而面试中，也是个高频题。 遇到这种问题，我们一般也会想到是因为索引。 那除开索引之外，还有哪些因素会导致数据库查询变慢呢？ 有哪些操作，可以提升mysql的查询能力呢？ 今天这篇文章，我们就来聊聊会导致数据库查询变慢的场景有哪些，并给出原因和解决方案。 数据库查询流程我们先来看下，一条查询语句下来，会经历哪些流程。 比如我们有一张数据库表 123456789CREATE TABLE `user` ( `id` int(10) unsigned NOT NULL AUTO_INCREMENT COMMENT &#x27;主键&#x27;, `name` varchar(100) NOT NULL DEFAULT &#x27;&#x27; COMMENT &#x27;名字&#x27;, `age` int(11) NOT NULL DEFAULT &#x27;0&#x27; COMMENT &#x27;年龄&#x27;, `gender` int(8) NOT NULL DEFAULT &#x27;0&#x27; COMMENT &#x27;性别&#x27;, PRIMARY KEY (`id`), KEY `idx_age` (`age`), KEY `idx_gender` (`gender`)) ENGINE=InnoDB DEFAULT CHARSET=utf8; 我们平常写的应用代码（go或C++之类的），这时候就叫客户端了。 客户端底层会带着账号密码，尝试向mysql建立一条TCP长链接。 mysql的连接管理模块会对这条连接进行管理。 建立连接后，客户端执行一条查询sql语句。 比如： 1select * from user where gender = 1 and age = 100; 客户端会将sql语句通过网络连接给mysql。 mysql收到sql语句后，会在分析器中先判断下SQL语句有没有语法错误，比如select，如果少打一个l，写成slect，则会报错You have an error in your SQL syntax; 。这个报错对于我这样的手残党来说可以说是很熟悉了。 接下来是优化器，在这里会根据一定的规则选择该用什么索引。 之后，才是通过执行器去调用存储引擎的接口函数。","text":"我熟练应用ctrl c和ctrl v 开发curd代码好多年了。 mysql查询为什么会慢，关于这个问题，在实际开发经常会遇到，而面试中，也是个高频题。 遇到这种问题，我们一般也会想到是因为索引。 那除开索引之外，还有哪些因素会导致数据库查询变慢呢？ 有哪些操作，可以提升mysql的查询能力呢？ 今天这篇文章，我们就来聊聊会导致数据库查询变慢的场景有哪些，并给出原因和解决方案。 数据库查询流程我们先来看下，一条查询语句下来，会经历哪些流程。 比如我们有一张数据库表 123456789CREATE TABLE `user` ( `id` int(10) unsigned NOT NULL AUTO_INCREMENT COMMENT &#x27;主键&#x27;, `name` varchar(100) NOT NULL DEFAULT &#x27;&#x27; COMMENT &#x27;名字&#x27;, `age` int(11) NOT NULL DEFAULT &#x27;0&#x27; COMMENT &#x27;年龄&#x27;, `gender` int(8) NOT NULL DEFAULT &#x27;0&#x27; COMMENT &#x27;性别&#x27;, PRIMARY KEY (`id`), KEY `idx_age` (`age`), KEY `idx_gender` (`gender`)) ENGINE=InnoDB DEFAULT CHARSET=utf8; 我们平常写的应用代码（go或C++之类的），这时候就叫客户端了。 客户端底层会带着账号密码，尝试向mysql建立一条TCP长链接。 mysql的连接管理模块会对这条连接进行管理。 建立连接后，客户端执行一条查询sql语句。 比如： 1select * from user where gender = 1 and age = 100; 客户端会将sql语句通过网络连接给mysql。 mysql收到sql语句后，会在分析器中先判断下SQL语句有没有语法错误，比如select，如果少打一个l，写成slect，则会报错You have an error in your SQL syntax; 。这个报错对于我这样的手残党来说可以说是很熟悉了。 接下来是优化器，在这里会根据一定的规则选择该用什么索引。 之后，才是通过执行器去调用存储引擎的接口函数。 存储引擎类似于一个个组件，它们才是mysql真正获取一行行数据并返回数据的地方，存储引擎是可以替换更改的，既可以用不支持事务的MyISAM，也可以替换成支持事务的Innodb。这个可以在建表的时候指定。比如 123CREATE TABLE `user` ( ...) ENGINE=InnoDB; 现在最常用的是InnoDB。 我们就重点说这个。 InnoDB中，因为直接操作磁盘会比较慢，所以加了一层内存提提速，叫buffer pool，这里面，放了很多内存页，每一页16KB，有些内存页放的是数据库表里看到的那种一行行的数据，有些则是放的索引信息。 查询SQL到了InnoDB中。会根据前面优化器里计算得到的索引，去查询相应的索引页，如果不在buffer pool里则从磁盘里加载索引页。再通过索引页加速查询，得到数据页的具体位置。如果这些数据页不在buffer pool中，则从磁盘里加载进来。 这样我们就得到了我们想要的一行行数据。 最后将得到的数据结果返回给客户端。 慢查询分析如果上面的流程比较慢的话，我们可以通过开启profiling看到流程慢在哪。 12345678910mysql&gt; set profiling=ON;Query OK, 0 rows affected, 1 warning (0.00 sec)mysql&gt; show variables like &#x27;profiling&#x27;;+---------------+-------+| Variable_name | Value |+---------------+-------+| profiling | ON |+---------------+-------+1 row in set (0.00 sec) 然后正常执行sql语句。 这些SQL语句的执行时间都会被记录下来，此时你想查看有哪些语句被记录下来了，可以执行 show profiles; 1234567891011mysql&gt; show profiles;+----------+------------+---------------------------------------------------+| Query_ID | Duration | Query |+----------+------------+---------------------------------------------------+| 1 | 0.06811025 | select * from user where age&gt;=60 || 2 | 0.00151375 | select * from user where gender = 2 and age = 80 || 3 | 0.00230425 | select * from user where gender = 2 and age = 60 || 4 | 0.00070400 | select * from user where gender = 2 and age = 100 || 5 | 0.07797650 | select * from user where age!=60 |+----------+------------+---------------------------------------------------+5 rows in set, 1 warning (0.00 sec) 关注下上面的query_id，比如select * from user where age&gt;=60 对应的query_id是1，如果你想查看这条SQL语句的具体耗时，那么可以执行以下的命令。 123456789101112131415161718192021mysql&gt; show profile for query 1;+----------------------+----------+| Status | Duration |+----------------------+----------+| starting | 0.000074 || checking permissions | 0.000010 || Opening tables | 0.000034 || init | 0.000032 || System lock | 0.000027 || optimizing | 0.000020 || statistics | 0.000058 || preparing | 0.000018 || executing | 0.000013 || Sending data | 0.067701 || end | 0.000021 || query end | 0.000015 || closing tables | 0.000014 || freeing items | 0.000047 || cleaning up | 0.000027 |+----------------------+----------+15 rows in set, 1 warning (0.00 sec) 通过上面的各个项，大家就可以看到具体耗时在哪。比如从上面可以看出Sending data的耗时最大，这个是指执行器开始查询数据并将数据发送给客户端的耗时，因为我的这张表符合条件的数据有好几万条，所以这块耗时最大，也符合预期。 一般情况下，我们开发过程中，耗时大部分时候都在Sending data阶段，而这一阶段里如果慢的话，最容易想到的还是索引相关的原因。 索引相关原因索引相关的问题，一般能用explain命令帮助分析。通过它能看到用了哪些索引，大概会扫描多少行之类的信息。 mysql会在优化器阶段里看下选择哪个索引，查询速度会更快。 一般主要考虑几个因素，比如： 选择这个索引大概要扫描多少行（rows） 为了把这些行取出来，需要读多少个16kb的页 走普通索引需要回表，主键索引则不需要，回表成本大不大？ 回到show profile中提到的sql语句，我们使用explain select * from user where age&gt;=60 分析一下。 上面的这条语句，使用的type为ALL，意味着是全表扫描，possible_keys是指可能用得到的索引，这里可能使用到的索引是为age建的普通索引，但实际上数据库使用的索引是在key那一列，是NULL。也就是说这句sql不走索引，全表扫描。 这个是因为数据表里，符合条件的数据行数（rows）太多，如果使用age索引，那么需要将它们从age索引中读出来，并且age索引是普通索引，还需要回表找到对应的主键才能找到对应的数据页。算下来还不如直接走主键划算。于是最终选择了全表扫描。 当然上面只是举了个例子，实际上，mysql执行sql时，不用索引或者用的索引不符合我们预期这件事经常发生，索引失效的场景有很多，比如用了不等号，隐式转换等，这个相信大家背八股文的时候也背过不少了，我也不再赘述。 聊两个生产中容易遇到的问题吧。 索引不符合预期实际开发中有些情况比较特殊，比如有些数据库表一开始数据量小，索引少，执行sql时，确实使用了符合你预期的索引。但随时时间边长，开发的人变多了，数据量也变大了，甚至还可能会加入一些其他重复多余的索引，就有可能出现用着用着，用到了不符合你预期的其他索引了。从而导致查询突然变慢。 这种问题，也好解决，可以通过force index指定索引。比如 通过explain可以看出，加了force index之后，sql就选用了idx_age这个索引了。 走了索引还是很慢有些sql，用explain命令看，明明是走索引的，但还是很慢。一般是两种情况： 第一种是索引区分度太低，比如网页全路径的url链接，这拿来做索引，一眼看过去全都是同一个域名，如果前缀索引的长度建得不够长，那这走索引跟走全表扫描似的，正确姿势是尽量让索引的区分度更高，比如域名去掉，只拿后面URI部分去做索引。 第二种是索引中匹配到的数据太大，这时候需要关注的是explain里的rows字段了。 它是用于预估这个查询语句需要查的行数的，它不一定完全准确，但可以体现个大概量级。 当它很大时，一般常见的是下面几种情况。 如果这个字段具有唯一的属性，比如电话号码等，一般是不应该有大量重复的，那可能是你代码逻辑出现了大量重复插入的操作，你需要检查下代码逻辑，或者需要加个唯一索引限制下。 如果这个字段下的数据就是会很大，是否需要全部拿？如果不需要，加个limit限制下。如果确实要拿全部，那也不能一次性全拿，今天你数据量小，可能一次取一两万都没啥压力，万一哪天涨到了十万级别，那一次性取就有点吃不消了。你可能需要分批次取，具体操作是先用order by id排序一下，拿到一批数据后取最大id作为下次取数据的起始位置。 连接数过小索引相关的原因我们聊完了，我们来聊聊，除了索引之外，还有哪些因素会限制我们的查询速度的。 我们可以看到，mysql的server层里有个连接管理，它的作用是管理客户端和mysql之间的长连接。 正常情况下，客户端与server层如果只有一条连接，那么在执行sql查询之后，只能阻塞等待结果返回，如果有大量查询同时并发请求，那么后面的请求都需要等待前面的请求执行完成后，才能开始执行。 因此很多时候我们的应用程序，比如go或java这些，会打印出sql执行了几分钟的日志，但实际上你把这条语句单独拎出来执行，却又是毫秒级别的。这都是因为这些sql语句在等待前面的sql执行完成。 怎么解决呢？ 如果我们能多建几条连接，那么请求就可以并发执行，后面的连接就不用等那么久了。 而连接数过小的问题，受数据库和客户端两侧同时限制。 数据库连接数过小Mysql的最大连接数默认是100, 最大可以达到16384。 可以通过设置mysql的max_connections参数，更改数据库的最大连接数。 12345678910mysql&gt; set global max_connections= 500;Query OK, 0 rows affected (0.00 sec)mysql&gt; show variables like &#x27;max_connections&#x27;;+-----------------+-------+| Variable_name | Value |+-----------------+-------+| max_connections | 500 |+-----------------+-------+1 row in set (0.00 sec) 上面的操作，就把最大连接数改成了500。 应用侧连接数过小数据库连接大小是调整过了，但貌似问题还是没有变化？还是有很多sql执行达到了几分钟，甚至超时？ 那有可能是因为你应用侧（go，java写的应用，也就是mysql的客户端）的连接数也过小。 应用侧与mysql底层的连接，是基于TCP协议的长链接，而TCP协议，需要经过三次握手和四次挥手来实现建连和释放。如果我每次执行sql都重新建立一个新的连接的话，那就要不断握手和挥手，这很耗时。所以一般会建立一个长连接池，连接用完之后，塞到连接池里，下次要执行sql的时候，再从里面捞一条连接出来用，非常环保。 我们一般写代码的时候，都会通过第三方的orm库来对数据库进行操作，而成熟的orm库，百分之一千万都会有个连接池。 而这个连接池，一般会有个大小。这个大小就控制了你的连接数最大值，如果说你的连接池太小，都还没有数据库的大，那调了数据库的最大连接数也没啥作用。 一般情况下，可以翻下你使用的orm库的文档，看下怎么设置这个连接池的大小，就几行代码的事情，改改就好。比如go语言里的gorm里是这么设置的 12345678func Init() &#123; db, err := gorm.Open(mysql.Open(conn), config) sqlDB, err := db.DB() // SetMaxIdleConns 设置空闲连接池中连接的最大数量 sqlDB.SetMaxIdleConns(200) // SetMaxOpenConns 设置打开数据库连接的最大数量 sqlDB.SetMaxOpenConns(1000)&#125; buffer pool太小连接数是上去了，速度也提升了。 曾经遇到过面试官会追问，有没有其他办法可以让速度更快呢？ 那必须要眉头紧锁，假装思考，然后说：有的。 我们在前面的数据库查询流程里，提到了进了innodb之后，会有一层内存buffer pool，用于将磁盘数据页加载到内存页中，只要查询到buffer pool里有，就可以直接返回，否则就要走磁盘IO，那就慢了。 也就是说，如果我的buffer pool 越大，那我们能放的数据页就越多，相应的，sql查询时就更可能命中buffer pool，那查询速度自然就更快了。 可以通过下面的命令查询到buffer pool的大小，单位是Byte。 1234567mysql&gt; show global variables like &#x27;innodb_buffer_pool_size&#x27;;+-------------------------+-----------+| Variable_name | Value |+-------------------------+-----------+| innodb_buffer_pool_size | 134217728 |+-------------------------+-----------+1 row in set (0.01 sec) 也就是128Mb。 如果想要调大一点。可以执行 12345678910mysql&gt; set global innodb_buffer_pool_size = 536870912;Query OK, 0 rows affected (0.01 sec)mysql&gt; show global variables like &#x27;innodb_buffer_pool_size&#x27;;+-------------------------+-----------+| Variable_name | Value |+-------------------------+-----------+| innodb_buffer_pool_size | 536870912 |+-------------------------+-----------+1 row in set (0.01 sec) 这样就把buffer pool增大到512Mb了。 但是吧，如果buffer pool大小正常，只是别的原因导致的查询变慢，那改buffer pool毫无意义。 但问题又来了。 怎么知道buffer pool是不是太小了？这个我们可以看buffer pool的缓存命中率。 通过 show status like &#39;Innodb_buffer_pool_%&#39;;可以看到跟buffer pool有关的一些信息。 Innodb_buffer_pool_read_requests表示读请求的次数。 Innodb_buffer_pool_reads 表示从物理磁盘中读取数据的请求次数。 所以buffer pool的命中率就可以这样得到： 1buffer pool 命中率 = 1 - (Innodb_buffer_pool_reads/Innodb_buffer_pool_read_requests) * 100% 比如我上面截图里的就是，1 - (405/2278354) = 99.98%。可以说命中率非常高了。 一般情况下buffer pool命中率都在99%以上，如果低于这个值，才需要考虑加大innodb buffer pool的大小。 当然，还可以把这个命中率做到监控里，这样半夜sql变慢了，早上上班还能定位到原因，就很舒服。 还有哪些骚操作？前面提到的是在存储引擎层里加入了buffer pool用于缓存内存页，这样可以加速查询。 那同样的道理，server层也可以加个缓存，直接将第一次查询的结果缓存下来，这样下次查询就能立刻返回，听着挺美的。 按道理，如果命中缓存的话，确实是能为查询加速的。但这个功能限制很大，其中最大的问题是只要数据库表被更新过，表里面的所有缓存都会失效，数据表频繁的更新，就会带来频繁的缓存失效。所以这个功能只适合用于那些不怎么更新的数据表。 另外，这个功能在8.0版本之后，就被干掉了。所以这功能用来聊聊天可以，没必要真的在生产中使用啊。 总结 数据查询过慢一般是索引问题，可能是因为选错索引，也可能是因为查询的行数太多。 客户端和数据库连接数过小，会限制sql的查询并发数，增大连接数可以提升速度。 innodb里会有一层内存buffer pool用于提升查询速度，命中率一般&gt;99%，如果低于这个值，可以考虑增大buffer pool的大小，这样也可以提升速度。 查询缓存（query cache）确实能为查询提速，但一般不建议打开，因为限制比较大，并且8.0以后的Mysql里已经将这个功能干掉了。 最后最近原创更文的阅读量稳步下跌，思前想后，夜里辗转反侧。 我有个不成熟的请求。 离开广东好长时间了，好久没人叫我靓仔了。 大家可以在评论区里，叫我一靓仔吗？ 我这么善良质朴的愿望，能被满足吗？ 如果实在叫不出口的话，能帮我点下右下角的点赞和在看吗？ 别说了，一起在知识的海洋里呛水吧点击下方名片，关注公众号:【小白debug】 不满足于在留言区说骚话？ 加我，我们建了个划水吹牛皮群，在群里，你可以跟你下次跳槽可能遇到的同事或面试官聊点有意思的话题。就超！开！心！ 文章推荐： 程序员防猝死指南 TCP粘包 数据包：我只是犯了每个数据包都会犯的错 |硬核图解 动图图解！既然IP层会分片，为什么TCP层也还要分段？","categories":[{"name":"图解mysql","slug":"图解mysql","permalink":"https://xiaobaidebug.top/categories/%E5%9B%BE%E8%A7%A3mysql/"}],"tags":[]},{"title":"两个事务并发写，能保证数据唯一吗？","slug":"图解mysql/两个事务并发写，能保证数据唯一吗？","date":"2022-03-16T14:57:55.000Z","updated":"2022-10-30T02:28:13.642Z","comments":true,"path":"2022/03/16/图解mysql/两个事务并发写，能保证数据唯一吗？/","link":"","permalink":"https://xiaobaidebug.top/2022/03/16/%E5%9B%BE%E8%A7%A3mysql/%E4%B8%A4%E4%B8%AA%E4%BA%8B%E5%8A%A1%E5%B9%B6%E5%8F%91%E5%86%99%EF%BC%8C%E8%83%BD%E4%BF%9D%E8%AF%81%E6%95%B0%E6%8D%AE%E5%94%AF%E4%B8%80%E5%90%97%EF%BC%9F/","excerpt":"哟，又是我小白。最近有点高产了。 连我自己都害怕了。","text":"哟，又是我小白。最近有点高产了。 连我自己都害怕了。 直接进入正题吧。 两个事务并发写，能保证数据唯一吗？我先来解释下标题讲的是个啥。 我们假设有这么一个用户注册的场景。用户并发请求注册新用户。 你有一张数据库表，也就是下面的user表。 产品经理要求用户和用户之间，电话号码不能重复，为了保证这一点。我们想到了先查一下数据库，再判断一下，如果存在，就退出，否则插入一条数据。类似下面这样的伪代码。 123456select user where phone_no =2; // 查询sqlif (user 存在) &#123; return &#125; else &#123; insert user; // 插入sql&#125; 但这是两条sql语句，先执行查询sql，判断后再决定要不要执行插入sql。每次用户注册的时候都会执行这么一段逻辑。 那如果，此时有多个用户在做操作，就会并发执行这段逻辑。 如果都并发执行，第一条sql语句执行完之后，都会发现没有用户存在。此时都执行了插入，这样就出现了两条一样的数据才对。 所以，有人就想了，这两条sql语句逻辑应该是一个整体，不应该拆开，于是就想到了事务，通过事务把这两个sql作为一个整体，要么一起执行，要么都回滚。 这正是数据库ACID里的A（Atomicity），原子性的完美体现啊。 伪代码类似下面这样。 12345678begin;select user where phone_no =2; // 查询sqlif (user 存在) &#123; return &#125; else &#123; insert user; // 插入sql&#125;commit; 那么问题来了，这段逻辑，并发执行，能保证数据唯一？ 当然是不能。 事务內的多条sql语句，确实是原子的，要么一起成功，要么一起失败，这没错，但跟这个场景没什么太大关系。事务是并发执行的，第一个事务执行查询用户，并不会阻塞另一个事务查询用户，所以都有可能查到用户不存在，此时两个事务逻辑都判断为用户不存在，然后插入数据库。事务内两条sql都执行成功了，于是就插入了两条一样的数据。 怎么保证数据唯一？那么我们接下来聊聊，怎么保证上面这种场景下，插入的数据是唯一的。方法有很多种，但我们今天只讨论mysql内部的做法，不考虑其他外部中间件（比如redis分布式锁这些）。 唯一索引通过下面的命令，可以为数据库user表的phone_no字段加入唯一索引。 1ALTER TABLE `user` ADD unique(`phone_no`); 我们执行一条写操作时，比如下面这句， 1INSERT INTO `user` (`user_name`, `phone_no`) VALUES(&#x27;小红&#x27;, 2); 第一次会插入成功，第二次再执行插入，则会出现报错。 1Duplicate entry &#x27;2&#x27; for key &#x27;phone_no&#x27; 含义是phone_no这个字段是唯一的，加两次phone_no=2会导致重复。 于是乎回到我们文章开头的场景里，就完美解决了重复插入的问题了。 那么问题来了。 为什么唯一索引能保证数据唯一？我们看看一句写操作，会经历什么。 首先，mysql作为一个数据库，内部主要分为两层，一层是server层，一层是存储引擎层（一般是innodb）。 server层主要管的是数据库链接，权限校验，以及sql语句校验和优化之类的工作。请求打到存储引擎层，才是真正的查询和更新数据的操作。 大家都知道数据库是持久化存储，且最后都是把数据存到磁盘上的。 那数据库读写是直接读写磁盘数据吗？ 不是，如果直接读写磁盘的话，那就太慢了，为了提升速度。 它在磁盘前面加了一层内存，叫buffer pool。它里面有很多细节，但最主要的就是个双向链表，里面放的是一个个数据页，每个数据页的大小默认是 16kb，数据页里面放的就是磁盘的数据。 于是有了这层buffer pool内存，mysql的读和写操作都可以先操作这部分内存，如果想要读写的数据页不在buffer pool里，再跑到磁盘里去捞。由于读写内存的速度比读写磁盘快得多。 所以引擎读写都快多了。 但这还不够，很多时候写操作，我的诉求就是把xx更新为xx，或插入xx，数据库光知道这一点就够了，我根本不需要知道数据页原来长什么样子。 有点抽象？举个例子吧。 比方说我想要把id=1的这条数据的phone_no字段更新为100，数据库知道这一点就够了，至于这条数据原来phone_no究竟是等于20，还是30，这根本不重要，反正最后都会变成我想要的phone_no=100。 也就是说，如果有那么一块内存，记录下我准备把数据改成什么样子，然后后续异步慢慢更新到磁盘数据上。那我甚至到不需要在一开始就把这块数据从磁盘读到buffer pool中，按照这个思路，change buffer就来了。 于是乎，写加了普通索引的数据，它只要把想要写的内容写到change buffer上，就立马结束返回了。后面innodb引擎拿着这个change buffer，再异步读入磁盘数据到内存，将change buffer的数据修改到数据页中，再写回磁盘，这速度就上来了，秒啊。 但这个change buffer，放在唯一索引这里就不管用了，毕竟，它得保证数据真的只有一条，那就得去看下数据库里，是不是真的有这条数据。 所以，对于insert场景，普通索引把需求扔到change buffer就完事返回了，而唯一索引需要真的把数据从磁盘读到内存来，看下是不是有重复的，没重复的再插入数据。 这唯一索引，在性能上就输了一截了。 所以回到唯一索引为什么能保证数据唯一的问题上，一句话概括就是，唯一索引会绕过change buffer，确保把磁盘数据读到内存后再判断数据是否存在，不存在才能插入数据，否则报错，以此来保证数据是唯一的。 总结 加唯一索引可以保证数据并发写入时数据唯一，而且最省事省心。 数据库通过引入一层buffer pool内存来提升读写速度，普通索引可以利用change buffer提高数据插入的性能。 唯一索引会绕过change buffer，确保把磁盘数据读到内存后再判断数据是否存在，不存在才能插入数据，否则报错，以此来保证数据是唯一的。 给大家留个问题呗，前面也提到了，innodb中，利用了change buffer，为普通索引做了加速。有没有哪些场景下，change buffer不仅不能给普通索引加速，还起到反作用的呢？ 最后大家也别笑，文章开头提到的通过开事务来保证数据唯一性的错误操作，其实很容易犯，而且我曾经也遇到过不止一次这样的事情。 做这个操作的人，还会信誓旦旦，言之凿凿的说出他的理解，在我解释了几遍发现无果之后，我选择低头假装思考，然后说：”你说的有点道理，我再回去好好想想”，然后默默的为数据表加上唯一索引…… 我相信对方肯定已经理解了。那一刻，我感觉我写的不是代码，我写的是人情世故。 如果文章对你有帮助，欢迎….. 算了。 别说了，一起在知识的海洋里呛水吧点击下方名片，关注公众号:【小白debug】 不满足于在留言区说骚话？ 加我，我们建了个划水吹牛皮群，在群里，你可以跟你下次跳槽可能遇到的同事或面试官聊点有意思的话题。就超！开！心！ 文章推荐： 程序员防猝死指南 TCP粘包 数据包：我只是犯了每个数据包都会犯的错 |硬核图解 动图图解！既然IP层会分片，为什么TCP层也还要分段？","categories":[{"name":"图解mysql","slug":"图解mysql","permalink":"https://xiaobaidebug.top/categories/%E5%9B%BE%E8%A7%A3mysql/"}],"tags":[]},{"title":"给32位系统装8g内存条能用吗？为什么？","slug":"图解操作系统/给32位系统装8g内存条能用吗？为什么？","date":"2022-03-09T14:57:55.000Z","updated":"2022-10-30T02:28:13.643Z","comments":true,"path":"2022/03/09/图解操作系统/给32位系统装8g内存条能用吗？为什么？/","link":"","permalink":"https://xiaobaidebug.top/2022/03/09/%E5%9B%BE%E8%A7%A3%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/%E7%BB%9932%E4%BD%8D%E7%B3%BB%E7%BB%9F%E8%A3%858g%E5%86%85%E5%AD%98%E6%9D%A1%E8%83%BD%E7%94%A8%E5%90%97%EF%BC%9F%E4%B8%BA%E4%BB%80%E4%B9%88%EF%BC%9F/","excerpt":"关于32位和64位，这个概念一直让人比较懵。","text":"关于32位和64位，这个概念一直让人比较懵。 在买电脑的时候，我们看到过32位和64位CPU。 下软件的时候，我们也看到过32位或64位的软件。 就连装虚拟机的时候，我们也看过32位和64位的系统。 在写代码的时候，我们的数值，也可以定义为int32或者int64。 我们当然很清楚，装软件的时候，一般64位的系统就选64位的软件，肯定不出错，但是这又是为什么呢？既然CPU，软件，操作系统，数值大小都有32位和64位，他们之间就可以随意组合成各种问题，比如32位的系统能装64位的软件吗？32位的系统能计算int64的数值吗？他们之间到底有什么关系？这篇文章会尝试解释清楚。 从代码到到可执行文件我们从熟悉的场景开始说起，比方说，我们写代码的时候，会在代码编辑器里写入。 12345678910// test.c#include &lt;stdio.h&gt; int main()&#123; int i,j; i = 3; j = 2; return i + j;&#125; 但这个代码是给人看的，机器可看不懂，于是这段代码，还会经过被编译器转成汇编码。 汇编码就是我们大学的时候学的头秃的这种 12345678910111213// gcc -S test.cpushq %rbp.cfi_def_cfa_offset 16.cfi_offset %rbp, -16movq %rsp, %rbp.cfi_def_cfa_register %rbpmovl $0, -4(%rbp)movl $3, -8(%rbp)movl $2, -12(%rbp)movl -8(%rbp), %eaxaddl -12(%rbp), %eaxpopq %rbpretq 大家也别去看上面的内容，没必要。 而汇编，总归还是有各种movl，pushq这些符号，虽然确实不好看，但说到底还是给人看的，而机器cpu要的，说到底还是要0101这样的二进制编码，所以还需要使用汇编器将汇编转成二进制的机器码。我们可以看到下面内容分为3列，左边是指令地址， 右边是汇编码内容，中间的就是指令机器码，是16进制，可以转成二进制01串，这就是机器cpu能认识的内容了。 1234567891011121314// objdump -d test0000000000001125 &lt;main&gt;: 1125: 55 push %rbp 1126: 48 89 e5 mov %rsp,%rbp 1129: c7 45 fc 03 00 00 00 movl $0x3,-0x4(%rbp) 1130: c7 45 f8 02 00 00 00 movl $0x2,-0x8(%rbp) 1137: 8b 55 fc mov -0x4(%rbp),%edx 113a: 8b 45 f8 mov -0x8(%rbp),%eax 113d: 01 d0 add %edx,%eax 113f: 5d pop %rbp 1140: c3 retq 1141: 66 2e 0f 1f 84 00 00 nopw %cs:0x0(%rax,%rax,1) 1148: 00 00 00 114b: 0f 1f 44 00 00 nopl 0x0(%rax,%rax,1) 而机器码，最后会放在我们编译生成的可执行文件里。 也就是说我们平时写的代码，最后会变成一堆01机器码，放在可执行文件里，躺在磁盘上。 从可执行文件到进程一旦我们执行以下命令 1./可执行文件名 这个可执行文件就会加载进内存中，成为一个进程，运行起来。 可执行文件里的机器码也会被加载到内存中，它就像是一张列满todo list的清单，而CPU就对照着这张清单，一行行的执行上面的机器码。从效果上来看，进程就动起来了。 对CPU来说，它执行到某个特定的编码数值，就会执行特定的操作。比如计算2+3，其实就是通过总线把数据2和3从内存里读入，然后放到寄存器上，再用加法器相加这两个数值并将结果放入到寄存器里，最后将这个数值回写到内存中，以此循环往复，一行行执行机器码直到退出。 CPU位数的含义上面这个流程里，最重要的几个关键词，分别是CPU寄存器，总线，内存。 CPU的寄存器，说白了就是个存放数值的小盒子，盒子的大小，叫位宽。32位CPU能放入最大2^32的数值。64位就是最大2^64的值。这里的32位位宽的CPU就是我们常说的32位CPU，同理64位CPU也是一样。 而CPU跟内存之间，是用总线来进行信号传输的，总线可以分为数据总线，控制总线，地址总线。功能如其名，举个例子说明下他们的作用吧。在一个进程的运行过程中，CPU会根据进程的机器码一行行执行操作。 比如现在有一行是将A地址的数据与B地址的数据相加，那么CPU就会通过控制总线，发送信号给内存这个设备，告诉它，现在CPU要通过地址总线在内存中找到A数据的地址，然后取得A数据的值，假设是100，那么这个100，就会通过数据总线回传到CPU的某个寄存器中。B也一样，假设B=200，放到另一个寄存器中，此时A和B相加后，结果是300，然后控制CPU通过地址总线找到返回的参数地址，再把数据结果通过数据总线传回内存中。这一存一取，CPU都是通过控制总线对内存发出指令的。 而总线，也可以理解为有个宽度，比如宽度是32位，那么一次可以传32个0或1的信号，那么这个宽度能表达的数值范围就是0到2^32这么多。 32位CPU的总线宽度一般是32位，因为刚刚上面提到了，CPU可以利用地址总线在内存中进行寻址操作，那么现在这根地址总线，最大能寻址的范围，也就到2^32，其实就是4G。 64位CPU，按理说总线宽度是64位，但实际上是48位（也有看到说是40位或46位的，没关系，你知道它很大就行了），所以寻址范围能到2^48次方，也就是256T。 系统和软件的位数的含义上面提到了32位CPU和64位CPU的内存寻址范围，那么相应的操作系统，和软件（其实操作系统也能说是软件），也应该按CPU所能支持的范围去构建自己的寻址范围。 比方说下面这个图，在操作系统上运行一个用户态进程，会分为用户态和内核态，并设定一定的内存布局。操作系统和软件都需要以这个内存布局为基础运行程序。比如32位，内核态分配了1个G，用户态分配了3G，这种时候，你总不能将程序的运行内存边界设定在大于10G的地方。所以，系统和软件的位数，可以理解为，这个系统或软件内存寻址的范围位数。 一般情况下，由于现在我们的CPU架构在设计上都是完全向前兼容的，别说32位了，16位的都还兼容着，因此64位的CPU是能装上32位操作系统的。 同理，64位的操作系统是兼容32位的软件的，所以32位软件能装在64位系统上。 但反过来，因为32位操作系统只支持4g的内存，而64位的软件在编译的时候就设定自己的内存边界不止4个G，并且64位的CPU指令集内容比32位的要多，所以32位操作系统是肯定不能运行64位软件的。 同理，32位CPU也不能装64位的操作系统的。 程序数值int32和int64的含义这个我们平时写代码接触的最多，比较好理解了。int32也就是用4个字节，32位的内存去存储数据，int64也就是用8个字节，64位去存数据。这个数值就是刚刚CPU运行流程中放在内存里的数据。 那么问题又来了。 32位的CPU能进行int64位的数值计算吗？先说结论，能。但比起64位的CPU，性能会慢一些。 如果说我用的是64位的CPU，那么我在计算两个int64的数值相加时，我就能将数据通过64位的总线，一次性存入到64位的寄存器，并在进行计算后返回到内存中。整个过程一步到位，一气呵成。 但如果我现在用的是32位的CPU，那就憋屈一点了，我虽然在代码里放了个int64的数值，但实际上CPU的寄存器根本放不下这么大的数据，因此最简单的方法是，将int64的数值，拆成前后两半，现在两个int64相加，就变成了4个int32的数值相加，并且后半部分加好了之后，拿到进位，才能去计算前面的部分，这里光是执行的指令数就比64位的CPU要多。所以理论上，会更慢些。 系统位数会限制内存吗？上面提到了CPU位数，系统位数，软件位数，以及数值位数之间的区别与联系。 现在，我们回到标题里提到的问题。 32位CPU和系统插8g内存条，能用吗？系统能正常工作，但一般用不到8G，因为32位系统的总线寻址能力为2的32次方，也就是4G，哪怕装了8G的内存，真正能被用到的其实只有4g，多少有点浪费。 注意上面提到的是一般，为什么这么说，因为这里有例外，32位系统里，有些是可以支持超过4G内存的，比如Windows Server 2003就能最大支持64G的内存，它通过使用 PAE （Intel Physical Address Extension）技术向程序提供更多的物理内存，PAE本质上是通过分页管理的方式将32位的总线寻址能力增加到36位。因此理论上寻址能力达到2的36次方，也就是64G。 至于实现细节大家也不用关心，现在用到这玩意的机器也该淘汰的差不多了，而且都是windows server，注意Windows Server 2003 名字里带个server，是用来做服务器的，我们一般也用不到，知道这件事，除了能帮助我们更好的装x外，就没什么作用了。 所以，你当32位系统最大只能用到4G内存，那也没毛病。 64位CPU装32位操作系统，再插上8g的内存条，寻址能力还是4G吗上面提到32位CPU就算插上8G内存条，寻址能力也还是4G，那如果说我现在换用64位的CPU，但装了个32位的操作系统，这时候插入8G内存条，寻址能力能超过4G吗？ 寻址能力，除了受到cpu的限制外，还受到操作系统的限制，如果操作系统就是按着32位的指令和寻址范围（4G）来编译的话，那么它就会缺少64位系统该有的指令，它在运行软件的时候就不能做到超过这个限制，因此寻址能力还会是4G。 最后留下一个问题吧。 上面提到，我们平时写的代码（也就是C，go，java这些），先转成汇编，再转成机器码。最后CPU执行的是机器码，那么问题来了。 为什么我们平时写的代码不直接转成机器码，而要先转成汇编，这是不是多此一举？ 总结 CPU位数主要指的是寄存器的位宽， 32位CPU只能装32位的系统和软件，且能计算int64，int32的数值。内存寻址范围是4G。 64位CPU，同时兼容32位和64位的系统和软件，并且进行int64数值计算的时候，性能比32位CPU更好，内存寻址范围可以达到256T。 32位CPU和操作系统，插入8G的内存，会有点浪费，因为总线寻址范围比较有限，它只能用上4G不到的内存。 64位CPU，如果装上32位的操作系统，就算插上8G的内存，效果也还是只能用上4G不到的内存。 最后刚工作的时候一直觉得int32，有21个亿，这么大的数值肯定够用了吧，结果现实好几次打脸。 以前做游戏的时候，血量一开始是定义为int32，游戏设定是可以通过充钱，提升角色的属性，还能提升血量上限，谁也没想到，老板们通过氪金，硬是把血量给打到了int32最大值。于是策划提了个一句话需求：”血量要支持到int64大小”，这是我见过最简单的策划案，但也让人加班加的最凶。 那是我第一次感受到了钞能力。 这篇文章老早就想写了，但涉及的知识点有点多，一直很头疼，怎么样才能用最简单的方式把他们表述清楚，于是想着从大家最熟悉的场景开始说起。希望能给大家带来价值。 如果文章对你有帮助，欢迎….. 算了。 别说了，一起在知识的海洋里呛水吧点击下方名片，关注公众号:【小白debug】 不满足于在留言区说骚话？ 加我，我们建了个划水吹牛皮群，在群里，你可以跟你下次跳槽可能遇到的同事或面试官聊点有意思的话题。就超！开！心！ 文章推荐： 程序员防猝死指南 TCP粘包 数据包：我只是犯了每个数据包都会犯的错 |硬核图解 动图图解！既然IP层会分片，为什么TCP层也还要分段？","categories":[{"name":"图解操作系统","slug":"图解操作系统","permalink":"https://xiaobaidebug.top/categories/%E5%9B%BE%E8%A7%A3%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/"}],"tags":[]},{"title":"mysql主库更新后，从库都读到最新值了，主库还有可能读到旧值吗？","slug":"图解mysql/mysql主库更新后，从库读到最新值了，主库还有可能读到旧值吗？","date":"2022-03-02T14:57:55.000Z","updated":"2022-10-30T02:28:13.643Z","comments":true,"path":"2022/03/02/图解mysql/mysql主库更新后，从库读到最新值了，主库还有可能读到旧值吗？/","link":"","permalink":"https://xiaobaidebug.top/2022/03/02/%E5%9B%BE%E8%A7%A3mysql/mysql%E4%B8%BB%E5%BA%93%E6%9B%B4%E6%96%B0%E5%90%8E%EF%BC%8C%E4%BB%8E%E5%BA%93%E8%AF%BB%E5%88%B0%E6%9C%80%E6%96%B0%E5%80%BC%E4%BA%86%EF%BC%8C%E4%B8%BB%E5%BA%93%E8%BF%98%E6%9C%89%E5%8F%AF%E8%83%BD%E8%AF%BB%E5%88%B0%E6%97%A7%E5%80%BC%E5%90%97%EF%BC%9F/","excerpt":"大家好，我是小白，好长时间没更新技术文了，相信大家看我写的水文也看烦了。","text":"大家好，我是小白，好长时间没更新技术文了，相信大家看我写的水文也看烦了。 今天的文章，其实来自真实的面试题，而且还比较有趣，所以忍不住分享出来。 直接开始吧。 我们知道，mysql数据库，为了得到更高性能，一般会读写分离，主库用于写操作，比如用于执行insert，update操作，从库用于读，也就是最常见的select操作。像下面这个图这样。 虽然主库一般用于写操作，但也是能读的。那么今天的问题来了。 主库更新后，主库都读到最新值了，从库还有可能读到旧值吗？ 主库更新后，从库都读到最新值了，主库还有可能读到旧值吗？ 毕竟面试官都这么问了，那当然是有可能的，那至于是为啥，以及怎么做到的，今天我们来好好聊聊。 正常的主从更新流程比如我在主库和从库都有张user表，此时有以下两条数据。 正常情况下，我们往主库执行写操作，比如更新一条数据，执行 1update user set age = 50 where id = 1; 虽然这是一个单条写操作，但本质上可以理解为单条语句的事务。等同于下面这样 123begin;update user set age = 50 where id = 1;commit; 这个事务如果执行成功了，数据会先写入到主库的binlog文件中，然后再刷入磁盘。 binlog文件是mysql的server层日志，记录了用户对数据库有哪些变更操作，比如建数据库表加字段，对某些行的增删改等。 它的位置可以通过下面的查询语句看到。 123456789101112mysql&gt; show variables like &quot;%log_bin%&quot;;+---------------------------------+--------------------------------------+| Variable_name | Value |+---------------------------------+--------------------------------------+| log_bin | ON || log_bin_basename | /var/lib/mysql/mysql-slave-bin || log_bin_index | /var/lib/mysql/mysql-slave-bin.index || log_bin_trust_function_creators | OFF || log_bin_use_v1_row_events | OFF || sql_log_bin | ON |+---------------------------------+--------------------------------------+6 rows in set (0.04 sec) 其中binlog在 /var/lib/mysql/ 下，命名会类似mysql-bin.00000x。感兴趣的可以到这个目录下直接查看文件内容长什么样子。 如果两个mysql配置好了主从的关系，那么他们之间会建立一个tcp长连接，主要用于传输同步数据。 除此之外，主库还会再起一个binlog dump线程将binlog文件的变更发给从库。 可以在主库中通过 show full processlist; 查询到 binlog dump线程的存在。 以上，主库的工作就结束了，我们说说从库的。 从库在收到binlog后，会有一个io线程负责把收到的数据写入到relay log（中继日志）中。 然后再有一个sql 线程，来读取relay log的内容，然后对从库执行sql语句操作，从结果上来看就是将主库执行过的写操作，在从库上也重放一遍，这样主从数据就一致了。 是不是感觉relay log有些多余？ 为什么要先写一遍relay log然后再写从库，直接将数据写入到从库不好吗？ 在这里relay log的作用就类似于一个中间层，主库是多线程并发写的，从库的sql线程是单线程串行执行的，所以这两边的生产和消费速度肯定不同。当主库发的binlog消息过多时，从库的relay log可以起到暂存主库数据的作用，接着从库的sql线程再慢慢消费这些relay log数据，这样既不会限制主库发消息的速度，也不会给从库造成过大压力。 可以通过在从库中执行 show full processlist; 确认 io线程和sql线程的存在。 因此总结起来，主从同步的步骤就是 1.执行更新sql语句。 2.主库写成功时，binlog会更新。 3.主库binlog dump 线程将binlog的更新部分发给从库 4.从库io线程收到binlog更新部分，然后写入到relay log中 5.从库sql线程读取relay log内容，重放执行sql，最后主从一致。 到这里，我们可以开始回答文章开头的第一个问题。 主库更新后，主库都读到最新值了，从库还有可能读到旧值吗？这是可能的，上面提到的主从同步的5个步骤里，第3到第5步骤，都需要时间去执行，而这些步骤的执行时间总和，就是我们常说的主从延迟。 当更新一行数据后，立马去读主库，主库的数据肯定是最新值，这点没什么好说的，但如果此时主从延迟过大，这时候读从库，同步可能还没完成，因此读到的就是旧值。 在实际的开发当中，主从延迟也非常常见，当数据库压力稍微大点，主从延迟就能到100ms甚至1s以上。 具体的主从延迟时间可以在从库中执行 show slave status \\G;来查看，其中里面的Seconds_Behind_Master则是主从延迟的时间，单位是秒。 123456789101112131415mysql&gt; show slave status \\G;*************************** 1. row *************************** Slave_IO_State: Waiting for master to send event Master_Host: 172.17.0.2 Master_User: slave Connect_Retry: 30 Master_Log_File: mysql-bin.000002 Read_Master_Log_Pos: 756 Relay_Log_File: edu-mysql-relay-bin.000004 Relay_Log_Pos: 969 Relay_Master_Log_File: mysql-bin.000002 Slave_IO_Running: Yes Slave_SQL_Running: Yes Seconds_Behind_Master: 2 所以如果你有写数据后就立马要读数据的场景，要是此时读的是从库，很有可能会读到更新前的旧数据，如果你对数据一致性有较高要求，这种时候建议读主库。 主库更新后，从库都读到最新值了，主库还有可能读到旧值吗？那另一个问题就来了，如果从库都读到最新值了，那说明主库肯定已经更新完成了，那此时读主库是不是只能读到最新值呢？ 还真不是的，待会我给大家复现下，但在这之前我们了解一些前置知识点。 mysql的四种隔离级别这个绝对是面试八股文老股了。mysql有四种隔离级别，分别是读未提交（Read uncommitted），读提交（Read committed），可重复读（Repeatable read）和串行化（Serializable）。在不同的隔离级别下，并发读写效果会不太一样。 当前数据库处于什么隔离级别可以通过执行 select @@tx_isolation; 查看到。 1234567mysql&gt; select @@tx_isolation;+-----------------+| @@tx_isolation |+-----------------+| REPEATABLE-READ |+-----------------+1 row in set (0.01 sec) 也可以通过下面的语句去修改隔离级别。 1SET GLOBAL TRANSACTION ISOLATION LEVEL REPEATABLE-READ; 下面用一个case来让大家直观点的理解这四个隔离级别的区别。 假设我们有两个线程同时对某行数据A(A=1)进行以下操作。 我们执行事务都像上面这样，begin可以开启事务，commit会提交事务，上面两个线程，各执行一个事务，且此时是并发执行。 线程1会将某行的A这个字段从1更新为2。 线程2啥也不干，就读A。重点关注2线程的三次读A的行为，它们会根据隔离级别的不同，读到不同的值。 第1次读A： 如果是读未提交，那么会读到2，顾名思义，就算线程1未提交，线程2也能读到最新的值。 如果是读提交或者可重复读，那读到的都是1，读提交只认事务提交后的数据，而可重复读只要线程2的事务内没有执行对A的更新sql语句，那读A的数据就会一直不变。 第2次读A：时机正好在线程1提交了事务之后 如果是读未提交，前面都读到2了，现在读到的还是2，这个没啥好说的。 如果是读提交，那读到的都是2了，因为线程1的事务提交了，读提交只认提交后的数据，所以此时线程2能读到最新数据。 如果是可重复读那就还是1，理由跟上面一样。 第3次读A：时机正好在线程2提交了事务之后 如果是读未提交或读已经提交，结果跟前面一样，还是2。 如果是可重复读，那就变成了2，因为线程2前面的事务结束了，在同一个事务内A的值重复多次读都是一致的，但当事务结束了之后，新的查询不再需要受限于上一次开事务时的值。 上面的情况没有将串行化纳入讨论范围，只讨论了读未提交，读提交和可重复读这三个隔离级别，因为在这三个隔离级别下都有可能出现两个事务并发执行的场景，而在串行化的隔离级别中则不会出现，多个事务只会一个挨着一个依次串行执行，比如线程1的事务执行完了之后，线程2的事务才执行，因此不会产生并发查询更新的问题。 有了这个知识背景之后，我们就可以回到第二个问题里了。 数据库原始状态如下，此时主从都一样。 假设当前的数据库事务隔离级别是可重复读，现在主库有A，B两个线程，同时执行begin，开启事务。 此时主库的线程2，先读一次id=1的数据，发现age=72，由于当前事务隔离级别是可重复读，那么只要线程2在事务内不做更新操作的话，那么不管重复读多少次，age都是72。在这之后主库的线程1将age更新为100且执行commit提交了事务。 主库线程1的事务提交成功之后binlog就会顺利产生，然后同步给从库。此时从库去查询就能查到最新值age=100。回过头来，此时主库的线程2因为还没提交事务，所以一直读到的都是旧值age=72。但如果这时候线程2执行commit提交了事务，那么再查询，就能拿到最新值age=100了。 所以从结论上来说，出现了从库都读到最新值了，主库却读到了旧值的情况。 好了这道题到这里就结束了。 意不意外？ 这道面试题，通过一个问题，将主从同步，事务隔离级别等知识点都串起来了。 还是有点意思的。 那么问题又来了，这四个隔离级别是挺骚气的，那他们是怎么实现的呢？ 如果文章对你有帮助，欢迎….. 算了。 别说了，一起在知识的海洋里呛水吧点击下方名片，关注公众号:【小白debug】 不满足于在留言区说骚话？ 加我，我们建了个划水吹牛皮群，在群里，你可以跟你下次跳槽可能遇到的同事或面试官聊点有意思的话题。就超！开！心！ 文章推荐： 程序员防猝死指南 TCP粘包 数据包：我只是犯了每个数据包都会犯的错 |硬核图解 动图图解！既然IP层会分片，为什么TCP层也还要分段？","categories":[{"name":"图解mysql","slug":"图解mysql","permalink":"https://xiaobaidebug.top/categories/%E5%9B%BE%E8%A7%A3mysql/"}],"tags":[]},{"title":"为什么张一鸣推崇延时满足。。。","slug":"程序人生/为什么张一鸣推崇延时满足","date":"2022-01-30T14:57:55.000Z","updated":"2022-10-30T02:28:13.643Z","comments":true,"path":"2022/01/30/程序人生/为什么张一鸣推崇延时满足/","link":"","permalink":"https://xiaobaidebug.top/2022/01/30/%E7%A8%8B%E5%BA%8F%E4%BA%BA%E7%94%9F/%E4%B8%BA%E4%BB%80%E4%B9%88%E5%BC%A0%E4%B8%80%E9%B8%A3%E6%8E%A8%E5%B4%87%E5%BB%B6%E6%97%B6%E6%BB%A1%E8%B6%B3/","excerpt":"大家知道，字节的文化里，有一条叫”延迟满足“，意思是为了长远的、更大的利益，自愿延缓或者放弃目前的、较小的满足，有种先苦后甜的那个味道。 看到标题，感觉好像会是个口水文，可能会通过人物故事去剖析，然后讲一些没什么用的鸡汤。 我需要否定下，至少不是“好像”，这就是口水文。 我希望能从更底层的原理来聊聊这个话题，而不是光灌鸡汤。 大家高中的时候应该学过，人体具有调节平衡的机制。 举个例子，当你病毒性感冒时，人体会通过调节体内的白细胞，淋巴，噬菌体这些进行免疫抵抗，所以你会发烧。而打针，一般除了给你杀杀病毒细菌之外，还会通过盐水葡萄糖，让你的身体更快恢复平衡。 所以这就跟大学时候学的反馈调节系统，非常像。","text":"大家知道，字节的文化里，有一条叫”延迟满足“，意思是为了长远的、更大的利益，自愿延缓或者放弃目前的、较小的满足，有种先苦后甜的那个味道。 看到标题，感觉好像会是个口水文，可能会通过人物故事去剖析，然后讲一些没什么用的鸡汤。 我需要否定下，至少不是“好像”，这就是口水文。 我希望能从更底层的原理来聊聊这个话题，而不是光灌鸡汤。 大家高中的时候应该学过，人体具有调节平衡的机制。 举个例子，当你病毒性感冒时，人体会通过调节体内的白细胞，淋巴，噬菌体这些进行免疫抵抗，所以你会发烧。而打针，一般除了给你杀杀病毒细菌之外，还会通过盐水葡萄糖，让你的身体更快恢复平衡。 所以这就跟大学时候学的反馈调节系统，非常像。 这个图上面，左边是输入，右边是输出，当被控对象受到干扰的时候，输出就会发生变化，此时比较器就会计算偏差，然后控制器会根据偏差作出调整。 举个例子，四旋翼无人机能正常飘在空中，这是符合预期的状态，当外界轻微碰了它一下，虽然无人机姿态发生了一些偏移，但此时系统会计算出当前状态和预期状态的差距，然后通过调整四个螺旋桨的转速来不断减少偏差，最终回到原来的状态。 这里面比较重要的是比较器和控制器。它们做的事情无非就是发现偏差，然后想办法让偏差变小。 这就是所谓的反馈调节。 从效果上看其实就像个天平，你在一端压了重物，天平就倾斜，为了使天平回到平衡，你需要在另外一边也压点东西。而压东西的过程，就是调节。 了解了这一点后，再来了解下多巴胺和内啡肽是什么。 多巴胺大家应该经常听到，它可以让人产生快乐，当我们在做一些新鲜好玩的事情时，比如打游戏、听音乐，都会产生这玩意。**”期待”这件事情，也会产生多巴胺。回想下抖音的feed流，你永远不知道，下一个视频是啥，划了再说。如果你对一个东西更感兴趣，那你在面对这个东西的时候会比面对其他东西的时候，分泌更多的多巴胺，而推荐**机制，则将更多你可能感兴趣的东西推荐到你面前。抖音和头条在这双层机制的把持下，让人上头。 但如果多巴胺立马降下来了，会给人带来焦虑和空虚的感觉，这也是你进入贤者时间思考人生的重要原因。 比起多巴胺，可能内啡肽大家听得比较少。但吗啡大家应该在电视剧里多多少少听说过，一般用这个的人都是做了大手术躺在病床上的，它能止疼镇静还能让人产生愉悦的感觉，并且这种舒爽的感觉还会比较持久。而内啡肽效果就跟吗啡类似。 一般在经历了学习，健身，洗冷水澡这种比较痛苦的事情之后会产生。 以上两种，都是人体内的激素，都会对人体内的”天平”产生影响。当人体产生多巴胺之后，人是立刻爽了，但天平也倾斜了，为了使系统恢复平衡，人会产生难受的感觉，所以打完游戏你会一阵空虚。而内啡肽也类似，虽然学习健身让你很不爽，但因为天平也倾斜了，此时身体会通过分泌内啡肽让你重新爽回来，所以运动完会神清气爽。 总结来说多巴胺和内啡肽都是会让人快乐的东西，但区别点在于，多巴胺即刻满足，而内啡肽延迟满足。 我们再回过头来看张一鸣同学推崇的延迟满足，其实就有点内啡肽的那意思。 而抖音强调的则是即刻满足。一个推崇延迟满足的人做了一个能让每个人即刻满足的应用，不得不说，大佬总归是大佬，对人性，三个手指头拿捏得死死的。大佬之所以推崇延时满足，是因为在你真正得到满足之前，往往付出了大量的努力，不管是学习和健身都是反人性的，但是这些反人性的事情也确确实实对人的发展有益。 了解一些系统的实现原理，可以帮助我们更好的做系统调优。那么，现在我们明白了人体的设计原理，其实就可以更好的做人体这个系统的调优了。 有句话是这么说的。 “做人嘛，最重要是开心“。 古人诚不欺我。 “开心“，就是我们人体这个系统最重要的指标。 而想办法让自己”更开心”，就是所谓的”系统调优“。 比方说，如果你心情低落，你可以尝试立刻提升多巴胺，比如打开抖音。 你很清楚内啡肽可以给你带来较为持久的愉悦，那你可以尝试把让你痛苦的事情放在早上做，比如学习或健身都放在早上，这样下午和晚上你都会更加快乐。但如果反过来，早上打完游戏，多巴胺减少，人很难受，下午还要学习，就更难受了，多半真学不动，相信大家都有体会。 刚开始刷抖音，你会迅速分泌多巴胺，刷的时间长了，多巴胺的分泌带来的快乐则没有一开始那么明显，于是我们会慢慢出现”麻了“的感觉，需要更大的刺激才能保持这份快乐，于是出现越刷越上头，越刷也越无聊的情况。所以可以尝试降低刷抖音的时间，加完班回来，只刷前面的十几分钟，真的就够了。早点睡，小心猝死。 以前不少老哥总拿”学习使我快乐”当反话开玩笑，但其实学习确实会让你快乐，只不过不是当下快乐，而是学习之后你会分泌内啡肽，这其实也会让你快乐。如果你确实感觉不到快乐，那大概率是你学的时间不够长….. 人体不像计算机，我们也看不到人体的源码，否则我高低也给大家整上两行。 大家估计也清楚，基因这玩意，就是我们的源码。 我们写的系统没办法实现编码外的功能，而我们也没办法做到我们基因外的功能，比如基因规定了我们没翅膀，那我们就是不能飞。基因规定了我们喜欢看大长腿，那我没办法不去看啊。 我们能做的就是在理解系统原理的前提下，更好的去使用系统。 对了，最后补充一句，不管是多巴胺还是内啡肽，都具有成瘾性。 非要说哪个更好，作为成年人，我选择全都要！ 文章到这里也写完了，我的内啡肽也马上要上来了！ 如果此时我打开抖音。 那我的快乐，就是双倍！ 最后快过年了，各位老哥快关注我之前写过的文章，给自己搞点内啡肽。 如果文章对你有帮助，欢迎….. 算了。 别说了，一起在知识的海洋里呛水吧 点击下方名片，关注公众号:【小白debug】 不满足于在留言区说骚话？ 加我，我们建了个划水吹牛皮群，在群里，你可以跟你下次跳槽可能遇到的同事或面试官聊点有趣的话题。就超！开！心！ 快过年了，群里可能会有红包，懂？ 文章推荐： 程序员防猝死指南 TCP粘包 数据包：我只是犯了每个数据包都会犯的错 |硬核图解 动图图解！GMP模型里为什么要有P？背后的原因让人暖心 i/o timeout，希望你不要踩到这个net/http包的坑 妙啊! 程序猿的第一本互联网黑话指南 我感觉，我可能要拿图灵奖了。。。 给大家丢脸了，用了三年golang，我还是没答对这道内存泄漏题 硬核！漫画图解HTTP知识点+面试题 硬核图解！30张图带你搞懂！路由器，集线器，交换机，网桥，光猫有啥区别？","categories":[{"name":"骚话连篇","slug":"骚话连篇","permalink":"https://xiaobaidebug.top/categories/%E9%AA%9A%E8%AF%9D%E8%BF%9E%E7%AF%87/"}],"tags":[]},{"title":"大学生毕业找工作，该选择哪个方向。","slug":"程序人生/大学生毕业找工作，该选择哪个方向。","date":"2021-11-29T14:57:55.000Z","updated":"2022-10-30T02:28:13.643Z","comments":true,"path":"2021/11/29/程序人生/大学生毕业找工作，该选择哪个方向。/","link":"","permalink":"https://xiaobaidebug.top/2021/11/29/%E7%A8%8B%E5%BA%8F%E4%BA%BA%E7%94%9F/%E5%A4%A7%E5%AD%A6%E7%94%9F%E6%AF%95%E4%B8%9A%E6%89%BE%E5%B7%A5%E4%BD%9C%EF%BC%8C%E8%AF%A5%E9%80%89%E6%8B%A9%E5%93%AA%E4%B8%AA%E6%96%B9%E5%90%91%E3%80%82/","excerpt":"兄弟们。 出来说骚话啊。 考虑到，读者里面，有不少是还未踏入社会的学生党。 今天在这里想简单介绍下行业的区别。 虽然都是写代码，虽然大家都叫程序员，但其实，分为很多种类。程序员大体上分为前端和后端。 因为我不懂前端，所以这里主要讲下后端吧。 而后端，可以从很多角度进行分类。 我们从大家最熟悉的大学专业开始展开吧。 非计算机专业一般提到程序员，都会以为都是计算机专业的，但其实除了计算机专业外，还有一些专业，比如电气工程、自动化、通信工程等，都会有不少相关的对口程序员工种。 比如大学时候学的51单片，STM32之类的相关，那个其实属于嵌入式软件开发的范畴，用的一般是C语言。 如果是画画PCB电路板之类的，那应该属于嵌入式硬件工程师的范畴。 跟这两块比较相近的，还有个工作自动控制系统相关的相关工作，叫PLC工程师。用的编程语言也比较特别，叫梯形图。","text":"兄弟们。 出来说骚话啊。 考虑到，读者里面，有不少是还未踏入社会的学生党。 今天在这里想简单介绍下行业的区别。 虽然都是写代码，虽然大家都叫程序员，但其实，分为很多种类。程序员大体上分为前端和后端。 因为我不懂前端，所以这里主要讲下后端吧。 而后端，可以从很多角度进行分类。 我们从大家最熟悉的大学专业开始展开吧。 非计算机专业一般提到程序员，都会以为都是计算机专业的，但其实除了计算机专业外，还有一些专业，比如电气工程、自动化、通信工程等，都会有不少相关的对口程序员工种。 比如大学时候学的51单片，STM32之类的相关，那个其实属于嵌入式软件开发的范畴，用的一般是C语言。 如果是画画PCB电路板之类的，那应该属于嵌入式硬件工程师的范畴。 跟这两块比较相近的，还有个工作自动控制系统相关的相关工作，叫PLC工程师。用的编程语言也比较特别，叫梯形图。 以上这几种类型工种，一般出现在较为传统的行业里，比如工业控制、车企、电机电梯等企业，没那么传统的，有共享单车、无人机等。 计算机专业这个就很好理解了，也是毕业后进入互联网行业的主力军。而这里面方向也很多，但一般从我了解到的就业情况来说，分为下面这几类。 游戏方向游戏方向也算是互联网行业里比较特殊的一个分支。我们常说的前端和后端，在这里一般是叫客户端和服务端。服务端用的一般是C++，少数使用golang，java等，一般是根据游戏类型去区分，比如像的《率土之滨》之类的策略类游戏叫SLG，《王者荣耀》这种叫moba，《xx传奇》叫MMORPG，《地下城与勇士》这类叫ARPG，这里面服务端的架构设计根据游戏类型会有一些不同，但开发之间用的技术栈大体差距不算太大。 客户端之间差距就有些大了，做2d游戏的一般用cocos，3d游戏前两年一般用unity3D，现在都开始慢慢开始用unreal。而微信小游戏，一般用的laya或者白鹭引擎。当然还有flash小游戏，这个就有些古老了。有一说一，游戏客户端用的技术差异比较大，隔两年换一个新东西学学，太难了。相比之下，游戏服务端用的技术倒是稳定多了。 互联网应用方向 业务开发是最常见的curd boy，对于并不复杂的业务，很多时候就是写写数据库的插入（create），更新（update），读取（read）、删除（delete）等语句。 这里业务其实还细分为to b方向和to c方向，to b的业务一般用户不多，正因为用户不多，所以他们提的每一个问题都有可能被重视并且转化为定制化的需求，因为需求只针对某部分特定人群，所以产品逻辑做的巨复杂，巨奇怪也很正常。to b一般也比to c的产品逻辑更复杂，而产品的主要工作也是直接跟用户沟通，收集用户的痛点并且转化成各种奇怪的需求。用户也可以直接找到这个开发，并且反馈自己的疑问，所以很多时候开发也会沦为oncall工具人。 to c业务一般会相对to b业务来说并发稍微高点，因为产品是面向普通用户，所以设计上也会尽量傻瓜式，这就可以反推背后的逻辑也会相对to b 业务要简单一些。 基础架构开发又名，高级oncall工程师。跟上面的业务开发不同，业务开发oncall的对象一般是没有编程背景的普通用户。基础架构oncall的主要对象还是开发，所以总的来说，沟通理解成本可能会稍微低一些。做基架，也会给人一种更专业的感觉，很多知识都偏向于计算机底层，且通用，比如做网关的或者mesh的，换个公司，做的事情一般还能差不多且能延续。但业务开发，比如做电商的，如果离职跑去做教育，那需要从零开始重新理解业务。 行业上很多大佬都是做基架出身的。业务开发上班时间搞本操作系统来看，还看什么内核源码，那多少有些”不务正业”，”天天摸鱼”的感觉，但如果是基架开发，整这个就非常合情合理了。 安全方向这里面最特别的就是做信息安全的，就是是最接近电影里黑客的方向，就业方向对口的是安全行业，学的东西也跟其他方向的不太一样，这里面有着比较大的gap。我至今不知道他们平时的工作内容是什么，但是经常能看到一个认识的老哥在网上找各种网站的漏洞然后提交官方后获得多少w刀的一个奖励。反正羡慕死我了。 这么多种类怎么选行业怎么选我曾经也当过大学生，也理解大家毕业前面对着这些岗位一脸懵逼的痛点。 如果大家对研究通用化的技术特别感兴趣，并且自身硬实力也较强，可以考虑做基础架构相关的工作，这块学到的东西更通用化。但是这块有个缺点，一般情况下，做基架会离业务远一点。 既然当程序员，选了这么苦的路，除了少部分对技术有这极大热情的兄弟们，那我盲猜大部分兄弟可能跟我一样，是因为钱包比较瘦。 那既然这样，我们聊聊怎么样的岗位有机会赚更多。 大家得明白一个道理，代码不值钱，业务和数据才值钱。如果业务盈利很猛，那你离业务越近，你越有机会跟着吃肉喝汤。 在商业化社会，公司都是为了盈利的，而盈利的，一般是业务部门。当然，不是每个部门都有机会盈利，所以一旦不盈利，被裁得最快的也是业务开发。 那么问题来了，什么样的业务，离曼妮比较近呢。以我浅薄的认知水平，目前看下来，游戏、电商，金融这三个行业离曼妮是比较近的，越符合人性的业务功能越容易盈利，比如短视频，游戏这些，就很符合人性。而教育，运动这种，属于比较反人性的，可能就难一些。但凡事无绝对，神级产品经理可以无视一切常理。 所以，打工人，不要把路走窄了。 语言怎么选虽然不管什么语言，都能实现相似的功能，但是从目前的行业情况来看，不同的语言在不同行业里会有一定的分化。 比如如果你做嵌入式软件开发，那你一般是用C语言。做电商一般也是java，做游戏一般是C++。而golang，目前用的公司也越来越多了，有用它做游戏的，也有用于电商，网页后台。 为了不引起语言争论，如果大家不知道选什么语言，那可以考虑下java或golang。java这一块人多，竞争激烈些。选C++，学习路线比较陡峭，过于博大精深。选golang的话，比较简单，同时没有太多历史包袱，唯一的缺点就是岗位相对少一些，但目前看下来比前两年更多，相信以后用的人越来越多。 如果你做游戏，又想转互联网应用方向，那么做golang挺好的，它可以在这两个方向里来回横跳。 最后当然，以上都是一些人生建议。而且不一定对，都是我认知范围内的一些信息。大家听不听都不重要，毕竟很多人知道很多道理，依然过不好这一生。 比如我，以前做游戏的时候，游戏版号就被封了好长时间，行业确实也没之前那么景气了。后来认为教育是风口，想成为那头在风口上起飞的猪，结果这今年双减，长期来看可能也不太乐观。 干啥都凉，我小白，还真的是行业瞑灯啊，害。。。 如果文章对你有帮助，欢迎….. 算了。 别说了，一起在知识的海洋里呛水吧点击下方名片，关注公众号:【小白debug】 不满足于在留言区说骚话？ 加我，我们建了个划水吹牛皮群，在群里，你可以跟你下次跳槽可能遇到的同事或面试官聊点阳间的话题。就超！开！心！ 文章推荐： 程序员防猝死指南 TCP粘包 数据包：我只是犯了每个数据包都会犯的错 |硬核图解 动图图解！既然IP层会分片，为什么TCP层也还要分段？","categories":[{"name":"骚话连篇","slug":"骚话连篇","permalink":"https://xiaobaidebug.top/categories/%E9%AA%9A%E8%AF%9D%E8%BF%9E%E7%AF%87/"}],"tags":[]},{"title":"动图图解！怎么让goroutine跑一半就退出？","slug":"golang面试题/动图图解！怎么让goroutine跑一半就退出？","date":"2021-11-15T14:57:55.000Z","updated":"2022-10-30T02:28:13.644Z","comments":true,"path":"2021/11/15/golang面试题/动图图解！怎么让goroutine跑一半就退出？/","link":"","permalink":"https://xiaobaidebug.top/2021/11/15/golang%E9%9D%A2%E8%AF%95%E9%A2%98/%E5%8A%A8%E5%9B%BE%E5%9B%BE%E8%A7%A3%EF%BC%81%E6%80%8E%E4%B9%88%E8%AE%A9goroutine%E8%B7%91%E4%B8%80%E5%8D%8A%E5%B0%B1%E9%80%80%E5%87%BA%EF%BC%9F/","excerpt":"光看标题，大家可能不太理解我说的是啥。","text":"光看标题，大家可能不太理解我说的是啥。 我们平时创建一个协程，跑一段逻辑，代码大概长这样。 1234567891011121314151617181920212223package mainimport ( &quot;fmt&quot; &quot;time&quot;)func Foo() &#123; fmt.Println(&quot;打印1&quot;) defer fmt.Println(&quot;打印2&quot;) fmt.Println(&quot;打印3&quot;)&#125;func main() &#123; go Foo() fmt.Println(&quot;打印4&quot;) time.Sleep(1000*time.Second)&#125;// 这段代码，正常运行会有下面的结果打印4打印1打印3打印2 注意这上面”打印2“是在defer中的，所以会在函数结束前打印。因此后置于”打印3“。 那么今天的问题是，如何让Foo()函数跑一半就结束，比如说跑到打印2，就退出协程。输出如下结果 123打印4打印1打印2 也不卖关子了，我这边直接说答案。 在”打印2”后面插入一个 runtime.Goexit()， 协程就会直接结束。并且结束前还能执行到defer里的打印2。 12345678910111213141516171819202122232425package mainimport ( &quot;fmt&quot; &quot;runtime&quot; &quot;time&quot;)func Foo() &#123; fmt.Println(&quot;打印1&quot;) defer fmt.Println(&quot;打印2&quot;) runtime.Goexit() // 加入这行 fmt.Println(&quot;打印3&quot;)&#125;func main() &#123; go Foo() fmt.Println(&quot;打印4&quot;) time.Sleep(1000*time.Second)&#125;// 输出结果打印4打印1打印2 可以看到打印3这一行没出现了，协程确实提前结束了。 其实面试题到这里就讲完了，这一波自问自答可还行？ 但这不是今天的重点，我们需要搞搞清楚内部的逻辑。 runtime.Goexit()是什么？看一下内部实现。 1234567891011121314func Goexit() &#123; // 以下函数省略一些逻辑... gp := getg() for &#123; // 获取defer并执行 d := gp._defer reflectcall(nil, unsafe.Pointer(d.fn), deferArgs(d), uint32(d.siz), uint32(d.siz)) &#125; goexit1()&#125;func goexit1() &#123; mcall(goexit0)&#125; 从代码上看，runtime.Goexit()会先执行一下defer里的方法，这里就解释了开头的代码里为什么在defer里的打印2能正常输出。 然后代码再执行goexit1。本质就是对goexit0的简单封装。 我们可以把代码继续跟下去，看看goexit0做了什么。 123456789101112131415161718192021222324// goexit continuation on g0.func goexit0(gp *g) &#123; // 获取当前的 goroutine _g_ := getg() // 将当前goroutine的状态置为 _Gdead casgstatus(gp, _Grunning, _Gdead) // 全局协程数减一 if isSystemGoroutine(gp, false) &#123; atomic.Xadd(&amp;sched.ngsys, -1) &#125; // 省略各种清空逻辑... // 把g从m上摘下来。 dropg() // 把这个g放回到p的本地协程队列里，放不下放全局协程队列。 gfput(_g_.m.p.ptr(), gp) // 重新调度，拿下一个可运行的协程出来跑 schedule()&#125; 这段代码，信息密度比较大。 很多名词可能让人一脸懵。 简单描述下，Go语言里有个GMP模型的说法，M是内核线程，G也就是我们平时用的协程goroutine，P会在G和M之间做工具人，负责调度G到M上运行。 既然是调度，也就是说不是每个G都能一直处于运行状态，等G不能运行时，就把它存起来，再调度下一个能运行的G过来运行。 暂时不能运行的G，P上会有个本地队列去存放这些这些G，P的本地队列存不下的话，还有个全局队列，干的事情也类似。 了解这个背景后，再回到 goexit0 方法看看，做的事情就是将当前的协程G置为_Gdead状态，然后把它从M上摘下来，尝试放回到P的本地队列中。然后重新调度一波，获取另一个能跑的G，拿出来跑。 所以简单总结一下，只要执行 goexit 这个函数，当前协程就会退出，同时还能调度下一个可执行的协程出来跑。 看到这里，大家应该就能理解，开头的代码里，为什么runtime.Goexit()能让协程只执行一半就结束了。 goexit的用途看是看懂了，但是会忍不住疑惑。面试这么问问，那只能说明你遇到了一个喜欢为难年轻人的面试官，但正经人谁会没事跑一半协程就结束呢？所以goexit的真实用途是啥？ 有个小细节，不知道大家平时debug的时候有没有关注过。 为了说明问题，这里先给出一段代码。 123456789101112131415package mainimport ( &quot;fmt&quot; &quot;time&quot;)func Foo() &#123; fmt.Println(&quot;打印1&quot;)&#125;func main() &#123; go Foo() fmt.Println(&quot;打印3&quot;) time.Sleep(1000*time.Second)&#125; 这是一段非常简单的代码，输出什么完全不重要。通过go关键字启动了一个goroutine执行Foo()，里面打印一下就结束，主协程sleep很长时间，只为死等。 这里我们新启动的协程里，在Foo()函数内随便打个断点。然后debug一下。 会发现，这个协程的堆栈底部是从runtime.goexit()里开始启动的。 如果大家平时有注意观察，会发现，其实所有的堆栈底部，都是从这个函数开始的。我们继续跟跟代码。 goexit是什么？从上面的debug堆栈里点进去会发现，这是个汇编函数，可以看出调用的是runtime包内的 goexit1() 函数。 1234567// The top-most function running on a goroutine// returns to goexit+PCQuantum.TEXT runtime·goexit(SB),NOSPLIT,$0-0 BYTE $0x90 // NOP CALL runtime·goexit1(SB) // does not return // traceback from goexit1 must hit code range of goexit BYTE $0x90 // NOP 于是跟到了pruntime/proc.go里的代码中。 1234// 省略部分代码func goexit1() &#123; mcall(goexit0)&#125; 是不是很熟悉，这不就是我们开头讲runtime.Goexit()里内部执行的goexit0吗。 为什么每个堆栈底部都是这个方法？我们首先需要知道的是，函数栈的执行过程，是先进后出。 假设我们有以下代码 1234567891011func main() &#123; B()&#125;func B() &#123; A()&#125;func A() &#123;&#125; 上面的代码是main运行B函数，B函数再运行A函数，代码执行时就跟下面的动图那样。 这个是先进后出的过程，也就是我们常说的函数栈，执行完子函数A()后，就会回到父函数B()中，执行完B()后，最后就会回到main()。这里的栈底是main()，如果在栈底插入的是 goexit 的话，那么当程序执行结束的时候就都能跑到goexit里去。 结合前面讲过的内容，我们就能知道，此时栈底的goexit，会在协程内的业务代码跑完后被执行到，从而实现协程退出，并调度下一个可执行的G来运行。 那么问题又来了，栈底插入goexit这件事是谁做的，什么时候做的？ 直接说答案，这个在runtime/proc.go里有个newproc1方法，只要是创建协程都会用到这个方法。里面有个地方是这么写的。 1234567891011121314151617func newproc1(fn *funcval, argp unsafe.Pointer, narg int32, callergp *g, callerpc uintptr) &#123; // 获取当前g _g_ := getg() // 获取当前g所在的p _p_ := _g_.m.p.ptr() // 创建一个新 goroutine newg := gfget(_p_) // 底部插入goexit newg.sched.pc = funcPC(goexit) + sys.PCQuantum newg.sched.g = guintptr(unsafe.Pointer(newg)) // 把新创建的g放到p中 runqput(_p_, newg, true) // ...&#125; 主要的逻辑是获取当前协程G所在的调度器P，然后创建一个新G，并在栈底插入一个goexit。 所以我们每次debug的时候，就都能看到函数栈底部有个goexit函数。 main函数也是个协程，栈底也是goexit？关于main函数栈底是不是也有个goexit，我们对下面代码断点看下。直接得出结果。 main函数栈底也是goexit()。 从 asm_amd64.s可以看到Go程序启动的流程，这里提到的 runtime·mainPC 其实就是 runtime.main. 12345// create a new goroutine to start programMOVQ $runtime·mainPC(SB), AX // 也就是runtime.mainPUSHQ AXPUSHQ $0 // arg sizeCALL runtime·newproc(SB) 通过runtime·newproc创建runtime.main协程，然后在runtime.main里会启动main.main函数，这个就是我们平时写的那个main函数了。 123456789// runtime/proc.gofunc main() &#123; // 省略大量代码 fn := main_main // 其实就是我们的main函数入口 fn() &#125;//go:linkname main_main main.mainfunc main_main() 结论是，其实main函数也是由newproc创建的，只要通过newproc创建的goroutine，栈底就会有一个goexit。 os.Exit()和runtime.Goexit()有什么区别最后再回到开头的问题，实现一下首尾呼应。 开头的面试题，除了runtime.Goexit()，是不是还可以改为用os.Exit()？ 同样都是带有”退出”的含义，两者退出的对象不同。os.Exit() 指的是整个进程退出；而runtime.Goexit()指的是协程退出。 可想而知，改用os.Exit() 这种情况下，defer里的内容就不会被执行到了。 123456789101112131415161718192021222324package mainimport ( &quot;fmt&quot; &quot;os&quot; &quot;time&quot;)func Foo() &#123; fmt.Println(&quot;打印1&quot;) defer fmt.Println(&quot;打印2&quot;) os.Exit(0) fmt.Println(&quot;打印3&quot;)&#125;func main() &#123; go Foo() fmt.Println(&quot;打印4&quot;) time.Sleep(1000*time.Second)&#125;// 输出结果打印4打印1 总结 通过 runtime.Goexit()可以做到提前结束协程，且结束前还能执行到defer的内容 runtime.Goexit()其实是对goexit0的封装，只要执行 goexit0 这个函数，当前协程就会退出，同时还能调度下一个可执行的协程出来跑。 通过newproc可以创建出新的goroutine，它会在函数栈底部插入一个goexit。 os.Exit() 指的是整个进程退出；而runtime.Goexit()指的是协程退出。两者含义有区别。 最后无用的知识又增加了。 一般情况下，业务开发中，谁会没事执行这个函数呢？ 但是开发中不关心，不代表面试官不关心！ 下次面试官问你，如果想在goroutine执行一半就退出协程，该怎么办？你知道该怎么回答了吧？ 好了，兄弟们，有没有发现这篇文章写的又水又短，真的是因为我变懒了吗？ 不！ 当然不！ 我是为了兄弟们的身体健康考虑，保持蹲姿太久对身体不好，懂？ 如果文章对你有帮助，欢迎….. 算了。 一起在知识的海洋里呛水吧 我是小白，我们下期见！ 点击下方名片，关注公众号:【小白debug】 不满足于在留言区说骚话？ 加我，我们建了个划水吹牛皮群，在群里，你可以跟你下次跳槽可能遇到的同事或面试官聊点有趣的话题。就超！开！心！ 文章推荐： 程序员防猝死指南 TCP粘包 数据包：我只是犯了每个数据包都会犯的错 |硬核图解 动图图解！既然IP层会分片，为什么TCP层也还要分段？ 参考资料饶大的《哪来里的 goexit？》- https://qcrao.com/2021/06/07/where-is-goexit-from/","categories":[{"name":"golang面试题","slug":"golang面试题","permalink":"https://xiaobaidebug.top/categories/golang%E9%9D%A2%E8%AF%95%E9%A2%98/"}],"tags":[]},{"title":"动图图解！没有accept，能建立TCP连接吗？","slug":"图解网络/没有accept能建立TCP连接吗","date":"2021-09-25T14:57:55.000Z","updated":"2022-10-30T02:28:13.643Z","comments":true,"path":"2021/09/25/图解网络/没有accept能建立TCP连接吗/","link":"","permalink":"https://xiaobaidebug.top/2021/09/25/%E5%9B%BE%E8%A7%A3%E7%BD%91%E7%BB%9C/%E6%B2%A1%E6%9C%89accept%E8%83%BD%E5%BB%BA%E7%AB%8BTCP%E8%BF%9E%E6%8E%A5%E5%90%97/","excerpt":"上面这个动图，是我们平时客户端和服务端建立连接时的代码流程。 对应的是下面一段简化过的服务端伪代码。","text":"上面这个动图，是我们平时客户端和服务端建立连接时的代码流程。 对应的是下面一段简化过的服务端伪代码。 1234567891011121314151617int main()&#123; /*Step 1: 创建服务器端监听socket描述符listen_fd*/ listen_fd = socket(AF_INET, SOCK_STREAM, 0); /*Step 2: bind绑定服务器端的IP和端口，所有客户端都向这个IP和端口发送和请求数据*/ bind(listen_fd, xxx); /*Step 3: 服务端开启监听*/ listen(listen_fd, 128); /*Step 4: 服务器等待客户端的链接，返回值cfd为客户端的socket描述符*/ cfd = accept(listen_fd, xxx); /*Step 5: 读取客户端发来的数据*/ n = read(cfd, buf, sizeof(buf));&#125; 估计大家也是老熟悉这段伪代码了。 需要注意的是，在执行listen()方法之后还会执行一个accept()方法。 一般情况下，如果启动服务器，会发现最后程序会阻塞在accept()里。 此时服务端就算ok了，就等客户端了。 那么，再看下简化过的客户端伪代码。 1234567891011int main()&#123; /*Step 1: 创建客户端端socket描述符cfd*/ cfd = socket(AF_INET, SOCK_STREAM, 0); /*Step 2: connect方法,对服务器端的IP和端口号发起连接*/ ret = connect(cfd, xxxx); /*Step 4: 向服务器端写数据*/ write(cfd, buf, strlen(buf));&#125; 客户端比较简单，创建好socket之后，直接就发起connect方法。 此时回到服务端，会发现之前一直阻塞的accept方法，返回结果了。 这就算两端成功建立好了一条连接。之后就可以愉快的进行读写操作了。 那么，我们今天的问题是，如果没有这个accept方法，TCP连接还能建立起来吗？ 其实只要在执行accept() 之前执行一个 sleep(20)，然后立刻执行客户端相关的方法，同时抓个包，就能得出结论。 从抓包结果看来，就算不执行accept()方法，三次握手照常进行，并顺利建立连接。 更骚气的是，在服务端执行accept()前，如果客户端发送消息给服务端，服务端是能够正常回复ack确认包的。 并且，sleep(20)结束后，服务端正常执行accept()，客户端前面发送的消息，还是能正常收到的。 通过这个现象，我们可以多想想为什么。顺便好好了解下三次握手的细节。 三次握手的细节分析我们先看面试八股文的老股，三次握手。 服务端代码，对socket执行bind方法可以绑定监听端口，然后执行listen方法后，就会进入监听（LISTEN）状态。内核会为每一个处于LISTEN状态的socket 分配两个队列，分别叫半连接队列和全连接队列。 半连接队列、全连接队列是什么 半连接队列（SYN队列），服务端收到第一次握手后，会将sock加入到这个队列中，队列内的sock都处于SYN_RECV 状态。 全连接队列（ACCEPT队列），在服务端收到第三次握手后，会将半连接队列的sock取出，放到全连接队列中。队列里的sock都处于 ESTABLISHED状态。这里面的连接，就等着服务端执行accept()后被取出了。 看到这里，文章开头的问题就有了答案，建立连接的过程中根本不需要accept() 参与， 执行accept()只是为了从全连接队列里取出一条连接。 我们把话题再重新回到这两个队列上。 虽然都叫队列，但其实全连接队列（icsk_accept_queue）是个链表，而半连接队列（syn_table）是个哈希表。 为什么半连接队列要设计成哈希表先对比下全连接里队列，他本质是个链表，因为也是线性结构，说它是个队列也没毛病。它里面放的都是已经建立完成的连接，这些连接正等待被取走。而服务端取走连接的过程中，并不关心具体是哪个连接，只要是个连接就行，所以直接从队列头取就行了。这个过程算法复杂度为O(1)。 而半连接队列却不太一样，因为队列里的都是不完整的连接，嗷嗷等待着第三次握手的到来。那么现在有一个第三次握手来了，则需要从队列里把相应IP端口的连接取出，如果半连接队列还是个链表，那我们就需要依次遍历，才能拿到我们想要的那个连接，算法复杂度就是O(n)。 而如果将半连接队列设计成哈希表，那么查找半连接的算法复杂度就回到O(1)了。 因此出于效率考虑，全连接队列被设计成链表，而半连接队列被设计为哈希表。 怎么观察两个队列的大小查看全连接队列123# ss -lntState Recv-Q Send-Q Local Address:Port Peer Address:PortLISTEN 0 128 127.0.0.1:46269 *:* 通过ss -lnt命令，可以看到全连接队列的大小，其中Send-Q是指全连接队列的最大值，可以看到我这上面的最大值是128；Recv-Q是指当前的全连接队列的使用值，我这边用了0个，也就是全连接队列里为空，连接都被取出来了。 当上面Send-Q和Recv-Q数值很接近的时候，那么全连接队列可能已经满了。可以通过下面的命令查看是否发生过队列溢出。 12# netstat -s | grep overflowed 4343 times the listen queue of a socket overflowed 上面说明发生过4343次全连接队列溢出的情况。这个查看到的是历史发生过的次数。 如果配合使用watch -d 命令，可以自动每2s间隔执行相同命令，还能高亮显示变化的数字部分，如果溢出的数字不断变多，说明正在发生溢出的行为。 1234# watch -d &#x27;netstat -s | grep overflowed&#x27;Every 2.0s: netstat -s | grep overflowed Fri Sep 17 09:00:45 2021 4343 times the listen queue of a socket overflowed 查看半连接队列半连接队列没有命令可以直接查看到，但因为半连接队列里，放的都是SYN_RECV 状态的连接，那可以通过统计处于这个状态的连接的数量，间接获得半连接队列的长度。 12# netstat -nt | grep -i &#x27;127.0.0.1:8080&#x27; | grep -i &#x27;SYN_RECV&#x27; | wc -l0 注意半连接队列和全连接队列都是挂在某个Listen socket上的，我这里用的是127.0.0.1:8080，大家可以替换成自己想要查看的IP端口。 可以看到我的机器上的半连接队列长度为0，这个很正常，正经连接谁会没事老待在半连接队列里。 当队列里的半连接不断增多，最终也是会发生溢出，可以通过下面的命令查看。 12# netstat -s | grep -i &quot;SYNs to LISTEN sockets dropped&quot; 26395 SYNs to LISTEN sockets dropped 可以看到，我的机器上一共发生了26395次半连接队列溢出。同样建议配合watch -d 命令使用。 1234# watch -d &#x27;netstat -s | grep -i &quot;SYNs to LISTEN sockets dropped&quot;&#x27;Every 2.0s: netstat -s | grep -i &quot;SYNs to LISTEN sockets dropped&quot; Fri Sep 17 08:36:38 2021 26395 SYNs to LISTEN sockets dropped 全连接队列满了会怎么样？如果队列满了，服务端还收到客户端的第三次握手ACK，默认当然会丢弃这个ACK。 但除了丢弃之外，还有一些附带行为，这会受 tcp_abort_on_overflow 参数的影响。 12# cat /proc/sys/net/ipv4/tcp_abort_on_overflow0 tcp_abort_on_overflow设置为 0，全连接队列满了之后，会丢弃这个第三次握手ACK包，并且开启定时器，重传第二次握手的SYN+ACK，如果重传超过一定限制次数，还会把对应的半连接队列里的连接给删掉。 tcp_abort_on_overflow设置为 1，全连接队列满了之后，就直接发RST给客户端，效果上看就是连接断了。 这个现象是不是很熟悉，服务端端口未监听时，客户端尝试去连接，服务端也会回一个RST。这两个情况长一样，所以客户端这时候收到RST之后，其实无法区分到底是端口未监听，还是全连接队列满了。 半连接队列要是满了会怎么样一般是丢弃，但这个行为可以通过 tcp_syncookies 参数去控制。但比起这个，更重要的是先了解下半连接队列为什么会被打满。 首先我们需要明白，一般情况下，半连接的”生存”时间其实很短，只有在第一次和第三次握手间，如果半连接都满了，说明服务端疯狂收到第一次握手请求，如果是线上游戏应用，能有这么多请求进来，那说明你可能要富了。但现实往往比较骨感，你可能遇到了SYN Flood攻击。 所谓SYN Flood攻击，可以简单理解为，攻击方模拟客户端疯狂发第一次握手请求过来，在服务端憨憨地回复第二次握手过去之后，客户端死活不发第三次握手过来，这样做，可以把服务端半连接队列打满，从而导致正常连接不能正常进来。 那这种情况怎么处理？有没有一种方法可以绕过半连接队列？ 有，上面提到的tcp_syncookies派上用场了。 12# cat /proc/sys/net/ipv4/tcp_syncookies1 当它被设置为1的时候，客户端发来第一次握手SYN时，服务端不会将其放入半连接队列中，而是直接生成一个cookies，这个cookies会跟着第二次握手，发回客户端。客户端在发第三次握手的时候带上这个cookies，服务端验证到它就是当初发出去的那个，就会建立连接并放入到全连接队列中。可以看出整个过程不再需要半连接队列的参与。 会有一个cookies队列吗生成是cookies，保存在哪呢？是不是会有一个队列保存这些cookies？ 我们可以反过来想一下，如果有cookies队列，那它会跟半连接队列一样，到头来，还是会被SYN Flood 攻击打满。 实际上cookies并不会有一个专门的队列保存，它是通过通信双方的IP地址端口、时间戳、MSS等信息进行实时计算的，保存在TCP报头的seq里。 当服务端收到客户端发来的第三次握手包时，会通过seq还原出通信双方的IP地址端口、时间戳、MSS，验证通过则建立连接。 cookies方案为什么不直接取代半连接队列？目前看下来syn cookies方案省下了半连接队列所需要的队列内存，还能解决 SYN Flood攻击，那为什么不直接取代半连接队列？ 凡事皆有利弊，cookies方案虽然能防 SYN Flood攻击，但是也有一些问题。因为服务端并不会保存连接信息，所以如果传输过程中数据包丢了，也不会重发第二次握手的信息。 另外，编码解码cookies，都是比较耗CPU的，利用这一点，如果此时攻击者构造大量的第三次握手包（ACK包），同时带上各种瞎编的cookies信息，服务端收到ACK包后以为是正经cookies，憨憨地跑去解码（耗CPU），最后发现不是正经数据包后才丢弃。 这种通过构造大量ACK包去消耗服务端资源的攻击，叫ACK攻击，受到攻击的服务器可能会因为CPU资源耗尽导致没能响应正经请求。 没有listen，为什么还能建立连接那既然没有accept方法能建立连接，那是不是没有listen方法，也能建立连接？是的，之前写的一篇文章提到过客户端是可以自己连自己的形成连接（TCP自连接），也可以两个客户端同时向对方发出请求建立连接（TCP同时打开），这两个情况都有个共同点，就是没有服务端参与，也就是没有listen，就能建立连接。 当时文章最后也留了个疑问，没有listen，为什么还能建立连接？ 我们知道执行listen方法时，会创建半连接队列和全连接队列。 三次握手的过程中会在这两个队列中暂存连接信息。 所以形成连接，前提是你得有个地方存放着，方便握手的时候能根据IP端口等信息找到socket信息。 那么客户端会有半连接队列吗？ 显然没有，因为客户端没有执行listen，因为半连接队列和全连接队列都是在执行listen方法时，内核自动创建的。 但内核还有个全局hash表，可以用于存放sock连接的信息。这个全局hash表其实还细分为ehash，bhash和listen_hash等，但因为过于细节，大家理解成有一个全局hash就够了， 在TCP自连接的情况中，客户端在connect方法时，最后会将自己的连接信息放入到这个全局hash表中，然后将信息发出，消息在经过回环地址重新回到TCP传输层的时候，就会根据IP端口信息，再一次从这个全局hash中取出信息。于是握手包一来一回，最后成功建立连接。 TCP同时打开的情况也类似，只不过从一个客户端变成了两个客户端而已。 总结 每一个socket执行listen时，内核都会自动创建一个半连接队列和全连接队列。 第三次握手前，TCP连接会放在半连接队列中，直到第三次握手到来，才会被放到全连接队列中。 accept方法只是为了从全连接队列中拿出一条连接，本身跟三次握手几乎毫无关系。 出于效率考虑，虽然都叫队列，但半连接队列其实被设计成了哈希表，而全连接队列本质是链表。 全连接队列满了，再来第三次握手也会丢弃，此时如果tcp_abort_on_overflow=1，还会直接发RST给客户端。 半连接队列满了，可能是因为受到了SYN Flood攻击，可以设置tcp_syncookies，绕开半连接队列。 客户端没有半连接队列和全连接队列，但有一个全局hash，可以通过它实现自连接或TCP同时打开。 参考资料小林图解网络 – 推荐大家关注《小林coding》 如果文章对你有帮助，欢迎….. 算了。 兄弟们都是自家人，点不点赞，在不在看什么的，没关系的，大家看开心了就好。 在看，点赞什么的，我不是特别在意，真的，真的，别不信啊。 不三连也真的没关系的。 兄弟们不要在意啊。 我是虚伪的小白，我们下期见！ 别说了，一起在知识的海洋里呛水吧点击下方名片，关注公众号:【小白debug】 不满足于在留言区说骚话？ 加我，我们建了个划水吹牛皮群，在群里，你可以跟你下次跳槽可能遇到的同事或面试官聊点阳间的话题。就超！开！心！ 文章推荐： 程序员防猝死指南 TCP粘包 数据包：我只是犯了每个数据包都会犯的错 |硬核图解 动图图解！既然IP层会分片，为什么TCP层也还要分段？","categories":[{"name":"图解网络","slug":"图解网络","permalink":"https://xiaobaidebug.top/categories/%E5%9B%BE%E8%A7%A3%E7%BD%91%E7%BB%9C/"}],"tags":[]},{"title":"活久见！TCP两次挥手，你见过吗？那四次握手呢？","slug":"图解网络/活久见！TCP两次挥手，你见过吗？那四次握手呢？","date":"2021-09-25T14:57:55.000Z","updated":"2022-10-30T02:28:13.643Z","comments":true,"path":"2021/09/25/图解网络/活久见！TCP两次挥手，你见过吗？那四次握手呢？/","link":"","permalink":"https://xiaobaidebug.top/2021/09/25/%E5%9B%BE%E8%A7%A3%E7%BD%91%E7%BB%9C/%E6%B4%BB%E4%B9%85%E8%A7%81%EF%BC%81TCP%E4%B8%A4%E6%AC%A1%E6%8C%A5%E6%89%8B%EF%BC%8C%E4%BD%A0%E8%A7%81%E8%BF%87%E5%90%97%EF%BC%9F%E9%82%A3%E5%9B%9B%E6%AC%A1%E6%8F%A1%E6%89%8B%E5%91%A2%EF%BC%9F/","excerpt":"我们都知道，TCP是个面向连接的、可靠的、基于字节流的传输层通信协议。 那这里面提到的”面向连接“，意味着需要 建立连接，使用连接，释放连接。 建立连接是指我们熟知的TCP三次握手。 而使用连接，则是通过一发送、一确认的形式，进行数据传输。 还有就是释放连接，也就是我们常见的TCP四次挥手。 TCP四次挥手大家应该比较了解了，但大家见过三次挥手吗？还有两次挥手呢？ 都见过？ 那四次握手呢？ 今天这个话题，不想只是猎奇，也不想搞冷知识。 我们从四次挥手开始说起，搞点实用的知识点。","text":"我们都知道，TCP是个面向连接的、可靠的、基于字节流的传输层通信协议。 那这里面提到的”面向连接“，意味着需要 建立连接，使用连接，释放连接。 建立连接是指我们熟知的TCP三次握手。 而使用连接，则是通过一发送、一确认的形式，进行数据传输。 还有就是释放连接，也就是我们常见的TCP四次挥手。 TCP四次挥手大家应该比较了解了，但大家见过三次挥手吗？还有两次挥手呢？ 都见过？ 那四次握手呢？ 今天这个话题，不想只是猎奇，也不想搞冷知识。 我们从四次挥手开始说起，搞点实用的知识点。 TCP四次挥手简单回顾下TCP四次挥手。 正常情况下。只要数据传输完了，不管是客户端还是服务端，都可以主动发起四次挥手，释放连接。 就跟上图画的一样，假设，这次四次挥手是由客户端主动发起的，那它就是主动方。服务器是被动接收客户端的挥手请求的，叫被动方。 客户端和服务器，一开始，都是处于ESTABLISHED状态。 第一次挥手：一般情况下，主动方执行close()或 shutdown()方法，会发个FIN报文出来，表示”我不再发送数据了“。 第二次挥手：在收到主动方的FIN报文后，被动方立马回应一个ACK，意思是”我收到你的FIN了，也知道你不再发数据了”。 上面提到的是主动方不再发送数据了。但如果这时候，被动方还有数据要发，那就继续发。注意，虽然第二次和第三次挥手之间，被动方是能发数据到主动方的，但主动方能不能正常收就不一定了，这个待会说。 第三次挥手：在被动方在感知到第二次挥手之后，会做了一系列的收尾工作，最后也调用一个 close(), 这时候就会发出第三次挥手的 FIN-ACK。 第四次挥手：主动方回一个ACK，意思是收到了。 其中第一次挥手和第三次挥手，都是我们在应用程序中主动触发的（比如调用close()方法），也就是我们平时写代码需要关注的地方。 第二和第四次挥手，都是内核协议栈自动帮我们完成的，我们写代码的时候碰不到这地方，因此也不需要太关心。 另外不管是主动还是被动，每方发出了一个 FIN 和一个ACK 。也收到了一个 FIN 和一个ACK 。这一点大家关注下，待会还会提到。 FIN一定要程序执行close()或shutdown()才能发出吗？不一定。一般情况下，通过对socket执行 close() 或 shutdown() 方法会发出FIN。但实际上，只要应用程序退出，不管是主动退出，还是被动退出（因为一些莫名其妙的原因被kill了）, 都会发出 FIN。 FIN 是指”我不再发送数据”，因此shutdown() 关闭读不会给对方发FIN, 关闭写才会发FIN。 如果机器上FIN-WAIT-2状态特别多，是为什么根据上面的四次挥手图，可以看出，FIN-WAIT-2是主动方那边的状态。 处于这个状态的程序，一直在等第三次挥手的FIN。而第三次挥手需要由被动方在代码里执行close() 发出。 因此当机器上FIN-WAIT-2状态特别多，那一般来说，另外一台机器上会有大量的 CLOSE_WAIT。需要检查有大量的 CLOSE_WAIT的那台机器，为什么迟迟不愿调用close()关闭连接。 所以，如果机器上FIN-WAIT-2状态特别多，一般是因为对端一直不执行close()方法发出第三次挥手。 主动方在close之后收到的数据，会怎么处理之前写的一篇文章《代码执行send成功后，数据就发出去了吗？》中，从源码的角度提到了，一般情况下，程序主动执行close()的时候； 如果当前连接对应的socket的接收缓冲区有数据，会发RST。 如果发送缓冲区有数据，那会等待发送完，再发第一次挥手的FIN。 大家知道，TCP是全双工通信，意思是发送数据的同时，还可以接收数据。 Close()的含义是，此时要同时关闭发送和接收消息的功能。 也就是说，虽然理论上，第二次和第三次挥手之间，被动方是可以传数据给主动方的。 但如果 主动方的四次挥手是通过 close() 触发的，那主动方是不会去收这个消息的。而且还会回一个 RST。直接结束掉这次连接。 第二第三次挥手之间，不能传输数据吗？也不是。前面提到Close()的含义是，要同时关闭发送和接收消息的功能。 那如果能做到只关闭发送消息，不关闭接收消息的功能，那就能继续收消息了。这种 half-close 的功能，通过调用shutdown() 方法就能做到。 1int shutdown(int sock, int howto); 其中 howto 为断开方式。有以下取值： SHUT_RD：关闭读。这时应用层不应该再尝试接收数据，内核协议栈中就算接收缓冲区收到数据也会被丢弃。 SHUT_WR：关闭写。如果发送缓冲区中还有数据没发，会将将数据传递到目标主机。 SHUT_RDWR：关闭读和写。相当于close()了。 怎么知道对端socket执行了close还是shutdown不管主动关闭方调用的是close()还是shutdown()，对于被动方来说，收到的就只有一个FIN。 被动关闭方就懵了，”我怎么知道对方让不让我继续发数据？” 其实，大可不必纠结，该发就发。 第二次挥手和第三次挥手之间，如果被动关闭方想发数据，那么在代码层面上，就是执行了 send() 方法。 1int send( SOCKET s,const char* buf,int len,int flags); send() 会把数据拷贝到本机的发送缓冲区。如果发送缓冲区没出问题，都能拷贝进去，所以正常情况下，send()一般都会返回成功。 然后被动方内核协议栈会把数据发给主动关闭方。 如果上一次主动关闭方调用的是shutdown(socket_fd, SHUT_WR)。那此时，主动关闭方不再发送消息，但能接收被动方的消息，一切如常，皆大欢喜。 如果上一次主动关闭方调用的是close()。那主动方在收到被动方的数据后会直接丢弃，然后回一个RST。 针对第二种情况。 被动方内核协议栈收到了RST，会把连接关闭。但内核连接关闭了，应用层也不知道（除非被通知）。 此时被动方应用层接下来的操作，无非就是读或写。 如果是读，则会返回RST的报错，也就是我们常见的Connection reset by peer。 如果是写，那么程序会产生SIGPIPE信号，应用层代码可以捕获并处理信号，如果不处理，则默认情况下进程会终止，异常退出。 总结一下，当被动关闭方 recv() 返回EOF时，说明主动方通过 close()或 shutdown(fd, SHUT_WR) 发起了第一次挥手。 如果此时被动方执行两次 send()。 第一次send(), 一般会成功返回。 第二次send()时。如果主动方是通过 shutdown(fd, SHUT_WR) 发起的第一次挥手，那此时send()还是会成功。如果主动方通过 close()发起的第一次挥手，那此时会产生SIGPIPE信号，进程默认会终止，异常退出。不想异常退出的话，记得捕获处理这个信号。 如果被动方一直不发第三次挥手，会怎么样第三次挥手，是由被动方主动触发的，比如调用close()。 如果由于代码错误或者其他一些原因，被动方就是不执行第三次挥手。 这时候，主动方会根据自身第一次挥手的时候用的是 close() 还是 shutdown(fd, SHUT_WR) ，有不同的行为表现。 如果是 shutdown(fd, SHUT_WR) ，说明主动方其实只关闭了写，但还可以读，此时会一直处于 FIN-WAIT-2， 死等被动方的第三次挥手。 如果是 close()， 说明主动方读写都关闭了，这时候会处于 FIN-WAIT-2一段时间，这个时间由 net.ipv4.tcp_fin_timeout 控制，一般是 60s，这个值正好跟2MSL一样 。超过这段时间之后，状态不会变成 TIME-WAIT，而是直接变成CLOSED。 12# cat /proc/sys/net/ipv4/tcp_fin_timeout60 TCP三次挥手四次挥手聊完了，那有没有可能出现三次挥手？ 是可能的。 我们知道，TCP四次挥手里，第二次和第三次挥手之间，是有可能有数据传输的。第三次挥手的目的是为了告诉主动方，”被动方没有数据要发了”。 所以，在第一次挥手之后，如果被动方没有数据要发给主动方。第二和第三次挥手是有可能合并传输的。这样就出现了三次挥手。 如果有数据要发，就不能是三次挥手了吗上面提到的是没有数据要发的情况，如果第二、第三次挥手之间有数据要发，就不可能变成三次挥手了吗？ 并不是。TCP中还有个特性叫延迟确认。可以简单理解为：接收方收到数据以后不需要立刻马上回复ACK确认包。 在此基础上，不是每一次发送数据包都能对应收到一个 ACK 确认包，因为接收方可以合并确认。 而这个合并确认，放在四次挥手里，可以把第二次挥手、第三次挥手，以及他们之间的数据传输都合并在一起发送。因此也就出现了三次挥手。 TCP两次挥手前面在四次挥手中提到，关闭的时候双方都发出了一个FIN和收到了一个ACK。 正常情况下TCP连接的两端，是不同IP+端口的进程。 但如果TCP连接的两端，IP+端口是一样的情况下，那么在关闭连接的时候，也同样做到了一端发出了一个FIN，也收到了一个 ACK，只不过正好这两端其实是同一个socket 。 而这种两端IP+端口都一样的连接，叫TCP自连接。 是的，你没看错，我也没打错别字。同一个socket确实可以自己连自己，形成一个连接。 一个socket能建立连接？上面提到了，同一个客户端socket，自己对自己发起连接请求。是可以成功建立连接的。这样的连接，叫TCP自连接。 下面我们尝试下复现。 注意我是在以下系统进行的实验。在mac上多半无法复现。 1234567# cat /etc/os-releaseNAME=&quot;CentOS Linux&quot;VERSION=&quot;7 (Core)&quot;ID=&quot;centos&quot;ID_LIKE=&quot;rhel fedora&quot;VERSION_ID=&quot;7&quot;PRETTY_NAME=&quot;CentOS Linux 7 (Core)&quot; 通过nc命令可以很简单的创建一个TCP自连接 1# nc -p 6666 127.0.0.1 6666 上面的 -p 可以指定源端口号。也就是指定了一个端口号为6666的客户端去连接 127.0.0.1:6666 。 12# netstat -nt | grep 6666tcp 0 0 127.0.0.1:6666 127.0.0.1:6666 ESTABLISHED 整个过程中，都没有服务端参与。可以抓个包看下。 可以看到，相同的socket，自己连自己的时候，握手是三次的。挥手是两次的。 上面这张图里，左右都是同一个客户端，把它画成两个是为了方便大家理解状态的迁移。 我们可以拿自连接的握手状态对比下正常情况下的TCP三次握手。 看了自连接的状态图，再看看下面几个问题。 一端发出第一次握手后，如果又收到了第一次握手的SYN包，TCP连接状态会怎么变化？第一次握手过后，连接状态就变成了SYN_SENT状态。如果此时又收到了第一次握手的SYN包，那么连接状态就会从SYN_SENT状态变成SYN_RCVD。 12345678910// net/ipv4/tcp_input.cstatic int tcp_rcv_synsent_state_process()&#123; // SYN_SENT状态下，收到SYN包 if (th-&gt;syn) &#123; // 状态置为 SYN_RCVD tcp_set_state(sk, TCP_SYN_RECV); &#125;&#125; 一端发出第二次握手后，如果又收到第二次握手的SYN+ACK包，TCP连接状态会怎么变化？第二握手过后，连接状态就变为SYN_RCVD了，此时如果再收到第二次握手的SYN+ACK包。连接状态会变为ESTABLISHED。 12345678910111213141516// net/ipv4/tcp_input.cint tcp_rcv_state_process()&#123; // 前面省略很多逻辑，能走到这就认为肯定有ACK if (true) &#123; // 判断下这个ack是否合法 int acceptable = tcp_ack(sk, skb, FLAG_SLOWPATH | FLAG_UPDATE_TS_RECENT) &gt; 0; switch (sk-&gt;sk_state) &#123; case TCP_SYN_RECV: if (acceptable) &#123; // 状态从 SYN_RCVD 转为 ESTABLISHED tcp_set_state(sk, TCP_ESTABLISHED); &#125; &#125; &#125;&#125; 一端第一次挥手后，又收到第一次挥手的包，TCP连接状态会怎么变化？第一次挥手过后，一端状态就会变成 FIN-WAIT-1。正常情况下，是要等待第二次挥手的ACK。但实际上却等来了 一个第一次挥手的 FIN包， 这时候连接状态就会变为CLOSING。 1234567891011// net/static void tcp_fin(struct sock *sk)&#123; switch (sk-&gt;sk_state) &#123; case TCP_FIN_WAIT1: tcp_send_ack(sk); // FIN-WAIT-1状态下，收到了FIN，转为 CLOSING tcp_set_state(sk, TCP_CLOSING); break; &#125;&#125; 这可以说是隐藏剧情了。 CLOSING 很少见，除了出现在自连接关闭外，一般还会出现在TCP两端同时关闭连接的情况下。 处于CLOSING状态下时，只要再收到一个ACK，就能进入 TIME-WAIT 状态，然后等个2MSL，连接就彻底断开了。这跟正常的四次挥手还是有些差别的。大家可以滑到文章开头的TCP四次挥手再对比下。 代码复现自连接可能大家会产生怀疑，这是不是nc这个软件本身的bug。 那我们可以尝试下用strace看看它内部都做了啥。 123456789# strace nc -p 6666 127.0.0.1 6666// ...socket(AF_INET, SOCK_STREAM, IPPROTO_TCP) = 3fcntl(3, F_GETFL) = 0x2 (flags O_RDWR)fcntl(3, F_SETFL, O_RDWR|O_NONBLOCK) = 0setsockopt(3, SOL_SOCKET, SO_REUSEADDR, [1], 4) = 0bind(3, &#123;sa_family=AF_INET, sin_port=htons(6666), sin_addr=inet_addr(&quot;0.0.0.0&quot;)&#125;, 16) = 0connect(3, &#123;sa_family=AF_INET, sin_port=htons(6666), sin_addr=inet_addr(&quot;127.0.0.1&quot;)&#125;, 16) = -1 EINPROGRESS (Operation now in progress)// ... 无非就是以创建了一个客户端socket句柄，然后对这个句柄执行 bind, 绑定它的端口号是6666，然后再向 127.0.0.1:6666发起connect方法。 我们可以尝试用C语言去复现一遍。 下面的代码，只用于复现问题。直接跳过也完全不影响阅读。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172#include &lt;stdio.h&gt;#include &lt;unistd.h&gt;#include &lt;sys/socket.h&gt;#include &lt;stdlib.h&gt;#include &lt;arpa/inet.h&gt;#include &lt;ctype.h&gt;#include &lt;string.h&gt;#include &lt;strings.h&gt; int main()&#123; int lfd, cfd; struct sockaddr_in serv_addr, clie_addr; socklen_t clie_addr_len; char buf[BUFSIZ]; int n = 0, i = 0, ret = 0 ; printf(&quot;This is a client \\n&quot;); /*Step 1: 创建客户端端socket描述符cfd*/ cfd = socket(AF_INET, SOCK_STREAM, 0); if(cfd == -1) &#123; perror(&quot;socket error&quot;); exit(1); &#125; int flag=1,len=sizeof(int); if( setsockopt(cfd, SOL_SOCKET, SO_REUSEADDR, &amp;flag, len) == -1) &#123; perror(&quot;setsockopt&quot;); exit(1); &#125; bzero(&amp;clie_addr, sizeof(clie_addr)); clie_addr.sin_family = AF_INET; clie_addr.sin_port = htons(6666); inet_pton(AF_INET,&quot;127.0.0.1&quot;, &amp;clie_addr.sin_addr.s_addr); /*Step 2: 客户端使用bind绑定客户端的IP和端口*/ ret = bind(cfd, (struct sockaddr* )&amp;clie_addr, sizeof(clie_addr)); if(ret != 0) &#123; perror(&quot;bind error&quot;); exit(2); &#125; /*Step 3: connect链接服务器端的IP和端口号*/ bzero(&amp;serv_addr, sizeof(serv_addr)); serv_addr.sin_family = AF_INET; serv_addr.sin_port = htons(6666); inet_pton(AF_INET,&quot;127.0.0.1&quot;, &amp;serv_addr.sin_addr.s_addr); ret = connect(cfd,(struct sockaddr *)&amp;serv_addr, sizeof(serv_addr)); if(ret != 0) &#123; perror(&quot;connect error&quot;); exit(3); &#125; /*Step 4: 向服务器端写数据*/ while(1) &#123; fgets(buf, sizeof(buf), stdin); write(cfd, buf, strlen(buf)); n = read(cfd, buf, sizeof(buf)); write(STDOUT_FILENO, buf, n);//写到屏幕上 &#125; /*Step 5: 关闭socket描述符*/ close(cfd); return 0;&#125; 保存为 client.c 文件，然后执行下面命令，会发现连接成功。 12# gcc client.c -o client &amp;&amp; ./clientThis is a client 12# netstat -nt | grep 6666tcp 0 0 127.0.0.1:6666 127.0.0.1:6666 ESTABLISHED 说明，这不是nc的bug。事实上，这也是内核允许的一种情况。 自连接的解决方案自连接一般不太常见，但遇到了也不难解决。 解决方案比较简单，只要能保证客户端和服务端的端口不一致就行。 事实上，我们写代码的时候一般不会去指定客户端的端口，系统会随机给客户端分配某个范围内的端口。而这个范围，可以通过下面的命令进行查询 12# cat /proc/sys/net/ipv4/ip_local_port_range32768 60999 也就是只要我们的服务器端口不在32768-60999这个范围内，比如设置为8888。就可以规避掉这个问题。 另外一个解决方案，可以参考golang标准网络库的实现，在连接建立完成之后判断下IP和端口是否一致，如果遇到自连接，则断开重试。 123456789101112131415func dialTCP(net string, laddr, raddr *TCPAddr, deadline time.Time) (*TCPConn, error) &#123; // 如果是自连接，这里会重试 for i := 0; i &lt; 2 &amp;&amp; (laddr == nil || laddr.Port == 0) &amp;&amp; (selfConnect(fd, err) || spuriousENOTAVAIL(err)); i++ &#123; if err == nil &#123; fd.Close() &#125; fd, err = internetSocket(net, laddr, raddr, deadline, syscall.SOCK_STREAM, 0, &quot;dial&quot;, sockaddrToTCP) &#125; // ...&#125;func selfConnect(fd *netFD, err error) bool &#123; // 判断是否端口、IP一致 return l.Port == r.Port &amp;&amp; l.IP.Equal(r.IP)&#125; 四次握手前面提到的TCP自连接是一个客户端自己连自己的场景。那不同客户端之间是否可以互联？ 答案是可以的，有一种情况叫TCP同时打开。 大家可以对比下，TCP同时打开在握手时的状态变化，跟TCP自连接是非常的像。 比如SYN_SENT状态下，又收到了一个SYN，其实就相当于自连接里，在发出了第一次握手后，又收到了第一次握手的请求。结果都是变成 SYN_RCVD。 在 SYN_RCVD 状态下收到了 SYN+ACK，就相当于自连接里，在发出第二次握手后，又收到第二次握手的请求，结果都是变成 ESTABLISHED。他们的源码其实都是同一块逻辑。 复现TCP同时打开分别在两个控制台下，分别执行下面两行命令。 123while true; do nc -p 2224 127.0.0.1 2223 -v;donewhile true; do nc -p 2223 127.0.0.1 2224 -v;done 上面两个命令的含义也比较简单，两个客户端互相请求连接对方的端口号，如果失败了则不停重试。 执行后看到的现象是，一开始会疯狂失败，重试。一段时间后，连接建立完成。 1234# netstat -an | grep 2223Proto Recv-Q Send-Q Local Address Foreign Address State tcp 0 0 127.0.0.1:2224 127.0.0.1:2223 ESTABLISHEDtcp 0 0 127.0.0.1:2223 127.0.0.1:2224 ESTABLISHED 期间抓包获得下面的结果。 可以看到，这里面建立连接用了四次交互。因此可以说这是通过**”四次握手”**建立的连接。 而且更重要的是，这里面只涉及两个客户端，没有服务端。 看到这里，不知道大家有没有跟我一样，被刷新了一波认知，对socket有了重新的认识。 在以前的观念里，建立连接，必须要有一个客户端和一个服务端，并且服务端还要执行一个listen()和一个accept()。而实际上，这些都不是必须的。 那么下次，面试官问你**”没有listen()， TCP能建立连接吗？”**， 我想大家应该知道该怎么回答了。 但问题又来了，只有两个客户端，没有listen() ，为什么能建立TCP连接？ 如果大家感兴趣，我们以后有机会再填上这个坑。 总结 四次挥手中，不管是程序主动执行close()，还是进程被杀，都有可能发出第一次挥手FIN包。如果机器上FIN-WAIT-2状态特别多，一般是因为对端一直不执行close()方法发出第三次挥手。 Close()会同时关闭发送和接收消息的功能。shutdown() 能单独关闭发送或接受消息。 第二、第三次挥手，是有可能合在一起的。于是四次挥手就变成三次挥手了。 同一个socket自己连自己，会产生TCP自连接，自连接的挥手是两次挥手。 没有listen，两个客户端之间也能建立连接。这种情况叫TCP同时打开，它由四次握手产生。 最后今天提到的，不管是两次挥手，还是自连接，或是TCP同时打开什么的。 咋一看，可能对日常搬砖没什么用，实际上也确实没什么用。 并且在面试上大概率也不会被问到。 毕竟一般面试官也不在意茴字有几种写法。 这篇文章的目的，主要是想从另外一个角度让大家重新认识下socket。原来TCP是可以自己连自己的，甚至两个客户端之间，不用服务端也能连起来。 这实在是，太出乎意料了。 如果文章对你有帮助，欢迎….. 算了。 兄弟们都是自家人，点不点赞，在不在看什么的，没关系的，大家看开心了就好。 在看，点赞什么的，我不是特别在意，真的，真的，别不信啊。 不三连也真的没关系的。 兄弟们不要在意啊。 我是虚伪的小白，我们下期见！ 别说了，一起在知识的海洋里呛水吧点击下方名片，关注公众号:【小白debug】 不满足于在留言区说骚话？ 加我，我们建了个划水吹牛皮群，在群里，你可以跟你下次跳槽可能遇到的同事或面试官聊点阳间的话题。就超！开！心！ 文章推荐： 程序员防猝死指南 TCP粘包 数据包：我只是犯了每个数据包都会犯的错 |硬核图解 动图图解！GMP模型里为什么要有P？背后的原因让人暖心 i/o timeout，希望你不要踩到这个net/http包的坑 妙啊! 程序猿的第一本互联网黑话指南 我感觉，我可能要拿图灵奖了。。。 给大家丢脸了，用了三年golang，我还是没答对这道内存泄漏题 硬核！漫画图解HTTP知识点+面试题 硬核图解！30张图带你搞懂！路由器，集线器，交换机，网桥，光猫有啥区别？","categories":[{"name":"图解网络","slug":"图解网络","permalink":"https://xiaobaidebug.top/categories/%E5%9B%BE%E8%A7%A3%E7%BD%91%E7%BB%9C/"}],"tags":[]},{"title":"动图图解！收到RST，就一定会断开TCP连接吗？","slug":"图解网络/动图图解！收到RST，就一定会断开TCP连接吗？","date":"2021-09-01T14:57:55.000Z","updated":"2022-10-30T02:28:13.643Z","comments":true,"path":"2021/09/01/图解网络/动图图解！收到RST，就一定会断开TCP连接吗？/","link":"","permalink":"https://xiaobaidebug.top/2021/09/01/%E5%9B%BE%E8%A7%A3%E7%BD%91%E7%BB%9C/%E5%8A%A8%E5%9B%BE%E5%9B%BE%E8%A7%A3%EF%BC%81%E6%94%B6%E5%88%B0RST%EF%BC%8C%E5%B0%B1%E4%B8%80%E5%AE%9A%E4%BC%9A%E6%96%AD%E5%BC%80TCP%E8%BF%9E%E6%8E%A5%E5%90%97%EF%BC%9F/","excerpt":"想必大家已经知道我的niao性，搞个标题，就是不喜欢立马回答。 就是要搞一大堆原理性的东西，再回答标题的问题。 说这个是因为我这次会把问题的答案就放到开头吗？ 不！ 我就不！","text":"想必大家已经知道我的niao性，搞个标题，就是不喜欢立马回答。 就是要搞一大堆原理性的东西，再回答标题的问题。 说这个是因为我这次会把问题的答案就放到开头吗？ 不！ 我就不！ 但是大家可以直接根据目录看自己感兴趣的部分。 之所以要先铺垫一些原理，还是希望大家能先看些基础的，再慢慢循序渐进，这样有利于建立知识体系。多一点上下文，少一点gap。 好了，进入正题。 下面是这篇文章的目录。 什么是RST我们都知道TCP正常情况下断开连接是用四次挥手，那是正常时候的优雅做法。 但异常情况下，收发双方都不一定正常，连挥手这件事本身都可能做不到，所以就需要一个机制去强行关闭连接。 RST 就是用于这种情况，一般用来异常地关闭一个连接。它是一个TCP包头中的标志位。 正常情况下，不管是发出，还是收到置了这个标志位的数据包，相应的内存、端口等连接资源都会被释放。从效果上来看就是TCP连接被关闭了。 而接收到 RST的一方，一般会看到一个 connection reset 或 connection refused 的报错。 怎么知道收到RST了？我们知道内核跟应用层是分开的两层，网络通信功能在内核，我们的客户端或服务端属于应用层。应用层只能通过 send/recv 与内核交互，才能感知到内核是不是收到了RST。 当本端收到远端发来的RST后，内核已经认为此链接已经关闭。 此时如果本端应用层尝试去执行 读数据操作，比如recv，应用层就会收到 Connection reset by peer 的报错，意思是远端已经关闭连接。 如果本端应用层尝试去执行写数据操作，比如send，那么应用层就会收到 Broken pipe 的报错，意思是发送通道已经坏了。 这两个是开发过程中很经常遇到的报错，感觉大家可以把这篇文章放进收藏夹吃灰了，等遇到这个问题了，再打开来擦擦灰，说不定对你会有帮助。 出现RST的场景有哪些RST一般出现于异常情况，归类为 对端的端口不可用 和 socket提前关闭。 端口不可用端口不可用分为两种情况。要么是这个端口从来就没有”可用”过，比如根本就没监听（listen）过；要么就是曾经”可用”，但现在”不可用”了，比如服务突然崩了。 端口未监听 服务端listen 方法会创建一个sock放入到全局的哈希表中。 此时客户端发起一个connect请求到服务端。服务端在收到数据包之后，第一时间会根据IP和端口从哈希表里去获取sock。 如果服务端执行过listen，就能从全局哈希表里拿到sock。 但如果服务端没有执行过listen，那哈希表里也就不会有对应的sock，结果当然是拿不到。此时，正常情况下服务端会发RST给客户端。 端口未监听就一定会发RST吗？不一定。上面提到，发RST的前提是正常情况下，我们看下源码。 123456789101112131415161718// net/ipv4/tcp_ipv4.c // 代码经过删减int tcp_v4_rcv(struct sk_buff *skb)&#123; // 根据ip、端口等信息 获取sock。 sk = __inet_lookup_skb(&amp;tcp_hashinfo, skb, th-&gt;source, th-&gt;dest); if (!sk) goto no_tcp_socket;no_tcp_socket: // 检查数据包有没有出错 if (skb-&gt;len &lt; (th-&gt;doff &lt;&lt; 2) || tcp_checksum_complete(skb)) &#123; // 错误记录 &#125; else &#123; // 发送RST tcp_v4_send_reset(NULL, skb); &#125;&#125; 内核在收到数据后会从物理层、数据链路层、网络层、传输层、应用层，一层一层往上传递。到传输层的时候，根据当前数据包的协议是TCP还是UDP走不一样的函数方法。可以简单认为，TCP数据包都会走到 tcp_v4_rcv()。 这个方法会从全局哈希表里获取 sock，如果此时服务端没有listen()过 , 那肯定获取不了sock，会跳转到no_tcp_socket的逻辑。 注意这里会先走一个 tcp_checksum_complete()，目的是看看数据包的**校验和(Checksum)**是否合法。 校验和可以验证数据从端到端的传输中是否出现异常。由发送端计算，然后由接收端验证。计算范围覆盖数据包里的TCP首部和TCP数据。 如果在发送端到接收端传输过程中，数据发生任何改动，比如被第三方篡改，那么接收方能检测到校验和有差错，此时TCP段会被直接丢弃。如果校验和没问题，那才会发RST。 所以，只有在数据包没问题的情况下，比如校验和没问题，才会发RST包给对端。 为什么数据包异常的情况下，不发RST？一个数据包连校验都不能通过，那这个包，多半有问题。 有可能是在发送的过程中被篡改了，又或者，可能只是一个胡乱伪造的数据包。 五层网络，不管是哪一层，只要遇到了这种数据，推荐的做法都是默默扔掉，而不是去回复一个消息告诉对方数据有问题。 如果对方用的是TCP，是可靠传输协议，发现很久没有ACK响应，自己就会重传。 如果对方用的是UDP，说明发送端已经接受了“不可靠会丢包”的事实，那丢了就丢了。 因此，数据包异常的情况下，默默扔掉，不发RST，非常合理。 还是不能理解？那我再举个例子。 正常人喷你，他说话条理清晰，主谓宾分明。此时你喷回去，那你是个充满热情，正直，富有判断力的好人。 而此时一个憨憨也想喷你，但他思维混乱，连话都说不清楚，一直阿巴阿巴的，你虽然听不懂，但大受震撼，此时你会？ A：跟他激情互喷 B：不跟他一般见识，就当没听过 一般来说最优选择是B，毕竟你理他，他反而来劲。 这下，应该就懂了。 程序启动了但是崩了端口不可用的场景里，除了端口未监听以外，还有可能是从前监听了，但服务端机器上做监听操作的应用程序突然崩了，此时客户端还像往常一样正常发送消息，服务器内核协议栈收到消息后，则会回一个RST。在开发过程中，这种情况是最常见的。 比如你的服务端应用程序里，弄了个空指针，或者数组越界啥的，程序立马就崩了。 这种情况跟端口未监听本质上类似，在服务端的应用程序崩溃后，原来监听的端口资源就被释放了，从效果上来看，类似于处于CLOSED状态。 此时服务端又收到了客户端发来的消息，内核协议栈会根据IP端口，从全局哈希表里查找sock，结果当然是拿不到对应的sock数据，于是走了跟上面**”端口未监听”时一样的逻辑，回了个RST。客户端在收到RST后也释放了sock资源，从效果上来看，就是连接断了**。 RST和502的关系上面这张图，服务端程序崩溃后，如果客户端再有数据发送，会出现RST。但如果在客户端和服务端中间再加一个nginx，就像下图一样。 nginx会作为客户端和服务端之间的”中间人角色”，负责转发请求和响应结果。但当服务端程序崩溃，比如出现野指针或者OOM的问题，那转发到服务器的请求，必然得不到响应，后端服务端还会返回一个RST给nginx。nginx在收到这个RST后会断开与服务端的连接，同时返回客户端一个502错误码。 所以，出现502问题，一般情况下都是因为后端程序崩了，基于这一点假设，去看看监控是不是发生了OOM或者日志是否有空指针等报错信息。 socket提前关闭这种情况分为本端提前关闭，和远端提前关闭。 本端提前关闭如果本端socket接收缓冲区还有数据未读，此时提前close() socket。那么本端会先把接收缓冲区的数据清空，然后给远端发一个RST。 远端提前关闭远端已经close()了socket，此时本端还尝试发数据给远端。那么远端就会回一个RST。 大家知道，TCP是全双工通信，意思是发送数据的同时，还可以接收数据。 Close()的含义是，此时要同时关闭发送和接收消息的功能。 客户端执行close()， 正常情况下，会发出第一次挥手FIN，然后服务端回第二次挥手ACK。如果在第二次和第三次挥手之间，如果服务方还尝试传数据给客户端，那么客户端不仅不收这个消息，还会发一个RST消息到服务端。直接结束掉这次连接。 对方没收到RST，会怎么样？我们知道TCP是可靠传输，意味着本端发一个数据，远端在收到这个数据后就会回一个ACK，意思是”我收到这个包了”。 而RST，不需要ACK确认包。 因为RST本来就是设计来处理异常情况的，既然都已经在异常情况下了，还指望对方能正常回你一个ACK吗？可以幻想，不要妄想。 但问题又来了，网络环境这么复杂，丢包也是分分钟的事情，既然RST包不需要ACK来确认，那万一对方就是没收到RST，会怎么样？ RST丢了，问题不大。比方说上图服务端，发了RST之后，服务端就认为连接不可用了。 如果客户端之前发送了数据，一直没等到这个数据的确认ACK，就会重发，重发的时候，自然就会触发一个新的RST包。 而如果客户端之前没有发数据，但服务端的RST丢了，TCP有个keepalive机制，会定期发送探活包，这种数据包到了服务端，也会重新触发一个RST。 收到RST就一定会断开连接吗?先说结论，不一定会断开。我们看下源码。 1234567891011121314151617181920// net/ipv4/tcp_input.cstatic bool tcp_validate_incoming()&#123; // 获取sock struct tcp_sock *tp = tcp_sk(sk); // step 1：先判断seq是否合法（是否在合法接收窗口范围内） if (!tcp_sequence(tp, TCP_SKB_CB(skb)-&gt;seq, TCP_SKB_CB(skb)-&gt;end_seq)) &#123; goto discard; &#125; // step 2：执行收到 RST 后该干的事情 if (th-&gt;rst) &#123; if (TCP_SKB_CB(skb)-&gt;seq == tp-&gt;rcv_nxt) tcp_reset(sk); else tcp_send_challenge_ack(sk); goto discard; &#125;&#125; 收到RST包，第一步会通过tcp_sequence先看下这个seq是否合法，其实主要是看下这个seq是否在合法接收窗口范围内。如果不在范围内，这个RST包就会被丢弃。 至于接收窗口是个啥，我们先看下面这个图。 这里黄色的部分，就是指接收窗口，只要RST包的seq不在这个窗口范围内，那就会被丢弃。 为什么要校验是否在窗口范围内正常情况下客户端服务端双方可以通过RST来断开连接。假设不做seq校验，如果这时候有不怀好意的第三方介入，构造了一个RST包，且在TCP和IP等报头都填上客户端的信息，发到服务端，那么服务端就会断开这个连接。同理也可以伪造服务端的包发给客户端。这就叫RST攻击。 受到RST攻击时，从现象上看，客户端老感觉服务端崩了，这非常影响用户体验。 如果这是个游戏，我相信多崩几次，第二天大家就不来玩了。 实际消息发送过程中，接收窗口是不断移动的，seq也是在飞快的变动中，此时第三方是比较难构造出合法seq的RST包的，那么通过这个seq校验，就可以拦下了很多不合法的消息。 加了窗口校验就不能用RST攻击了吗不是，只是增加了攻击的成本。但如果想搞，还是可搞的。 以下是面向监狱编程的环节。 希望大家只了解原理就好了，不建议使用。 相信大家都不喜欢穿着蓝白条纹的衣服，拍纯狱风的照片。 从上面可以知道，不是每一个RST包都会导致连接重置的，要求是这个RST包的seq要在窗口范围内，所以，问题就变成了，我们怎么样才能构造出合法的seq。 盲猜seq窗口数值seq本质上只是个uint32类型。 123struct tcp_skb_cb &#123; __u32 seq; /* Starting sequence number */&#125; 如果在这个范围内疯狂猜测seq数值，并构造对应的包，发到目的机器，虽然概率低，但是总是能被试出来，从而实现RST攻击。这种乱棍打死老师傅的方式，就是所谓的合法窗口盲打（blind in-window attacks）。 觉得这种方式比较笨？那有没有聪明点的方式，还真有，但是在这之前需要先看下面的这个问题。 已连接状态下收到第一次握手包会怎么样？我们需要了解一个问题，比如服务端在已连接（ESTABLISHED）状态下，如果收到客户端发来的第一次握手包（SYN），会怎么样？ 以前我以为服务单会认为客户端憨憨了，直接RST连接。 但实际，并不是。 123456789101112131415161718192021static bool tcp_validate_incoming()&#123; struct tcp_sock *tp = tcp_sk(sk); /* 判断seq是否在合法窗口内 */ if (!tcp_sequence(tp, TCP_SKB_CB(skb)-&gt;seq, TCP_SKB_CB(skb)-&gt;end_seq)) &#123; if (!th-&gt;rst) &#123; // 收到一个不在合法窗口内的SYN包 if (th-&gt;syn) goto syn_challenge; &#125; &#125; /* * RFC 5691 4.2 : 发送 challenge ack */ if (th-&gt;syn) &#123;syn_challenge: tcp_send_challenge_ack(sk); &#125;&#125; 当客户端发出一个不在合法窗口内的SYN包的时候，服务端会发一个带有正确的seq数据ACK包出来，这个ACK包叫 challenge ack。 上图是抓包的结果，用scapy随便伪造一个seq=5的包发到服务端（端口9090），服务端回复一个带有正确seq值的challenge ack包给客户端（端口8888）。 利用challenge ack获取seq上面提到的这个challenge ack ，仿佛为盲猜seq的老哥们打开了一个新世界。 在获得这个challenge ack后，攻击程序就可以以ack值为基础，在一定范围内设置seq，这样造成RST攻击的几率就大大增加了。 总结 RST其实是TCP包头里的一个标志位，目的是为了在异常情况下关闭连接。 内核收到RST后，应用层只能通过调用读/写操作来感知，此时会对应获得 Connection reset by peer 和Broken pipe 报错。 发出RST后不需要得到对方的ACK确认包，因此RST丢失后对方不能立刻感知，但是通过下一次重传数据或keepalive心跳包可以导致RST重传。 收到RST包，不一定会断开连接，seq不在合法窗口范围内的数据包会被默默丢弃。通过构造合法窗口范围内seq，可以造成RST攻击，这一点大家了解就好，千万别学！ 参考资料TCP旁路攻击分析与重现 - https://www.cxyzjd.com/article/qq_27446553/52416369 最后最近想用vscode写小说了，故事梗概都想好了。 十年前，他是大厂最年轻CTO，闭眼刷leetcode，敲代码 0 error ，0 warning， 却被诬陷删库跑路，锒铛入狱，众叛亲离……十年后，他重新归来！却看到自己的女儿在仇人公司里修bug！ “我要你付出代价！” 一声令下，十万 p7，p8 应声前来……. 爽否？ 如果文章对你有帮助，欢迎….. 算了。 兄弟们都是自家人，点不点赞，在不在看什么的，没关系的，大家看开心了就好。 在看，点赞什么的，我不是特别在意，真的，真的，别不信啊。 不三连也真的没关系的。 兄弟们不要在意啊。 我是虚伪的小白，我们下期见！ 别说了，一起在知识的海洋里呛水吧点击下方名片，关注公众号:【小白debug】 不满足于在留言区说骚话？ 加我，我们建了个划水吹牛皮群，在群里，你可以跟你下次跳槽可能遇到的同事或面试官聊点阳间的话题。就超！开！心！ 文章推荐： 程序员防猝死指南 TCP粘包 数据包：我只是犯了每个数据包都会犯的错 |硬核图解 动图图解！既然IP层会分片，为什么TCP层也还要分段？","categories":[{"name":"图解网络","slug":"图解网络","permalink":"https://xiaobaidebug.top/categories/%E5%9B%BE%E8%A7%A3%E7%BD%91%E7%BB%9C/"}],"tags":[]},{"title":"动图图解！代码执行send成功后，数据就发出去了吗？","slug":"图解网络/动图图解！代码执行send成功后，数据就发出去了吗？","date":"2021-08-10T14:57:55.000Z","updated":"2022-10-30T02:26:27.971Z","comments":true,"path":"2021/08/10/图解网络/动图图解！代码执行send成功后，数据就发出去了吗？/","link":"","permalink":"https://xiaobaidebug.top/2021/08/10/%E5%9B%BE%E8%A7%A3%E7%BD%91%E7%BB%9C/%E5%8A%A8%E5%9B%BE%E5%9B%BE%E8%A7%A3%EF%BC%81%E4%BB%A3%E7%A0%81%E6%89%A7%E8%A1%8Csend%E6%88%90%E5%8A%9F%E5%90%8E%EF%BC%8C%E6%95%B0%E6%8D%AE%E5%B0%B1%E5%8F%91%E5%87%BA%E5%8E%BB%E4%BA%86%E5%90%97%EF%BC%9F/","excerpt":"今天又是被倾盆的需求淹没的一天。 有没有人知道，那种“我用3句话，就让产品为我砍了18个需求”的鸡汤课在哪报名，想报。","text":"今天又是被倾盆的需求淹没的一天。 有没有人知道，那种“我用3句话，就让产品为我砍了18个需求”的鸡汤课在哪报名，想报。 “听懂掌声“的那种课就算了，太费手了。 扯远了，回到我们今天的正题，我们了解下这篇文的目录。 代码执行send成功后，数据就发出去了吗？ 回答这个问题之前，需要了解什么是Socket 缓冲区。 Socket 缓冲区什么是 socket 缓冲区编程的时候，如果要跟某个IP建立连接，我们需要调用操作系统提供的 socket API。 socket 在操作系统层面，可以理解为一个文件。 我们可以对这个文件进行一些方法操作。 用listen方法，可以让程序作为服务器监听其他客户端的连接。 用connect，可以作为客户端连接服务器。 用send或write可以发送数据，recv或read可以接收数据。 在建立好连接之后，这个 socket 文件就像是远端机器的 “代理人” 一样。比如，如果我们想给远端服务发点什么东西，那就只需要对这个文件执行写操作就行了。 那写到了这个文件之后，剩下的发送工作自然就是由操作系统内核来完成了。 既然是写给操作系统，那操作系统就需要提供一个地方给用户写。同理，接收消息也是一样。 这个地方就是 socket 缓冲区。 用户发送消息的时候写给 send buffer（发送缓冲区）。 用户接收消息的时候，是从 recv buffer（接收缓冲区）中读取数据。 也就是说一个socket ，会带有两个缓冲区，一个用于发送，一个用于接收。因为这是个先进先出的结构，有时候也叫它们发送、接收队列。 怎么观察 socket 缓冲区如果想要查看 socket 缓冲区，可以在linux环境下执行 netstat -nt 命令。 1234# netstat -ntActive Internet connections (w/o servers)Proto Recv-Q Send-Q Local Address Foreign Address State tcp 0 60 172.22.66.69:22 122.14.220.252:59889 ESTABLISHED 这上面表明了，这里有一个协议（Proto）类型为 TCP 的连接，同时还有本地（Local Address）和远端（Foreign Address）的IP信息，状态（State）是已连接。 还有Send-Q 是发送缓冲区，下面的数字60是指，当前还有60 Byte在发送缓冲区中未发送。而 Recv-Q 代表接收缓冲区， 此时是空的，数据都被应用进程接收干净了。 TCP部分我们在使用TCP建立连接之后，一般会使用 send 发送数据。 12345678910111213141516int main(int argc, char *argv[])&#123; // 创建socket sockfd=socket(AF_INET,SOCK_STREAM, 0)) // 建立连接 connect(sockfd, 服务器ip信息, sizeof(server)) // 执行 send 发送消息 send(sockfd,str,sizeof(str),0)) // 关闭 socket close(sockfd); return 0;&#125; 上面是一段伪代码，仅用于展示大概逻辑，我们在建立好连接后，一般会在代码中执行 send 方法。那么此时，消息就会被立刻发到对端机器吗？ 执行 send 发送的字节，会立马发送吗？答案是不确定！执行 send 之后，数据只是拷贝到了socket 缓冲区。至于什么时候会发数据，发多少数据，全听操作系统安排。 在用户进程中，程序通过操作 socket 会从用户态进入内核态，而 send方法会将数据一路传到传输层。在识别到是 TCP协议后，会调用 tcp_sendmsg 方法。 1234567891011// net/ipv4/tcp.c// 以下省略了大量逻辑int tcp_sendmsg()&#123; // 如果还有可以放数据的空间 if (skb_availroom(skb) &gt; 0) &#123; // 尝试拷贝待发送数据到发送缓冲区 err = skb_add_data_nocache(sk, skb, from, copy); &#125; // 下面是尝试发送的逻辑代码,先省略 &#125; 在 tcp_sendmsg 中， 核心工作就是将待发送的数据组织按照先后顺序放入到发送缓冲区中， 然后根据实际情况（比如拥塞窗口等）判断是否要发数据。如果不发送数据，那么此时直接返回。 如果缓冲区满了会怎么办前面提到的情况里是，发送缓冲区有足够的空间，可以用于拷贝待发送数据。 如果发送缓冲区空间不足，或者满了，执行发送，会怎么样？这里分两种情况。 首先，socket在创建的时候，是可以设置是阻塞的还是非阻塞的。 1int s = socket(AF_INET, SOCK_STREAM | SOCK_NONBLOCK, IPPROTO_TCP); 比如通过上面的代码，就可以将 socket 设置为非阻塞 （SOCK_NONBLOCK）。 当发送缓冲区满了，如果还向socket执行send 如果此时 socket 是阻塞的，那么程序会在那干等、死等，直到释放出新的缓存空间，就继续把数据拷进去，然后返回。 如果此时 socket 是非阻塞的，程序就会立刻返回一个 EAGAIN 错误信息，意思是 Try again , 现在缓冲区满了，你也别等了，待会再试一次。 我们可以简单看下源码是怎么实现的。还是回到刚才的 tcp_sendmsg 发送方法中。 12345678910int tcp_sendmsg()&#123; if (skb_availroom(skb) &gt; 0) &#123; // ..如果有足够缓冲区就执行balabla &#125; else &#123; // 如果发送缓冲区没空间了，那就等到有空间，至于等的方式，分阻塞和非阻塞 if ((err = sk_stream_wait_memory(sk, &amp;timeo)) != 0) goto do_error; &#125; &#125; 里面提到的 sk_stream_wait_memory 会根据socket是否阻塞，来决定是一直等，还是等一会就返回。 123456789101112int sk_stream_wait_memory(struct sock *sk, long *timeo_p)&#123; while (1) &#123; // 非阻塞模式时，会等到超时返回 EAGAIN if (等待超时)) return -EAGAIN; // 阻塞等待时，会等到发送缓冲区有足够的空间了，才跳出 if (sk_stream_memory_free(sk) &amp;&amp; !vm_wait) break; &#125; return err;&#125; 如果接收缓冲区为空，执行 recv 会怎么样？接收缓冲区也是类似的情况。 当接收缓冲区为空，如果还向socket执行 recv 如果此时 socket 是阻塞的，那么程序会在那干等，直到接收缓冲区有数据，就会把数据从接收缓冲区拷贝到用户缓冲区，然后返回。 如果此时 socket 是非阻塞的，程序就会立刻返回一个 EAGAIN 错误信息。 下面用一张图汇总一下，方便大家保存面试的时候用哈哈哈。 如果socket缓冲区还有数据，执行close了，会怎么样？首先我们要知道，一般正常情况下，发送缓冲区和接收缓冲区 都应该是空的。 如果发送、接收缓冲区长时间非空，说明有数据堆积，这往往是由于一些网络问题或用户应用层问题，导致数据没有正常处理。 正常情况下，如果 socket 缓冲区为空，执行 close。就会触发四次挥手。 这个也是面试老八股文内容了，这里我们只需要关注第一次挥手，发的是 FIN 就够了。 如果接收缓冲区有数据时，执行close了，会怎么样？socket close 时，主要的逻辑在 tcp_close() 里实现。 先说结论，关闭过程主要有两种情况： 如果接收缓冲区还有数据未读，会先把接收缓冲区的数据清空，然后给对端发一个RST。 如果接收缓冲区是空的，那么就调用 tcp_send_fin() 开始进行四次挥手过程的第一次挥手。 1234567891011121314151617181920void tcp_close(struct sock *sk, long timeout)&#123; // 如果接收缓冲区有数据，那么清空数据 while ((skb = __skb_dequeue(&amp;sk-&gt;sk_receive_queue)) != NULL) &#123; u32 len = TCP_SKB_CB(skb)-&gt;end_seq - TCP_SKB_CB(skb)-&gt;seq - tcp_hdr(skb)-&gt;fin; data_was_unread += len; __kfree_skb(skb); &#125; if (data_was_unread) &#123; // 如果接收缓冲区的数据被清空了，发 RST tcp_send_active_reset(sk, sk-&gt;sk_allocation); &#125; else if (tcp_close_state(sk)) &#123; // 正常四次挥手， 发 FIN tcp_send_fin(sk); &#125; // 等待关闭 sk_stream_wait_close(sk, timeout);&#125; 如果发送缓冲区有数据时，执行close了，会怎么样？以前以为，这种情况下，内核会把发送缓冲区数据清空，然后四次挥手。 但是发现源码并不是这样的。 1234567891011121314151617void tcp_send_fin(struct sock *sk)&#123; // 获得发送缓冲区的最后一块数据 struct sk_buff *skb, *tskb = tcp_write_queue_tail(sk); struct tcp_sock *tp = tcp_sk(sk); // 如果发送缓冲区还有数据 if (tskb &amp;&amp; (tcp_send_head(sk) || sk_under_memory_pressure(sk))) &#123; TCP_SKB_CB(tskb)-&gt;tcp_flags |= TCPHDR_FIN; // 把最后一块数据值为 FIN TCP_SKB_CB(tskb)-&gt;end_seq++; tp-&gt;write_seq++; &#125; else &#123; // 发送缓冲区没有数据，就造一个FIN包 &#125; // 发送数据 __tcp_push_pending_frames(sk, tcp_current_mss(sk), TCP_NAGLE_OFF);&#125; 此时，还有些数据没发出去，内核会把发送缓冲区最后一个数据块拿出来。然后置为 FIN。 socket 缓冲区是个先进先出的队列，这种情况是指，内核会等待TCP层安静地把发送缓冲区数据都发完，最后再执行 四次挥手的第一次挥手（FIN包）。 有一点需要注意的是，只有在接收缓冲区为空的前提下，我们才有可能走到 tcp_send_fin() 。而只有在进入了这个方法之后，我们才有可能考虑发送缓冲区是否为空的场景。 UDP部分UDP也有缓冲区吗说完TCP了，我们聊聊UDP。这对好基友，同时都是传输层里的重要协议。既然前面提到TCP有发送、接收缓冲区，那UDP有吗？ 以前我以为。 “每个UDP socket都有一个接收缓冲区，没有发送缓冲区，从概念上来说就是只要有数据就发，不管对方是否可以正确接收，正因为不需要缓冲数据，所以也不需要发送缓冲区。” 后来我发现我错了。 UDP socket 也是 socket，一个socket 就是会有收和发两个缓冲区。跟用什么协议关系不大。 有没有是一回事，用不用又是另外一回事。 UDP不用发送缓冲区？事实上，UDP不仅有发送缓冲区，也用发送缓冲区。 一般正常情况下，会把数据直接拷到发送缓冲区后直接发送。 还有一种情况，是在发送数据的时候，设置一个 MSG_MORE 的标记。 1ssize_t send(int sock, const void *buf, size_t len, int flags); // flag 置为 MSG_MORE 大概的意思是告诉内核，待会还有其他更多消息要一起发，先别着急发出去。此时内核就会把这份数据先用发送缓冲区缓存起来，待会应用层说ok了，再一起发。 我们可以看下源码。 12345678910111213141516int udp_sendmsg()&#123; // corkreq 为 true 表示是 MSG_MORE 的方式，仅仅组织报文，不发送； int corkreq = up-&gt;corkflag || msg-&gt;msg_flags&amp;MSG_MORE； // 将要发送的数据，按照MTU大小分割，每个片段一个skb；并且这些 // skb会放入到套接字的发送缓冲区中；该函数只是组织数据包，并不执行发送动作。 err = ip_append_data(sk, fl4, getfrag, msg-&gt;msg_iov, ulen, sizeof(struct udphdr), &amp;ipc, &amp;rt, corkreq ? msg-&gt;msg_flags|MSG_MORE : msg-&gt;msg_flags); // 没有启用 MSG_MORE 特性，那么直接将发送队列中的数据发送给IP。 if (!corkreq) err = udp_push_pending_frames(sk);&#125; 因此，不管是不是 MSG_MORE， IP都会先把数据放到发送队列中，然后根据实际情况再考虑是不是立刻发送。 而我们大部分情况下，都不会用 MSG_MORE，也就是来一个数据包就直接发一个数据包。从这个行为上来说，虽然UDP用上了发送缓冲区，但实际上并没有起到”缓冲”的作用。 最后这篇文章，我也就写了20个小时吧。画图也就画吐了而已，每天早上7点钟爬起来写一个多小时再去上班。 兄弟们都是自家人，点不点赞，在不在看什么的，没关系的，大家看开心了就好。 在看，点赞什么的，我不是特别在意，真的，真的，别不信啊。 不三连也真的没关系的。 兄弟们不要在意啊。 我是心口不一的小白，我们下期见！ 别说了，一起在知识的海洋里呛水吧点击下方名片，关注公众号:【小白debug】 文章推荐： 程序员防猝死指南 TCP粘包 数据包：我只是犯了每个数据包都会犯的错 |硬核图解 动图图解！GMP模型里为什么要有P？背后的原因让人暖心 i/o timeout，希望你不要踩到这个net/http包的坑 妙啊! 程序猿的第一本互联网黑话指南 我感觉，我可能要拿图灵奖了。。。 给大家丢脸了，用了三年golang，我还是没答对这道内存泄漏题 硬核！漫画图解HTTP知识点+面试题 硬核图解！30张图带你搞懂！路由器，集线器，交换机，网桥，光猫有啥区别？","categories":[{"name":"图解网络","slug":"图解网络","permalink":"https://xiaobaidebug.top/categories/%E5%9B%BE%E8%A7%A3%E7%BD%91%E7%BB%9C/"}],"tags":[]},{"title":"连接一个 IP 不存在的主机时，握手过程是怎样的？","slug":"图解网络/连接一个IP不存在的主机时，握手过程是怎样的","date":"2021-07-25T14:57:55.000Z","updated":"2022-10-30T02:25:54.027Z","comments":true,"path":"2021/07/25/图解网络/连接一个IP不存在的主机时，握手过程是怎样的/","link":"","permalink":"https://xiaobaidebug.top/2021/07/25/%E5%9B%BE%E8%A7%A3%E7%BD%91%E7%BB%9C/%E8%BF%9E%E6%8E%A5%E4%B8%80%E4%B8%AAIP%E4%B8%8D%E5%AD%98%E5%9C%A8%E7%9A%84%E4%B8%BB%E6%9C%BA%E6%97%B6%EF%BC%8C%E6%8F%A1%E6%89%8B%E8%BF%87%E7%A8%8B%E6%98%AF%E6%80%8E%E6%A0%B7%E7%9A%84/","excerpt":"文章持续更新，可以微信搜一搜「小白debug」第一时间阅读，回复【教程】获golang免费视频教程。本文已经收录在GitHub https://github.com/xiaobaiTech/golangFamily , 有大厂面试完整考点和成长路线，欢迎Star。 鸽了好长时间了，最近很忙。以前工作忙完，就抽空写文章。 现在忙完工作，还要一三五学驾照，二四六看家具。有同感的老铁们不要举手，拉到右下角**点个”在看”**就好了。 真的，全怪某音。","text":"文章持续更新，可以微信搜一搜「小白debug」第一时间阅读，回复【教程】获golang免费视频教程。本文已经收录在GitHub https://github.com/xiaobaiTech/golangFamily , 有大厂面试完整考点和成长路线，欢迎Star。 鸽了好长时间了，最近很忙。以前工作忙完，就抽空写文章。 现在忙完工作，还要一三五学驾照，二四六看家具。有同感的老铁们不要举手，拉到右下角**点个”在看”**就好了。 真的，全怪某音。 扯远了，回到今天的主题。 方兄最近写了篇很赞的文章 写给想去字节写 Go 的你 ，里面提到了两个问题。 连接一个 IP 不存在的主机时，握手过程是怎样的？ 连接一个 IP 地址存在但端口号不存在的主机时，握手过程又是怎样的呢？ 让我回想起曾经也被面试官也问过类似的问题，意识到应该很多朋友会对这个问题感兴趣。 所以来给大家唠唠。 这两个问题可以延伸出非常多的点。 看完了，说不定能加分！ 正常情况的握手过程是怎么样的上面提到的问题，其实是指TCP的三次握手流程。这绝对是面试八股文里的老股了。 我们简单回顾下基础知识点。 在服务端启动好后会调用 listen() 方法，进入到 LISTEN 状态，然后静静等待客户端的连接请求到来。 而此时客户端主动调用 connect(IP地址) ，就会向某个IP地址发起第一次握手，发送SYN 到目的服务器。 服务器在收到第一次握手后就会响应客户端，这是第二次握手。 客户端在收到第二次握手的消息后，响应服务的一个ACK，这算第三次握手，此时客户端 就会进入 ESTABLISHED状态，认为连接已经建立完成。 通过抓包可以直观看出三次握手的流程。 连一个 IP 不存在的主机时，握手过程是怎样的那不存在的IP，分两种，局域网内和局域网外的。 我以我家里的情况举例。 家里有一台家用路由器。本质上它的功能已经集成了我们常说的路由器，交换机和无线接入点的功能了。 其中路由器和交换机在之前写过的 《硬核图解！30张图带你搞懂！路由器，集线器，交换机，网桥，光猫有啥区别？》里已经详细介绍过了，就不再说一遍了。无线接入点基本可以认为就是个放出 wifi 信号的组件。 家用路由器下，连着我的N台设备，包括手机和电脑，他们的IP都有个共同点。都是 192.168.31.xx 形式的。其中，我的电脑的IP是192.168.31.6 ，这个可以通过 ifconfig查到。 符合这个形式的这些个设备，本质上就是通过各种设备（wifi或交换机等）接入到上图路由器的e2端口，他们共同构成一个局域网。 因此，在我家，我们可以粗暴点认为只要是 192.168.31.xx 形式的IP，就是局域网内的IP。否则就是局域网外的IP，比如 192.0.2.2 。 目的IP在局域网内因为通过 ifconfig 可以查到我的局域网内IP是192.168.31.6 ，这里盲猜末尾+1是不存在的 IP 。试了下，192.168.31.7 还真不存在。 123456789$ ping 192.168.31.7PING 192.168.31.7 (192.168.31.7): 56 data bytesRequest timeout for icmp_seq 0Request timeout for icmp_seq 1Request timeout for icmp_seq 2Request timeout for icmp_seq 3^C--- 192.168.31.7 ping statistics ---5 packets transmitted, 0 packets received, 100.0% packet loss 于是写个程序尝试连这个IP 。下面的代码是 golang 写的，大家不看代码也没关系，放出来只是方便大家自己复现的时候用的。 1234567891011121314151617181920212223242526272829303132333435363738394041424344// tcp客户端package mainimport ( &quot;fmt&quot; &quot;io&quot; &quot;net&quot; &quot;os&quot;)func main() &#123; client, err := net.Dial(&quot;tcp&quot;, &quot;192.168.31.7:8081&quot;) if err != nil &#123; fmt.Println(&quot;err:&quot;, err) return &#125; defer client.Close() go func() &#123; input := make([]byte, 1024) for &#123; n, err := os.Stdin.Read(input) if err != nil &#123; fmt.Println(&quot;input err:&quot;, err) continue &#125; client.Write([]byte(input[:n])) &#125; &#125;() buf := make([]byte, 1024) for &#123; n, err := client.Read(buf) if err != nil &#123; if err == io.EOF &#123; return &#125; fmt.Println(&quot;read err:&quot;, err) continue &#125; fmt.Println(string(buf[:n])) &#125;&#125; 然后尝试抓包。 可以发现根本没有三次握手的包，只有一些 ARP 包，在询问“谁是 192.168.31.7，告诉一下 192.168.31.6” 。 这里有三个问题 为什么会发ARP请求？ 为什么没有TCP握手包？ ARP本身是没有重试机制的，为什么ARP请求会发那么多遍？ 首先我们看下正常情况下执行connect，也就是第一次握手 的流程。 应用层执行connect过后，会通过socket层，操作系统接口，进程会从用户态进入到内核态，此时进入 传输层，因为是TCP第一次握手，会加入TCP头，且置SYN标志。 然后进入网络层，我想要连的是 192.168.31.7 ，虽然它是我瞎编的，但IP头还是得老老实实把它加进去。 此时需要重点介绍的是邻居子系统，它在网络层和数据链路层之间。可以通过ARP协议将目的IP转为对应的MAC地址，然后数据链路层就可以用这个MAC地址组装帧头。 我们看下那么ARP协议的流程是 1.先到本地ARP表查一下有没有 192.168.31.7 对应的 mac地址，有的话就返回，这里显然是不可能会有的。 可以通过 arp -a 命令查看本机的 arp表都记录了哪些信息 1234$ arp -a? (192.168.31.1) at 88:c1:97:59:d1:c3 on en0 ifscope [ethernet]? (224.0.0.251) at 1:0:4e:0:1:fb on en0 ifscope permanent [ethernet]? (239.255.255.250) at 1:0:3e:7f:ff:fb on en0 ifscope permanent [ethernet] 2.看下 192.168.31.7 跟本机IP 192.168.31.6 在不在一个局域网下。如果在的话，就在局域网内发一个 arp 广播，内容就是 前面提到的 “谁是 192.168.31.7，告诉一下 192.168.31.6”。 3.如果目的IP跟本机IP不在同一个局域网下，那么会去获取默认网关的MAC地址，这里就是指获取家用路由器的MAC地址。然后把消息发给家用路由器，让路由器发到互联网，找到下一跳路由器，一跳一跳的发送数据，直到把消息发到目的IP上，又或者找不到目的地最终被丢弃。 4.第2和第3点都是本地没有查到 ARP 缓存记录的情况，这时候会把SYN报文放进一个队列（叫unresolved_queue）里暂存起来，然后发起ARP请求；等ARP层收到ARP回应报文之后，会再从缓存中取出 SYN 报文，组装 MAC 帧头，完成刚刚没完成的发送流程。 如果经过 ARP 流程能正常返回 MAC 地址，那皆大欢喜，直接给数据链路层，经过 ring buffer 后传到网卡，发出去。 但因为现在这个IP是瞎编的，因此不可能得到目的地址 MAC ，所以消息也一直没法到数据链路层。整个流程卡在了ARP流程中。 而抓包是在数据链路层之后进行的，因此 TCP 第一次握手的包一直没能抓到，只能抓到为了获得 192.168.31.7 的MAC地址的ARP请求。 发送数据时，是在经过数据链路层之后的 dev_queue_xmit_nit 方法执行抓包操作的，这是属于网卡驱动层的方法了。 顺带一提，接收端抓包是在 __netif_receive_skb_core 方法里执行的，也属于网卡驱动层。感兴趣的朋友们可以以这个为关键词搜索相关知识点哈 此时 因为 TCP 协议是可靠的协议，对于 TCP 层来说，第一次握手的消息，已经发出去了，但是一直没有收到 ACK。也不知道消息是出去后是遇到什么事了。为了保证可靠性，它会不断重发。 而每一次重发，都会因为同样的原因（没有目的 MAC 地址）而尬在了 ARP 那个流程里。因此，才看到好几次重复的 ARP 消息。 那回到刚刚的三个问题 为什么会发 ARP 请求？ 因为目的地址是瞎编的，本地ARP表没有目的机器的MAC地址，因此发出ARP消息。 为什么没有 TCP 握手包？ 因为协议栈的数据到了网络层后，在数据链路层前，就因为没有目的MAC地址，没法发出。因此抓包软件抓不到相关数据。 为什么 ARP 请求会发那么多遍？ 因为 TCP 协议的可靠性，会重发第一次握手的消息，但每一次都因为没有目的 MAC 地址而失败，每次都会发出ARP请求。 小结连一个 IP 不存在的主机时，如果目的IP在局域网内，则第一次握手会失败，接着不断尝试重发握手的请求。同时，本机会不断发出ARP请求，企图获得目的机器的 MAC 地址。并且，因为没能获得目的 MAC 地址，这些 TCP 握手请求最终都发不出去， 目的IP在局域网外上面提到的是，目的 IP 在局域网内的情况，下面讨论目的IP在局域网外的情况。 瞎编一个不是 192.168.31.xx 形式的 IP 作为这次要用的局域网外IP， 比如 10.225.31.11。 先抓包看一下。 这次的现象是能发出 TCP 第一次握手的 SYN包。 这里有两个问题 为什么连局域网外的 IP 现象跟连局域网内不一致？ TCP 第一次握手的重试规律好像不太对？ 为什么连局域网外的IP现象跟连局域网内不一致？这个问题的答案其实在上面 ARP 的流程里已经提到过了，如果目的 IP 跟本机 IP 不在同一个局域网下，那么会去获取默认网关的 MAC 地址，这里就是指获取家用路由器的MAC地址。 此时ARP流程成功返回家用路由器的 MAC 地址，数据链路层加入帧头，消息通过网卡发到了家用路由器上。 消息会通过互联网一直传递到某个局域网为 10.225.31.xx 的路由器上，那个路由器 发出ARP 请求，询问他们局域网内的机器有没有叫 10.225.31.11的 （结果当然没有）。 最终没能发送成功，发送端也就迟迟收不到目的机的第二次握手响应。 因此触发TCP重传。 TCP第一次握手的重试规律好像不太对？在 Linux 中，第一次握手的 SYN 重传次数，是通过 tcp_syn_retries 参数控制的。可以通过下面的方式查看 12$cat /proc/sys/net/ipv4/tcp_syn_retries6 这里的含义是指 syn重传 会发生6次。 而每次重试都会间隔一定的时间，这里的间隔一般是 1s，2s，4s，8s, 16s, 32s . 而事实上，看我的截图，是先重试4次，每次都是1s，之后才是 1s，2s，4s，8s, 16s, 32s 的重试。 这跟我们知道的不太一样。 这个是因为我用的是macOS抓的包，跟linux就不是一个系统，各自的TCP协议栈在sync重传方面的实现都可能会有一定的差异。 我还听说 oppo 和 vivo 的 syn重传 是0.5s起步的。而 windows 的 syn重传 还有自己的专利。 这些冷知识大家可以不用在意。面试的时候知道linux的就够了，剩下的可以用来装逼。毕竟面试官不在意”茴”字到底有几种写法。 连IP 地址存在但端口号不存在的主机的握手过程前面提到的是IP地址压根就不存在的情况。假如IP地址存在但端口号是瞎编的呢？ 目的IP是回环地址 现象也比较简单，已经IP地址是存在的，也就是在互联网中这个机器是存在的。 那么我们可以正常发消息到目的IP，因为对应的MAC地址和IP都是正确的，所以，数据从数据链路层到网络层都很OK。 直到传输层，TCP协议在识别到这个端口号对应的进程根本不存在时，就会把数据丢弃，响应一个RST消息给发送端。 RST是什么？我们都是到TCP正常情况下断开连接是用四次挥手，那是正常时候的优雅做法。 但异常情况下，收发双方都不一定正常，连挥手这件事本身都可能做不到，所以就需要一个机制去强行关闭连接。 RST 就是用于这种情况，一般用来异常地关闭一个连接。它在TCP包头中，在收到置了这个标志位的数据包后，连接就会被关闭，此时接收到 RST的一方，一般会看到一个 connection reset 或 connection refused 的报错。 目的IP在局域网内刚刚提到我的本机IP是 192.168.31.6 ，局域网内有台 192.168.31.1 。同样尝试连一个不存在的端口。 此时现象跟前者一致。 唯一不同的是，前者是回环地址，RST数据是从本机的传输层返回的。而这次的情况，RST数据是从目的机器的传输层返回的。 目的IP在局域网外找一个存在的外网ip，这里我拿了最近刚白嫖的阿里云服务器地址 47.102.221.141 。（炫耀） 进行连接连接，发现与前面两种情况是一致的，目的机器在收到我的请求后，立马就通过 RST标志位 断开了这次的连接。 这一点跟前面两种情况一致。 熟悉小白的朋友们都知道，每次搞事情做测试，都会用 baidu.com 。 这次也不例外，ping 一下 baidu.com ,获得它的 IP: 220.181.38.148 。 123456789101112$ ping baidu.comPING baidu.com (220.181.38.148): 56 data bytes64 bytes from 220.181.38.148: icmp_seq=0 ttl=48 time=35.728 ms64 bytes from 220.181.38.148: icmp_seq=1 ttl=48 time=38.052 ms64 bytes from 220.181.38.148: icmp_seq=2 ttl=48 time=37.845 ms64 bytes from 220.181.38.148: icmp_seq=3 ttl=48 time=37.210 ms64 bytes from 220.181.38.148: icmp_seq=4 ttl=48 time=38.402 ms64 bytes from 220.181.38.148: icmp_seq=5 ttl=48 time=37.692 ms^C--- baidu.com ping statistics ---6 packets transmitted, 6 packets received, 0.0% packet lossround-trip min/avg/max/stddev = 35.728/37.488/38.402/0.866 ms 发消息到给百度域名背后的 IP，且瞎随机指定一个端口 8080， 抓包。 现象却不一致。没有 RST 。而且触发了第一次握手的重试消息。这是为什么？ 这是因为baidu的机器，作为线上生产的机器，会设置一系列安全策略，比如只对外暴露某些端口，除此之外的端口，都一律拒绝。 所以很多发到 8080端口的消息都在防火墙这一层就被拒绝掉了，根本到不了目的主机里，而RST是在目的主机的TCP/IP协议栈里发出的，都还没到这一层，就更不可能发RST了。因此发送端发现消息没有回应（因为被防火墙丢了），就会重传。所以才会出现上述抓包里的现象。 总结连一个 IP 不存在的主机时 如果IP在局域网内，会发送N次ARP请求获得目的主机的MAC地址，同时不能发出TCP握手消息。 如果IP在局域网外，会将消息通过路由器发出，但因为最终找不到目的地，触发TCP重试流程。 连IP 地址存在但端口号不存在的主机时 不管目的IP是回环地址还是局域网内外的IP地址，目的主机的传输层都会在收到握手消息后，发现端口不正确，发出RST消息断开连接。 当然如果目的机器设置了防火墙策略，限制他人将消息发到不对外暴露的端口，那么这种情况，发送端就会不断重试第一次握手。 最后留个问题，连一个 不存在的局域网外IP的主机时，我们可以看到TCP的重发规律是：开始时，每隔1s重发五次 TCP SYN消息，接着2s,4s,8s,16s,32s都重发一次； 对比连一个 不存在的局域网内IP的主机时，却是每隔1s重发了4次ARP请求，接着过了32s后才再发出一次ARP请求。已知ARP请求是没有重传机制的，它的重试就是TCP重试触发的，但两者规律不一致，是为什么？ 最后欢迎大家加我微信（公众号里右下角“联系我”），互相围观朋友圈砍一刀啥的哈哈。 如果文章对你有帮助，看下文章底部右下角，做点正能量的事情（点两下）支持一下。（**卑微疯狂暗示，拜托拜托，这对我真的很重要！**） 我是小白，我们下期见。 别说了，一起在知识的海洋里呛水吧关注公众号:【小白debug】 文章推荐： 程序员防猝死指南 TCP粘包 数据包：我只是犯了每个数据包都会犯的错 |硬核图解 动图图解！GMP模型里为什么要有P？背后的原因让人暖心 i/o timeout，希望你不要踩到这个net/http包的坑 妙啊! 程序猿的第一本互联网黑话指南 我感觉，我可能要拿图灵奖了。。。 给大家丢脸了，用了三年golang，我还是没答对这道内存泄漏题 硬核！漫画图解HTTP知识点+面试题 硬核图解！30张图带你搞懂！路由器，集线器，交换机，网桥，光猫有啥区别？","categories":[{"name":"图解网络","slug":"图解网络","permalink":"https://xiaobaidebug.top/categories/%E5%9B%BE%E8%A7%A3%E7%BD%91%E7%BB%9C/"}],"tags":[]},{"title":"硬核图解！断网了，还能ping通 127.0.0.1 吗？为什么？","slug":"图解网络/硬核图解！断网了，还能ping通回环地址吗？为什么","date":"2021-06-25T14:57:55.000Z","updated":"2022-10-30T02:25:54.028Z","comments":true,"path":"2021/06/25/图解网络/硬核图解！断网了，还能ping通回环地址吗？为什么/","link":"","permalink":"https://xiaobaidebug.top/2021/06/25/%E5%9B%BE%E8%A7%A3%E7%BD%91%E7%BB%9C/%E7%A1%AC%E6%A0%B8%E5%9B%BE%E8%A7%A3%EF%BC%81%E6%96%AD%E7%BD%91%E4%BA%86%EF%BC%8C%E8%BF%98%E8%83%BDping%E9%80%9A%E5%9B%9E%E7%8E%AF%E5%9C%B0%E5%9D%80%E5%90%97%EF%BC%9F%E4%B8%BA%E4%BB%80%E4%B9%88/","excerpt":"首发于个人公众号：小白debug原文地址：硬核图解！断网了，还能ping通 127.0.0.1 吗？为什么？ 你女神爱不爱你，你问她，她可能不会告诉你。 但网通不通，你 ping 一下就知道了。","text":"首发于个人公众号：小白debug原文地址：硬核图解！断网了，还能ping通 127.0.0.1 吗？为什么？ 你女神爱不爱你，你问她，她可能不会告诉你。 但网通不通，你 ping 一下就知道了。 可能看到标题，你就知道答案了，但是你了解背后的原因吗？那如果把 127.0.0.1 换成 0.0.0.0 或 localhost 会怎么样呢？ 你知道这几个IP有什么区别吗？ 以前面试的时候就遇到过这个问题，大家看个动图了解下面试官和我当时的场景，求当时小白的心里阴影面积。 话不多说，我们直接开车。 拔掉网线，断网。 然后在控制台输入 ping 127.0.0.1。 1234567891011$ ping 127.0.0.1PING 127.0.0.1 (127.0.0.1): 56 data bytes64 bytes from 127.0.0.1: icmp_seq=0 ttl=64 time=0.080 ms64 bytes from 127.0.0.1: icmp_seq=1 ttl=64 time=0.093 ms64 bytes from 127.0.0.1: icmp_seq=2 ttl=64 time=0.074 ms64 bytes from 127.0.0.1: icmp_seq=3 ttl=64 time=0.079 ms64 bytes from 127.0.0.1: icmp_seq=4 ttl=64 time=0.079 ms^C--- 127.0.0.1 ping statistics ---5 packets transmitted, 5 packets received, 0.0% packet lossround-trip min/avg/max/stddev = 0.074/0.081/0.093/0.006 ms 说明，拔了网线，ping 127.0.0.1 是能ping通的。 其实这篇文章看到这里，标题前半个问题已经被回答了。但是我们可以再想深一点。 为什么断网了还能 ping 通 127.0.0.1 呢？ 这能说明你不用交网费就能上网吗？ 不能。 首先我们需要进入基础科普环节。 不懂的同学看了就懂了，懂的看了就当查漏补缺吧。 什么是127.0.0.1首先，这是个 IPV4 地址。 IPV4 地址有 32 位，一个字节有 8 位，共 4 个字节。 其中127 开头的都属于回环地址，也是 IPV4 的特殊地址，没什么道理，就是人为规定的。 而127.0.0.1是众多回环地址中的一个。之所以不是 127.0.0.2 ，而是 127.0.0.1，是因为源码里就是这么定义的，也没什么道理。 12/* Address to loopback in software to local host. */#define INADDR_LOOPBACK 0x7f000001 /* 127.0.0.1 */ IPv4 的地址是 32 位的，2的32次方，大概是40+亿。地球光人口就76亿了，40亿IP这点量，塞牙缝都不够，实际上IP也确实用完了。 所以就有了IPV6， IPv6 的地址是 128 位的，大概是2的128次方≈10的38次方。据说地球的沙子数量大概是 10的23次方，所以IPV6的IP可以认为用不完。 IPV4以8位一组，每组之间用 . 号隔开。 IPV6就以16位为一组，每组之间用 : 号隔开。如果全是0，那么可以省略不写。 在IPV4下的回环地址是 127.0.0.1，在IPV6下，表达为 ::1 。中间把连续的0给省略了，之所以不是7个 冒号，而是2个冒号: ， 是因为一个 IPV6 地址中只允许出现⼀次两个连续的冒号。 多说一句： 在IPV4下用的是 ping 127.0.0.1 命令。 在IPV6下用的是 ping6 ::1 命令。 什么是 pingping 是应用层命令，可以理解为它跟游戏或者聊天软件属于同一层。只不过聊天软件可以收发消息，还能点个赞什么的，有很多复杂的功能。而 ping 作为一个小软件，它的功能比较简单，就是尝试发送一个小小的消息到目标机器上，判断目的机器是否可达，其实也就是判断目标机器网络是否能连通。 ping应用的底层，用的是网络层的ICMP协议。 虽然ICMP协议和IP协议都属于网络层协议，但其实ICMP也是利用了IP协议进行消息的传输。 所以，大家在这里完全可以简单的理解为 ping 某个IP 就是往某个IP地址发个消息。 TCP发数据和ping的区别一般情况下，我们会使用 TCP 进行网络数据传输，那么我们可以看下它和 ping 的区别。 ping和其他应用层软件都属于应用层。 那么我们横向对比一下，比方说聊天软件，如果用的是TCP的方式去发送消息。 为了发送消息，那就得先知道往哪发。linux里万物皆文件，那你要发消息的目的地，也是个文件，这里就引出了socket 的概念。 要使用 socket , 那么首先需要创建它。 在 TCP 传输中创建的方式是 socket(AF_INET, SOCK_STREAM, 0);，其中 AF_INET 表示将使用 IPV4 里 host:port 的方式去解析待会你输入的网络地址。SOCK_STREAM 是指使用面向字节流的 TCP 协议，工作在传输层。 创建好了 socket 之后，就可以愉快的把要传输的数据写到这个文件里。调用 socket 的sendto接口的过程中进程会从用户态进入到内核态，最后会调用到 sock_sendmsg 方法。 然后进入传输层，带上TCP头。网络层带上IP头，数据链路层带上 MAC头等一系列操作后。进入网卡的发送队列 ring buffer ，顺着网卡就发出去了。 回到 ping ， 整个过程也基本跟 TCP 发数据类似，差异的地方主要在于，创建 socket 的时候用的是 socket(AF_INET,SOCK_RAW,IPPROTO_ICMP)，SOCK_RAW 是原始套接字 ，工作在网络层， 所以构建ICMP（网络层协议）的数据，是再合适不过了。ping 在进入内核态后最后也是调用的 sock_sendmsg 方法，进入到网络层后加上ICMP和IP头后，数据链路层加上MAC头，也是顺着网卡发出。因此 本质上ping 跟 普通应用发消息 在程序流程上没太大差别。 这也解释了为什么当你发现怀疑网络有问题的时候，别人第一时间是问你能ping通吗？因为可以简单理解为ping就是自己组了个数据包，让系统按着其他软件发送数据的路径往外发一遍，能通的话说明其他软件发的数据也能通。 为什么断网了还能 ping 通 127.0.0.1前面提到，有网的情况下，ping 最后是通过网卡将数据发送出去的。 那么断网的情况下，网卡已经不工作了，ping 回环地址却一切正常，我们可以看下这种情况下的工作原理。 从应用层到传输层再到网络层。这段路径跟ping外网的时候是几乎是一样的。到了网络层，系统会根据目的IP，在路由表中获取对应的路由信息，而这其中就包含选择哪个网卡把消息发出。 当发现目标IP是外网IP时，会从”真网卡”发出。 当发现目标IP是回环地址时，就会选择本地网卡。 本地网卡，其实就是个**”假网卡”，它不像”真网卡”那样有个ring buffer什么的，”假网卡”会把数据推到一个叫 input_pkt_queue 的 链表 中。这个链表，其实是所有网卡共享的，上面挂着发给本机的各种消息。消息被发送到这个链表后，会再触发一个软中断**。 专门处理软中断的工具人**”ksoftirqd”** （这是个内核线程），它在收到软中断后就会立马去链表里把消息取出，然后顺着数据链路层、网络层等层层往上传递最后给到应用程序。 ping 回环地址和通过TCP等各种协议发送数据到回环地址都是走这条路径。整条路径从发到收，都没有经过”真网卡”。之所以127.0.0.1叫本地回环地址，可以理解为，消息发出到这个地址上的话，就不会出网络，在本机打个转就又回来了。所以断网，依然能 ping 通 127.0.0.1。 ping回环地址和ping本机地址有什么区别我们在mac里执行 ifconfig 。 1234567$ ifconfiglo0: flags=8049&lt;UP,LOOPBACK,RUNNING,MULTICAST&gt; mtu 16384 inet 127.0.0.1 netmask 0xff000000 ...en0: flags=8863&lt;UP,BROADCAST,SMART,RUNNING,SIMPLEX,MULTICAST&gt; mtu 1500 inet 192.168.31.6 netmask 0xffffff00 broadcast 192.168.31.255 ... 能看到 lo0，表示本地回环接口，对应的地址，就是我们前面提到的 127.0.0.1 ，也就是回环地址。 和 eth0，表示本机第一块网卡，对应的IP地址是192.168.31.6，管它叫本机IP。 之前一直认为ping本机IP的话会通过”真网卡”出去，然后遇到第一个路由器，再发回来到本机。 为了验证这个说法，可以进行抓包，但结果跟上面的说法并不相同。 可以看到 ping 本机IP 跟 ping 回环地址一样，相关的网络数据，都是走的 lo0，本地回环接口，也就是前面提到的**”假网卡”**。 只要走了本地回环接口，那数据都不会发送到网络中，在本机网络协议栈中兜一圈，就发回来了。因此 ping回环地址和ping本机地址没有区别。 127.0.0.1 和 localhost 以及 0.0.0.0 有区别吗回到文章开头动图里的提问，算是面试八股文里的老常客了。 以前第一次用 nginx 的时候，发现用这几个 IP，都能正常访问到 nginx 的欢迎网页。一度认为这几个 IP 都是一样的。 但本质上还是有些区别的。 首先 localhost 就不叫 IP，它是一个域名，就跟 &quot;baidu.com&quot;,是一个形式的东西，只不过默认会把它解析为 127.0.0.1 ，当然这可以在 /etc/hosts 文件下进行修改。 所以默认情况下，使用 localhost 跟使用 127.0.0.1 确实是没区别的。 其次就是 0.0.0.0，执行 ping 0.0.0.0 ，是会失败的，因为它在IPV4中表示的是无效的目标地址。 1234$ ping 0.0.0.0PING 0.0.0.0 (0.0.0.0): 56 data bytesping: sendto: No route to hostping: sendto: No route to host 但它还是很有用处的，回想下，我们启动服务器的时候，一般会 listen 一个 IP 和端口，等待客户端的连接。 如果此时 listen 的是本机的 0.0.0.0 , 那么它表示本机上的所有IPV4地址。 12/* Address to accept any incoming messages. */#define INADDR_ANY ((unsigned long int) 0x00000000) /* 0.0.0.0 */ 举个例子。刚刚提到的 127.0.0.1 和 192.168.31.6 ，都是本机的IPV4地址，如果监听 0.0.0.0 ，那么用上面两个地址，都能访问到这个服务器。 当然， 客户端 connect 时，不能使用 0.0.0.0 。必须指明要连接哪个服务器IP。 总结 127.0.0.1 是回环地址。localhost是域名，但默认等于 127.0.0.1。 ping 回环地址和 ping 本机地址，是一样的，走的是lo0 “假网卡”，都会经过网络层和数据链路层等逻辑，最后在快要出网卡前狠狠拐了个弯， 将数据插入到一个链表后就软中断通知 ksoftirqd 来进行收数据的逻辑，压根就不出网络。所以断网了也能 ping 通回环地址。 如果服务器 listen 的是 0.0.0.0，那么此时用127.0.0.1和本机地址都可以访问到服务。 最后最近工作上的事情太忙，本来就黑的黑眼圈，就更黑了，鸽了大家这么久实在不好意思哈。 这篇文章里，有几张大图本来都是动图，但是发现动起来之后发现字太小，点开来放大之后图又不会动了。有些影响体验，我就先改成静态图吧。 欢迎大家加我微信（公众号里右下角“联系我”），互相围观朋友圈砍一刀啥的哈哈。 如果文章对你有帮助，看下文章底部右下角，做点正能量的事情（点两下）支持一下。（疯狂暗示，拜托拜托，这对我真的很重要！） 我是小白，我们下期见。 参考资料《127.0.0.1 之本机网络通信过程知多少 ?！》—— 推荐关注飞哥的《开发内功修炼》 文章推荐： 动图图解！既然IP层会分片，为什么TCP层也还要分段？ 动图图解！GMP模型里为什么要有P？背后的原因让人暖心 i/o timeout，希望你不要踩到这个net/http包的坑 妙啊! 程序猿的第一本互联网黑话指南 程序员防猝死指南 我感觉，我可能要拿图灵奖了。。。 给大家丢脸了，用了三年golang，我还是没答对这道内存泄漏题 硬核！漫画图解HTTP知识点+面试题 TCP粘包 数据包：我只是犯了每个数据包都会犯的错 |硬核图解 硬核图解！30张图带你搞懂！路由器，集线器，交换机，网桥，光猫有啥区别？ 别说了，一起在知识的海洋里呛水吧关注公众号:【小白debug】","categories":[{"name":"图解网络","slug":"图解网络","permalink":"https://xiaobaidebug.top/categories/%E5%9B%BE%E8%A7%A3%E7%BD%91%E7%BB%9C/"}],"tags":[]},{"title":"动图图解！GMP模型里为什么要有P？背后的原因让人暖心","slug":"golang面试题/动图图解，GMP里为什么要有P","date":"2021-06-11T14:57:55.000Z","updated":"2022-10-30T02:25:54.093Z","comments":true,"path":"2021/06/11/golang面试题/动图图解，GMP里为什么要有P/","link":"","permalink":"https://xiaobaidebug.top/2021/06/11/golang%E9%9D%A2%E8%AF%95%E9%A2%98/%E5%8A%A8%E5%9B%BE%E5%9B%BE%E8%A7%A3%EF%BC%8CGMP%E9%87%8C%E4%B8%BA%E4%BB%80%E4%B9%88%E8%A6%81%E6%9C%89P/","excerpt":"文章持续更新，可以微信搜一搜「小白debug」第一时间阅读，回复【教程】获golang免费视频教程。本文已经收录在GitHub https://github.com/xiaobaiTech/golangFamily , 有大厂面试完整考点和成长路线，欢迎Star。 GM模型是什么 在 Go 1.1版本之前，其实用的就是GM模型。","text":"文章持续更新，可以微信搜一搜「小白debug」第一时间阅读，回复【教程】获golang免费视频教程。本文已经收录在GitHub https://github.com/xiaobaiTech/golangFamily , 有大厂面试完整考点和成长路线，欢迎Star。 GM模型是什么 在 Go 1.1版本之前，其实用的就是GM模型。 G，协程。通常在代码里用 go 关键字执行一个方法，那么就等于起了一个G。 M，内核线程，操作系统内核其实看不见G和P，只知道自己在执行一个线程。G和P都是在用户层上的实现。 除了G和M以外，还有一个全局协程队列，这个全局队列里放的是多个处于可运行状态的G。M如果想要获取G，就需要访问一个全局队列。同时，内核线程M是可以同时存在多个的，因此访问时还需要考虑并发安全问题。因此这个全局队列有一把全局的大锁，每次访问都需要去获取这把大锁。 并发量小的时候还好，当并发量大了，这把大锁，就成为了性能瓶颈。 GMP模型是什么 基于没有什么是加一个中间层不能解决的思路，golang在原有的GM模型的基础上加入了一个调度器P，可以简单理解为是在G和M中间加了个中间层。 于是就有了现在的GMP模型里。 P 的加入，还带来了一个本地协程队列，跟前面提到的全局队列类似，也是用于存放G，想要获取等待运行的G，会优先从本地队列里拿，访问本地队列无需加锁。而全局协程队列依然是存在的，但是功能被弱化，不到万不得已是不会去全局队列里拿G的。 GM模型里M想要运行G，直接去全局队列里拿就行了；GMP模型里，M想要运行G，就得先获取P，然后从 P 的本地队列获取 G。 新建 G 时，新G会优先加入到 P 的本地队列；如果本地队列满了，则会把本地队列中一半的 G 移动到全局队列。 P 的本地队列为空时，就从全局队列里去取。 如果全局队列为空时，M 会从其他 P 的本地队列偷（stealing）一半G放到自己 P 的本地队列。 M 运行 G，G 执行之后，M 会从 P 获取下一个 G，不断重复下去。 为什么P的逻辑不直接加在M上主要还是因为M其实是内核线程，内核只知道自己在跑线程，而golang的运行时（包括调度，垃圾回收等）其实都是用户空间里的逻辑。操作系统内核哪里还知道，也不需要知道用户空间的golang应用原来还有那么多花花肠子。这一切逻辑交给应用层自己去做就好，毕竟改内核线程的逻辑也不合适啊。 如果文章对你有帮助，看下文章底部右下角，做点正能量的事情（点两下）支持一下。（疯狂暗示，拜托拜托，这对我真的很重要！） 我是小白，我们下期见。 参考资料[1]《Golang 调度器 GMP 原理与调度全分析》 ——Aceld :https://learnku.com/articles/41728 [2]《GMP模型为什么要有P》 ——煎鱼 :https://mp.weixin.qq.com/s/an7dml9NLOhqOZjEGLdEEw [3]《深度解密Go语言之Scheduler》 ——qcrao :https://qcrao.com/2019/09/02/dive-into-go-scheduler/#%E4%BB%80%E4%B9%88%E6%98%AF-scheduler 文章推荐： i/o timeout，希望你不要踩到这个net/http包的坑 妙啊! 程序猿的第一本互联网黑话指南 程序员防猝死指南 我感觉，我可能要拿图灵奖了。。。 给大家丢脸了，用了三年golang，我还是没答对这道内存泄漏题 硬核！漫画图解HTTP知识点+面试题 TCP粘包 数据包：我只是犯了每个数据包都会犯的错 |硬核图解 硬核图解！30张图带你搞懂！路由器，集线器，交换机，网桥，光猫有啥区别？ 别说了，关注公众号:【小白debug】，一起在知识的海洋里呛水吧关注公众号:【小白debug】","categories":[{"name":"golang面试题","slug":"golang面试题","permalink":"https://xiaobaidebug.top/categories/golang%E9%9D%A2%E8%AF%95%E9%A2%98/"}],"tags":[]},{"title":"我感觉，我可能要拿图灵奖了。。。","slug":"程序人生/我感觉，我可能要拿图灵奖了。。。","date":"2021-06-10T14:57:55.000Z","updated":"2022-10-30T02:23:15.272Z","comments":true,"path":"2021/06/10/程序人生/我感觉，我可能要拿图灵奖了。。。/","link":"","permalink":"https://xiaobaidebug.top/2021/06/10/%E7%A8%8B%E5%BA%8F%E4%BA%BA%E7%94%9F/%E6%88%91%E6%84%9F%E8%A7%89%EF%BC%8C%E6%88%91%E5%8F%AF%E8%83%BD%E8%A6%81%E6%8B%BF%E5%9B%BE%E7%81%B5%E5%A5%96%E4%BA%86%E3%80%82%E3%80%82%E3%80%82/","excerpt":"是的，这个是标题党。 事情是这样的，最近在zhihu上回答了一个问题。一夜之间拿到了900+赞，让我相当震惊。","text":"是的，这个是标题党。 事情是这样的，最近在zhihu上回答了一个问题。一夜之间拿到了900+赞，让我相当震惊。 实话说，就是个抖机灵的回答。不知道是不是命中了什么推荐规则。没想到打开手机突然发现99+的信息，一时之间有些蒙圈。 打开评论，也是相当有趣哈哈哈。 在知乎划水这么久，第一次遇到这种场面，纪念下。 但说说心里话。 既开心又难过。 开心是因为能获得那么多赞，刷新一下手机就立马十多个赞，太爽太快乐了。 难过是因为之前辛辛苦苦花了好长时间写的文章，加一起点赞都不及随便抖机灵的答案。果然大家还是比较喜欢轻松快乐的东西，学习是反人性的。 那么多赞还发牢骚，这大概就是所谓的得了便宜还卖乖吧哈哈哈哈。 对，说的就是我这种情况。 一码归一码，虽然几乎没有涨粉，但能得到这么大的流量，总的来说还是很开心的。 另外想问下，有大佬知道知乎是什么样一个推荐规则吗？我还想看到99+小红点。。。 还有有什么可以从zhihu回答引流到【g】【zong】【hao】 的小技巧吗？感觉自己这个门外汉白瞎了这波流量。。。。 最近看了巨人的漫画大结局，很难受，追了8年了，以前每个月等更新，现在突然感觉生活少了点盼头。巨人的结局影响了我写文的速度，但是，下一篇已经在路上了。。。 首发于个人公众号：小白debug原文地址：https://mp.weixin.qq.com/s/rLLfj883lJbWr21wHAJTJA 文章推荐： 妙啊! 程序猿的第一本互联网黑话指南 程序员防猝死指南 给大家丢脸了，用了三年golang，我还是没答对这道内存泄漏题 硬核！漫画图解HTTP知识点+面试题 TCP粘包 数据包：我只是犯了每个数据包都会犯的错 |硬核图解 硬核图解！30张图带你搞懂！路由器，集线器，交换机，网桥，光猫有啥区别？","categories":[{"name":"骚话连篇","slug":"骚话连篇","permalink":"https://xiaobaidebug.top/categories/%E9%AA%9A%E8%AF%9D%E8%BF%9E%E7%AF%87/"}],"tags":[]},{"title":"读者提问：你听说过pip协议吗？该不该签？","slug":"程序人生/你做的这个事情，业务价值是什么？","date":"2021-05-29T14:57:55.000Z","updated":"2022-10-30T02:37:04.071Z","comments":true,"path":"2021/05/29/程序人生/你做的这个事情，业务价值是什么？/","link":"","permalink":"https://xiaobaidebug.top/2021/05/29/%E7%A8%8B%E5%BA%8F%E4%BA%BA%E7%94%9F/%E4%BD%A0%E5%81%9A%E7%9A%84%E8%BF%99%E4%B8%AA%E4%BA%8B%E6%83%85%EF%BC%8C%E4%B8%9A%E5%8A%A1%E4%BB%B7%E5%80%BC%E6%98%AF%E4%BB%80%E4%B9%88%EF%BC%9F/","excerpt":"","text":"我们先来聊聊你这大半年都做了哪些事情吧。 你做的这个事情，业务价值是什么？ 那你了解这个事情对业务的收益是什么吗？ 你了解后续业务规划是怎么样的吗？ 你对业务的规划有什么自己的想法吗？ ok，看得出来你对业务的收益和规划都比较清晰，所以你完成了这些需求，也取得了不少结果。 但这是业务需求本身的价值，你正好分到了一个容易取得结果的需求，但这是业务属性决定的，你不能说A需求业务价值比B需求更容易拿到结果，其他同事碰巧拿到了B需求，而你拿到了A需求，大家一样努力，就否定B同事的付出，对吧？ 所以我就想问你，除了业务本身的价值以外，你还为业务提供了哪些额外的价值？ 嗯嗯，这其实也是为了完成业务需求做的事情，还有其他例子可以举证的吗？ 那这些事情有落地吗？取得什么成果了吗？我比较关注有哪些结果落地了。 另外，你在这段时间里，你有没有觉得自己哪些事情做的不够好的？ 那还有其他觉得做的不好的点吗？ 我看了一下，我发现你的bug比较多。这一点你有意识到吗？ 嗯嗯，我知道，你确实没有造成过任何一次线上事故，所有的bug都是提测期间出现的。 我理解这其实是你的代码提测质量比较差？ 嗯嗯，我明白，分配给你的需求确实不少，从产出上来看确实也不错。但我们在分配活的时候，都是根据每个人的能力模型来进行分配的，我们分配给你这么多活，说明我们是认为你的能力可以cover住的。如果你觉得吃力，我觉得你应该及早提醒我们，让我们降低对你的预期和调整你的工作安排，如果你需要支持但却没有主动来沟通，我理解这是沟通能力不足的表现。 Ok，那我可以认为你是认可自己的能力可以胜任这些工作的，所以我们是拉平了这条比较的线的。所以对每一个同事其实都是公平的。但有些同事，比如xxx，就在完成了业务开发的同时，还做了xxx的事情。而你在完成需求以外，我看不到为业务和团队提供更多的价值，并且提测质量也不太理想，这一点不太符合预期。 另外，你是否了解组内其他开发目前做的事情吗？ 嗯那你了解他们做的业务会对你做的事情带来什么收益吗？ ok，看来你对整个项目组做的事情了解的并不是很全面啊，你可能需要提升一下大局观，你可以尝试一下，跳上一个台阶去看下我们下一步的规划，而不是只盯着自己在做的事情。 而且从你对自己接下来的做的事情的规划上来看，你打算深钻这个领域，这点我觉得ROI可能有点低了，这说句不好听，其实叫钻牛角尖，我觉得你如果完成手上的业务需求，可以把时间投入到组里其他项目中，去拿到更多的结果。 所以综合以上这些考虑，我这次给你的绩效是xxx，我知道这可能让你有些意外，但我这边结合上面说的事情给你列出几个点，希望能引起你的反思。balabala。我想问问你是否认可。 不不不，你不要闷着，也不需要情绪化，你如果有什么想法，完全可以说出来，我们坦诚的交流。 一个人最可贵的品质其实是他能虚心的接受他人的意见，我举一些身边的例子。balablabala。所以你现在再对齐到你自己的情况上，你是否有做到？ 没错，你确实可能做到了这些点，但是我们在招你进来的时候，我们对你有更高的期望，我希望你不仅仅只是做到上面这些点。 而且我个人也非常关注你，我发现你是个有着xxx优秀品质的人，我甚至在你身上看到了以前的自己。但是我现在重新审视过去的自己，就会发现，自己有xxx的不足，你想一下，你是不是也跟曾经的我一样，犯了这些错误？ 嗯嗯，我能走到今天这个位置，那当然说明我在这方面比你有经验，至少是个前辈。所以我希望能帮助你变得更好。我也有信心有能力能帮助到你。 我也知道你非常关注自己的技术能力成长，这起码说明你是个很上进的人，我也知道你其实是个很有想法的人，我想听听你的想法。 看来你已经意识到自己的问题了，你对自己的问题有复盘过吗？你有没有总结出什么方法论吗？是不是可以将这些事情落地为一套SOP？ 那你告诉我，接下来你将怎么做，做哪些事情，怎么样才能避免下一次还犯这样的错误？ 我给你立个标杆吧，你身边有的同事xxx，他balablabala，最后取得了balabla的结果，所以说你也应该向他一样。你希望能变成和他一样的人吗？ 好的，接下来为了让你变得更好，我会跟你一起制定一套改进方案pip (performance improve plan) ，针对你的问题和痛点，给出解决方法，并且帮助你在一定的时间内能变得更好。我其实一直很相信你的能力，我相信只要你认真执行，一定可以变得更好，如果你还能在这个过程中沉淀出一套方案论，并且将这个方法论带给身边的同事，让身边的同事也变得更好，这就是大大超出预期的成果，那下次一定能拿到好的绩效。你认可吗？ 总结以上内容，均来自于一些读者的想象，我只负责整理。并不是读者的亲身经历。完全不是。现实中也完全不可能会有这样的人。 如有雷同……不，不可能有雷同。 很多读者可能没听说过pip，它其实是一份协议，也有人说过这是认罪/劝退协议书，原则上它会规定你在一定的时间内完成某些任务，如果你签了，就相当于承认自己有问题，如果你最后未能达到要求，就会以能力不足为由被辞退。 那个人还说过：”N+1？没有的啊，你忘了你自己承认自己不能胜任工作了吗。” 当然，说这个话的人，肯定是瞎说，大家不要信。我不信，狗也不信。 就我知道的情况来看，很多工作了三五年的老哥，做了几年才发现原来他们能力不足，需要做pip计划，也不知道为啥，虽然他们表面看起来能力出色，工作也做的很好，但可能是他们都是在演戏吧。我谴责他们没有好好工作。 让你签pip的人怎么可能只是想找个理由裁员呢，他当然只是希望你变得更好而已。请大家不要恶意揣测任何人。 但不得不说，从对话里你可以看出，这里面其实涉及到非常多的谈判技巧，既有推也有拉，俗称打一巴掌给颗糖，再打巴掌再给糖。你能在里面看到几个这样的小技巧？你又能在这样的对话下抗住几个回合？ 如果你还遇到过什么有意思的犬话，我们评论区见啊。 如果你遇到了pip，那你加我微信，我有一个不成熟的小建议。 最后我本是某科技公司ceo权力被架空股份被清空现在我只想夺回我的公司现在只差一个 你的点赞和在看我就能东山再起点击关注《小白debug》 ，我有一套详细的复仇计划等待实施 别说了，一起在知识的海洋里呛水吧点击下方名片，关注公众号:【小白debug】 文章推荐： 程序员防猝死指南 TCP粘包 数据包：我只是犯了每个数据包都会犯的错 |硬核图解 动图图解！既然IP层会分片，为什么TCP层也还要分段？","categories":[{"name":"骚话连篇","slug":"骚话连篇","permalink":"https://xiaobaidebug.top/categories/%E9%AA%9A%E8%AF%9D%E8%BF%9E%E7%AF%87/"}],"tags":[]},{"title":"动图图解！既然IP层会分片，为什么TCP层也还要分段？","slug":"图解网络/动图图解！既然IP层会分片，为什么TCP层也还要分段？","date":"2021-05-25T14:57:55.000Z","updated":"2022-10-30T02:25:54.111Z","comments":true,"path":"2021/05/25/图解网络/动图图解！既然IP层会分片，为什么TCP层也还要分段？/","link":"","permalink":"https://xiaobaidebug.top/2021/05/25/%E5%9B%BE%E8%A7%A3%E7%BD%91%E7%BB%9C/%E5%8A%A8%E5%9B%BE%E5%9B%BE%E8%A7%A3%EF%BC%81%E6%97%A2%E7%84%B6IP%E5%B1%82%E4%BC%9A%E5%88%86%E7%89%87%EF%BC%8C%E4%B8%BA%E4%BB%80%E4%B9%88TCP%E5%B1%82%E4%B9%9F%E8%BF%98%E8%A6%81%E5%88%86%E6%AE%B5%EF%BC%9F/","excerpt":"什么是TCP分段和IP分片我们知道网络就像一根管子，而管子吧，就会有粗细。 一个数据包想从管子的一端到另一端，得过这个管子。（废话） 但数据包的量有大有小，想过管子，数据包不能大于这根管子的粗细。 问题来了，数据包过大时怎么办？","text":"什么是TCP分段和IP分片我们知道网络就像一根管子，而管子吧，就会有粗细。 一个数据包想从管子的一端到另一端，得过这个管子。（废话） 但数据包的量有大有小，想过管子，数据包不能大于这根管子的粗细。 问题来了，数据包过大时怎么办？ 答案比较简单。会把数据包切分小块。这样数据就可以由大变小，顺利传输。 回去看下网络分层协议，数据先过传输层，再到网络层。 这个行为在传输层和网络层都有可能发生。 在传输层（TCP协议）里，叫分段。 在网络层（IP层），叫分片。（注意以下提到的IP没有特殊说明的情况下，都是指IPV4） 那么不管是分片还是分段，肯定需要按照一定的长度切分。 在TCP里，这个长度是MSS。 在IP层里，这个长度是MTU。 那MSS和MTU是什么关系呢？这个在之前的文章里简单提到过。这里单独拿出来。 MSS是什么MSS：Maximum Segment Size 。 TCP 提交给 IP 层最大分段大小，不包含 TCP Header 和 TCP Option，只包含 TCP Payload ，MSS 是 TCP 用来限制应用层最大的发送字节数。假设 MTU= 1500 byte，那么 MSS = 1500- 20(IP Header) -20 (TCP Header) = 1460 byte，如果应用层有 2000 byte 发送，那么需要两个切片才可以完成发送，第一个 TCP 切片 = 1460，第二个 TCP 切片 = 540。 如何查看MSS？我们都知道TCP三次握手，而MSS会在三次握手的过程中传递给对方，用于通知对端本地最大可以接收的TCP报文数据大小（不包含TCP和IP报文首部）。 比如上图中，B将自己的MSS发送给A，建议A在发数据给B的时候，采用MSS=1420进行分段。而B在发数据给A的时候，同样会带上MSS=1372。两者在对比后，会采用小的那个值（1372）作为通信的MSS值，这个过程叫MSS协商。 另外，一般情况下MSS + 20（TCP头）+ 20（IP头）= MTU，上面抓包的图里对应的MTU分别是1372+40 和 1420+40。 同一个路径上，MTU不一定是对称的，也就是说A到B和B到A，两条路径上的MTU可以是不同的，对应的MSS也一样。 三次握手中协商了MSS就不会改变了吗？当然不是，每次执行TCP发送消息的函数时，会重新计算一次MSS，再进行分段操作。 对端不传MSS会怎么样？我们再看TCP的报头。 其实MSS是作为可选项引入的，只不过一般情况下MSS都会传，但是万一遇到了哪台机器的实现上比较调皮，不传MSS这个可选项。那对端该怎么办？ 如果没有接收到对端TCP的MSS，本端TCP默认采用MSS=536Byte。 那为什么会是536？ 1536（data） + 20（tcp头）+20（ip头）= 576Byte 前面提到了IP会切片，那会切片，也就会重组，而这个576正好是 IP 最小重组缓冲区的大小。 MTU是什么MTU: Maximum Transmit Unit，最大传输单元。 其实这个是由数据链路层提供，为了告诉上层IP层，自己的传输能力是多大。IP层就会根据它进行数据包切分。一般 MTU=1500 Byte。假设IP层有 &lt;= 1500 byte 需要发送，只需要一个 IP 包就可以完成发送任务；假设 IP 层有 &gt; 1500 byte 数据需要发送，需要分片才能完成发送，分片后的 IP Header ID 相同，同时为了分片后能在接收端把切片组装起来，还需要在分片后的IP包里加上各种信息。比如这个分片在原来的IP包里的偏移offset。 如何查看MTU在mac控制台输入 ifconfig命令，可以看到MTU的值为多大。 1234567$ ipconfiglo0: flags=8049&lt;UP,LOOPBACK,RUNNING,MULTICAST&gt; mtu 16384 ...en0: flags=8863&lt;UP,BROADCAST,SMART,RUNNING,SIMPLEX,MULTICAST&gt; mtu 1500 ...p2p0: flags=8843&lt;UP,BROADCAST,RUNNING,SIMPLEX,MULTICAST&gt; mtu 2304 ... 可以看到这上面有好几个MTU，可以简单理解为每个网卡的处理能力不同，所以对应的MTU也不同。当然这个值是可以修改的，但不在今天的讨论范畴内，不再展开。 在一台机器的应用层到这台机器的网卡，这条链路上，基本上可以保证，MSS &lt; MTU。 为什么MTU一般是1500这其实是由传输效率决定的。首先，虽然我们平时用的网络感觉挺稳定的，但其实这是因为TCP在背地里做了各种重传等保证了传输的可靠，其实背地里线路是动不动就丢包的，而越大的包，发生丢包的概率就越大。 那是不是包越小就越好？也不是 但是如果选择一个比较小的长度，假设选择MTU为300Byte，TCP payload = 300 - IP Header - TCP Header = 300 - 20 - 20 = 260 byte。那有效传输效率= 260 / 300 = 86% 而如果以太网长度为1500，那有效传输效率= 1460 / 1500 = 96% ，显然比 86% 高多了。 所以，包越小越不容易丢包，包越大，传输效率又越高，因此权衡之下，选了1500。 为什么IP层会分片，TCP还要分段由于本身IP层就会做分片这件事情。就算TCP不分段，到了IP层，数据包也会被分片，数据也能正常传输。 既然网络层就会分片了，那么TCP为什么还要分段？是不是有些多此一举？ 假设有一份数据，较大，且在TCP层不分段，如果这份数据在发送的过程中出现丢包现象，TCP会发生重传，那么重传的就是这一大份数据（虽然IP层会把数据切分为MTU长度的N多个小包，但是TCP重传的单位却是那一大份数据）。 如果TCP把这份数据，分段为N个小于等于MSS长度的数据包，到了IP层后加上IP头和TCP头，还是小于MTU，那么IP层也不会再进行分包。此时在传输路上发生了丢包，那么TCP重传的时候也只是重传那一小部分的MSS段。效率会比TCP不分段时更高。 类似的，传输层除了TCP外，还有UDP协议，但UDP本身不会分段，所以当数据量较大时，只能交给IP层去分片，然后传到底层进行发送。 也就是说，正常情况下，在一台机器的传输层到网络层这条链路上，如果传输层对数据做了分段，那么IP层就不会再分片。如果传输层没分段，那么IP层就可能会进行分片。 说白了，数据在TCP分段，就是为了在IP层不需要分片，同时发生重传的时候只重传分段后的小份数据。 TCP分段了，IP层就一定不会分片了吗上面提到了，在发送端，TCP分段后，IP层就不会再分片了。 但是整个传输链路中，可能还会有其他网络层设备，而这些设备的MTU可能小于发送端的MTU。此时虽然数据包在发送端已经分段过了，但是在IP层就还会再分片一次。 如果链路上还有设备有更小的MTU，那么还会再分片，最后所有的分片都会在接收端处进行组装。 因此，就算TCP分段过后，在链路上的其他节点的IP层也是有可能再分片的，而且哪怕数据被第一次IP分片过了，也是有可能被其他机器的IP层进行二次、三次、四次….分片的。 IP层怎么做到不分片上面提到的IP层在传输过程中因为各个节点间MTU可能不同，导致数据是可能被多次分片的。而且每次分片都要加上各种信息便于在接收端进行分片重组。那么IP层是否可以做到不分片？ 如果有办法知道整个链路上，最小的MTU是多少，并且以最小MTU长度发送数据，那么不管数据传到哪个节点，都不会发生分片。 整个链路上，最小的MTU，就叫PMTU（path MTU）。 有一个获得这个PMTU的方法，叫 Path MTU Discovery。 12$cat /proc/sys/net/ipv4/ip_no_pmtu_disc0 默认为0，意思是开启PMTU发现的功能。现在一般机器上都是开启的状态。 原理比较简单，首先我们先回去看下IP的数据报头。 这里有个标红的标志位DF（Don’t Fragment），当它置为1，意味着这个IP报文不分片。 当链路上某个路由器，收到了这个报文，当IP报文长度大于路由器的MTU时，路由器会看下这个IP报文的DF 如果为0（允许分片），就会分片并把分片后的数据传到下一个路由器 如果为1，就会把数据丢弃，同时返回一个ICMP包给发送端，并告诉它 “达咩!” 数据不可达，需要分片，同时带上当前机器的MTU 理解了上面的原理后，我们再看下PMTU发现是怎么实现的。 应用通过TCP正常发送消息，传输层TCP分段后，到网络层加上IP头，DF置为1，消息再到更底层执行发送 此时链路上有台路由器由于各种原因MTU变小了 IP消息到这台路由器了，路由器发现消息长度大于自己的MTU，且消息自带DF不让分片。就把消息丢弃。同时返回一个ICMP错误给发送端，同时带上自己的MTU。 发送端收到这个ICMP消息，会更新自己的MTU，同时记录到一个PMTU表中。 因为TCP的可靠性，会尝试重传这个消息，同时以这个新MTU值计算出MSS进行分段，此时新的IP包就可以顺利被刚才的路由器转发。 如果路径上还有更小的MTU的路由器，那上面发生的事情还会再发生一次。 总结 数据在TCP分段，在IP层就不需要分片，同时发生重传的时候只重传分段后的小份数据 TCP分段时使用MSS，IP分片时使用MTU MSS是通过MTU计算得到，在三次握手和发送消息时都有可能产生变化。 IP分片是不得已的行为，尽量不在IP层分片，尤其是链路上中间设备的IP分片。因此，在IPv6中已经禁止中间节点设备对IP报文进行分片，分片只能在链路的最开头和最末尾两端进行。 建立连接后，路径上节点的MTU值改变时，可以通过PMTU发现更新发送端MTU的值。这种情况下，PMTU发现通过浪费N次发送机会来换取的PMTU，TCP因为有重传可以保证可靠性，在UDP就相当于消息直接丢了。 文章推荐： 动图图解！GMP模型里为什么要有P？背后的原因让人暖心 i/o timeout，希望你不要踩到这个net/http包的坑 妙啊! 程序猿的第一本互联网黑话指南 程序员防猝死指南 我感觉，我可能要拿图灵奖了。。。 给大家丢脸了，用了三年golang，我还是没答对这道内存泄漏题 硬核！漫画图解HTTP知识点+面试题 TCP粘包 数据包：我只是犯了每个数据包都会犯的错 |硬核图解 硬核图解！30张图带你搞懂！路由器，集线器，交换机，网桥，光猫有啥区别？ 最后画动图，太难了。。。看完求个赞，下次图会动得更凶。 欢迎大家加我微信（公众号里右下角“联系我”），互相围观朋友圈砍一刀啥的哈哈。 如果文章对你有帮助，看下文章底部右下角，做点正能量的事情（点两下）支持一下。（疯狂暗示，拜托拜托，这对我真的很重要！） 我是小白，我们下期见。 别说了，一起在知识的海洋里呛水吧关注公众号:【小白debug】","categories":[{"name":"图解网络","slug":"图解网络","permalink":"https://xiaobaidebug.top/categories/%E5%9B%BE%E8%A7%A3%E7%BD%91%E7%BB%9C/"}],"tags":[]},{"title":"i/o timeout ， 希望你不要踩到这个net/http包的坑","slug":"golang面试题/io_timeout，希望你不要踩到这个http包的坑","date":"2021-05-18T14:57:55.000Z","updated":"2022-10-30T02:25:54.071Z","comments":true,"path":"2021/05/18/golang面试题/io_timeout，希望你不要踩到这个http包的坑/","link":"","permalink":"https://xiaobaidebug.top/2021/05/18/golang%E9%9D%A2%E8%AF%95%E9%A2%98/io_timeout%EF%BC%8C%E5%B8%8C%E6%9C%9B%E4%BD%A0%E4%B8%8D%E8%A6%81%E8%B8%A9%E5%88%B0%E8%BF%99%E4%B8%AAhttp%E5%8C%85%E7%9A%84%E5%9D%91/","excerpt":"文章持续更新，可以微信搜一搜「小白debug」第一时间阅读，回复【教程】获golang免费视频教程。本文已经收录在GitHub https://github.com/xiaobaiTech/golangFamily , 有大厂面试完整考点和成长路线，欢迎Star。 问题我们来看一段日常代码。","text":"文章持续更新，可以微信搜一搜「小白debug」第一时间阅读，回复【教程】获golang免费视频教程。本文已经收录在GitHub https://github.com/xiaobaiTech/golangFamily , 有大厂面试完整考点和成长路线，欢迎Star。 问题我们来看一段日常代码。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869package mainimport ( &quot;bytes&quot; &quot;encoding/json&quot; &quot;fmt&quot; &quot;io/ioutil&quot; &quot;net&quot; &quot;net/http&quot; &quot;time&quot;)var tr *http.Transportfunc init() &#123; tr = &amp;http.Transport&#123; MaxIdleConns: 100, Dial: func(netw, addr string) (net.Conn, error) &#123; conn, err := net.DialTimeout(netw, addr, time.Second*2) //设置建立连接超时 if err != nil &#123; return nil, err &#125; err = conn.SetDeadline(time.Now().Add(time.Second * 3)) //设置发送接受数据超时 if err != nil &#123; return nil, err &#125; return conn, nil &#125;, &#125;&#125;func main() &#123; for &#123; _, err := Get(&quot;http://www.baidu.com/&quot;) if err != nil &#123; fmt.Println(err) break &#125; &#125;&#125;func Get(url string) ([]byte, error) &#123; m := make(map[string]interface&#123;&#125;) data, err := json.Marshal(m) if err != nil &#123; return nil, err &#125; body := bytes.NewReader(data) req, _ := http.NewRequest(&quot;Get&quot;, url, body) req.Header.Add(&quot;content-type&quot;, &quot;application/json&quot;) client := &amp;http.Client&#123; Transport: tr, &#125; res, err := client.Do(req) if res != nil &#123; defer res.Body.Close() &#125; if err != nil &#123; return nil, err &#125; resBody, err := ioutil.ReadAll(res.Body) if err != nil &#123; return nil, err &#125; return resBody, nil&#125; 做的事情，比较简单，就是循环去请求 http://www.baidu.com/ , 然后等待响应。 看上去貌似没啥问题吧。 代码跑起来，也确实能正常收发消息。 但是这段代码跑一段时间，就会出现 i/o timeout 的报错。 这其实是最近排查了的一个问题，发现这个坑可能比较容易踩上，我这边对代码做了简化。 实际生产中发生的现象是，golang服务在发起http调用时，虽然http.Transport设置了3s超时，会偶发出现i/o timeout的报错。 但是查看下游服务的时候，发现下游服务其实 100ms 就已经返回了。 排查 就很奇怪了，明明服务端显示处理耗时才100ms，且客户端超时设的是3s, 怎么就出现超时报错 i/o timeout 呢？ 这里推测有两个可能。 因为服务端打印的日志其实只是服务端应用层打印的日志。但客户端应用层发出数据后，中间还经过客户端的传输层，网络层，数据链路层和物理层，再经过服务端的物理层，数据链路层，网络层，传输层到服务端的应用层。服务端应用层处耗时100ms，再原路返回。那剩下的3s-100ms可能是耗在了整个流程里的各个层上。比如网络不好的情况下，传输层TCP使劲丢包重传之类的原因。 网络没问题，客户端到服务端链路整个收发流程大概耗时就是100ms左右。客户端处理逻辑问题导致超时。 一般遇到问题，大部分情况下都不会是底层网络的问题，大胆怀疑是自己的问题就对了，不死心就抓个包看下。 分析下，从刚开始三次握手（画了红框的地方）。 到最后出现超时报错 i/o timeout （画了蓝框的地方）。 从time那一列从7到10，确实间隔3s。而且看右下角的蓝框，是51169端口发到80端口的一次Reset连接。 80端口是服务端的端口。换句话说就是客户端3s超时主动断开链接的。 但是再仔细看下第一行三次握手到最后客户端超时主动断开连接的中间，其实有非常多次HTTP请求。 回去看代码设置超时的方式。 1234567891011121314tr = &amp;http.Transport&#123; MaxIdleConns: 100, Dial: func(netw, addr string) (net.Conn, error) &#123; conn, err := net.DialTimeout(netw, addr, time.Second*2) //设置建立连接超时 if err != nil &#123; return nil, err &#125; err = conn.SetDeadline(time.Now().Add(time.Second * 3)) //设置发送接受数据超时 if err != nil &#123; return nil, err &#125; return conn, nil &#125;,&#125; 也就是说，这里的3s超时，其实是在建立连接之后开始算的，而不是单次调用开始算的超时。 看注释里写的是 SetDeadline sets the read and write deadlines associated with the connection. 超时原因大家知道HTTP是应用层协议，传输层用的是TCP协议。 HTTP协议从1.0以前，默认用的是短连接，每次发起请求都会建立TCP连接。收发数据。然后断开连接。 TCP连接每次都是三次握手。每次断开都要四次挥手。 其实没必要每次都建立新连接，建立的连接不断开就好了，每次发送数据都复用就好了。 于是乎，HTTP协议从1.1之后就默认使用长连接。具体相关信息可以看之前的 这篇文章。 那么golang标准库里也兼容这种实现。 通过建立一个连接池，针对每个域名建立一个TCP长连接，比如http://baidu.com和http://golang.com 就是两个不同的域名。 第一次访问http://baidu.com 域名的时候会建立一个连接，用完之后放到空闲连接池里，下次再要访问http://baidu.com 的时候会重新从连接池里把这个连接捞出来复用。 插个题外话：这也解释了之前这篇文章里最后的疑问，为什么要强调是同一个域名：一个域名会建立一个连接，一个连接对应一个读goroutine和一个写goroutine。正因为是同一个域名，所以最后才会泄漏3个goroutine，如果不同域名的话，那就会泄漏 1+2*N 个协程，N就是域名数。 假设第一次请求要100ms，每次请求完http://baidu.com 后都放入连接池中，下次继续复用，重复29次，耗时2900ms。 第30次请求的时候，连接从建立开始到服务返回前就已经用了3000ms，刚好到设置的3s超时阈值，那么此时客户端就会报超时 i/o timeout 。 虽然这时候服务端其实才花了100ms，但耐不住前面29次加起来的耗时已经很长。 也就是说只要通过 http.Transport 设置了 err = conn.SetDeadline(time.Now().Add(time.Second * 3)) ，并且你用了长连接，哪怕服务端处理再快，客户端设置的超时再长，总有一刻，你的程序会报超时错误。 正确姿势原本预期是给每次调用设置一个超时，而不是给整个连接设置超时。 另外，上面出现问题的原因是给长连接设置了超时，且长连接会复用。 基于这两点，改一下代码。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970package mainimport ( &quot;bytes&quot; &quot;encoding/json&quot; &quot;fmt&quot; &quot;io/ioutil&quot; &quot;net/http&quot; &quot;time&quot;)var tr *http.Transportfunc init() &#123; tr = &amp;http.Transport&#123; MaxIdleConns: 100, // 下面的代码被干掉了 //Dial: func(netw, addr string) (net.Conn, error) &#123; // conn, err := net.DialTimeout(netw, addr, time.Second*2) //设置建立连接超时 // if err != nil &#123; // return nil, err // &#125; // err = conn.SetDeadline(time.Now().Add(time.Second * 3)) //设置发送接受数据超时 // if err != nil &#123; // return nil, err // &#125; // return conn, nil //&#125;, &#125;&#125;func Get(url string) ([]byte, error) &#123; m := make(map[string]interface&#123;&#125;) data, err := json.Marshal(m) if err != nil &#123; return nil, err &#125; body := bytes.NewReader(data) req, _ := http.NewRequest(&quot;Get&quot;, url, body) req.Header.Add(&quot;content-type&quot;, &quot;application/json&quot;) client := &amp;http.Client&#123; Transport: tr, Timeout: 3*time.Second, // 超时加在这里，是每次调用的超时 &#125; res, err := client.Do(req) if res != nil &#123; defer res.Body.Close() &#125; if err != nil &#123; return nil, err &#125; resBody, err := ioutil.ReadAll(res.Body) if err != nil &#123; return nil, err &#125; return resBody, nil&#125;func main() &#123; for &#123; _, err := Get(&quot;http://www.baidu.com/&quot;) if err != nil &#123; fmt.Println(err) break &#125; &#125;&#125; 看注释会发现，改动的点有两个 http.Transport里的建立连接时的一些超时设置干掉了。 在发起http请求的时候会场景http.Client，此时加入超时设置，这里的超时就可以理解为单次请求的超时了。同样可以看下注释 Timeout specifies a time limit for requests made by this Client. 到这里，代码就改好了，实际生产中问题也就解决了。 实例代码里，如果拿去跑的话，其实还会下面的错 1Get http://www.baidu.com/: EOF 这个是因为调用得太猛了，http://www.baidu.com 那边主动断开的连接，可以理解为一个限流措施，目的是为了保护服务器，毕竟每个人都像这么搞，服务器是会炸的。。。 解决方案很简单，每次HTTP调用中间加个sleep间隔时间就好。 到这里，其实问题已经解决了，下面会在源码层面分析出现问题的原因。对读源码不感兴趣的朋友们可以不用接着往下看，直接拉到文章底部右下角，做点正能量的事情（点两下）支持一下。（疯狂暗示，拜托拜托，这对我真的很重要！） 源码分析用的go版本是1.12.7。 从发起一个网络请求开始跟。 123456789101112131415161718192021222324252627282930313233343536373839404142res, err := client.Do(req)func (c *Client) Do(req *Request) (*Response, error) &#123; return c.do(req)&#125;func (c *Client) do(req *Request) &#123; // ... if resp, didTimeout, err = c.send(req, deadline); err != nil &#123; // ... &#125; // ... &#125; func send(ireq *Request, rt RoundTripper, deadline time.Time) &#123; // ... resp, err = rt.RoundTrip(req) // ... &#125; // 从这里进入 RoundTrip 逻辑/src/net/http/roundtrip.go: 16func (t *Transport) RoundTrip(req *Request) (*Response, error) &#123; return t.roundTrip(req)&#125;func (t *Transport) roundTrip(req *Request) (*Response, error) &#123; // 尝试去获取一个空闲连接，用于发起 http 连接 pconn, err := t.getConn(treq, cm) // ...&#125;// 重点关注这个函数，返回是一个长连接func (t *Transport) getConn(treq *transportRequest, cm connectMethod) (*persistConn, error) &#123; // 省略了大量逻辑，只关注下面两点 // 有空闲连接就返回 pc := &lt;-t.getIdleConnCh(cm) // 没有创建连接 pc, err := t.dialConn(ctx, cm) &#125; 这里上面很多代码，其实只是为了展示这部分代码是怎么跟踪下来的，方便大家去看源码的时候去跟一下。 最后一个上面的代码里有个 getConn 方法。在发起网络请求的时候，会先取一个网络连接，取连接有两个来源。 如果有空闲连接，就拿空闲连接 1234567/src/net/http/tansport.go:810func (t *Transport) getIdleConnCh(cm connectMethod) chan *persistConn &#123; // 返回放空闲连接的chan ch, ok := t.idleConnCh[key] // ... return ch&#125; 没有空闲连接，就创建长连接。 123456789/src/net/http/tansport.go:1357func (t *Transport) dialConn() &#123; //... conn, err := t.dial(ctx, &quot;tcp&quot;, cm.addr()) // ... go pconn.readLoop() go pconn.writeLoop() // ...&#125; 当第一次发起一个http请求时，这时候肯定没有空闲连接，会建立一个新连接。同时会创建一个读goroutine和一个写goroutine。 注意上面代码里的t.dial(ctx, &quot;tcp&quot;, cm.addr())，如果像文章开头那样设置了 http.Transport的 1234567891011Dial: func(netw, addr string) (net.Conn, error) &#123; conn, err := net.DialTimeout(netw, addr, time.Second*2) //设置建立连接超时 if err != nil &#123; return nil, err &#125; err = conn.SetDeadline(time.Now().Add(time.Second * 3)) //设置发送接受数据超时 if err != nil &#123; return nil, err &#125; return conn, nil&#125;, 那么这里就会在下面的dial里被执行到 12345func (t *Transport) dial(ctx context.Context, network, addr string) (net.Conn, error) &#123; // ... c, err := t.Dial(network, addr) // ...&#125; 这里面调用的设置超时，会执行到 123456789101112131415161718192021222324/src/net/net.gofunc (c *conn) SetDeadline(t time.Time) error &#123; //... c.fd.SetDeadline(t) //...&#125;//...func setDeadlineImpl(fd *FD, t time.Time, mode int) error &#123; // ... runtime_pollSetDeadline(fd.pd.runtimeCtx, d, mode) return nil&#125;//go:linkname poll_runtime_pollSetDeadline internal/poll.runtime_pollSetDeadlinefunc poll_runtime_pollSetDeadline(pd *pollDesc, d int64, mode int) &#123; // ... // 设置一个定时器事件 rtf = netpollDeadline // 并将事件注册到定时器里 modtimer(&amp;pd.rt, pd.rd, 0, rtf, pd, pd.rseq)&#125; 上面的源码，简单来说就是，当第一次调用请求的，会建立个连接，这时候还会注册一个定时器事件，假设时间设了3s，那么这个事件会在3s后发生，然后执行注册事件的逻辑。而这个注册事件就是netpollDeadline。 注意这个netpollDeadline，待会会提到。 设置了超时事件，且超时事件是3s后之后，发生。再次期间正常收发数据。一切如常。 直到3s过后，这时候看读goroutine，会等待网络数据返回。 1234567/src/net/http/tansport.go:1642func (pc *persistConn) readLoop() &#123; //... for alive &#123; _, err := pc.br.Peek(1) // 阻塞读取服务端返回的数据 //...&#125; 然后就是一直跟代码。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051src/bufio/bufio.go: 129func (b *Reader) Peek(n int) ([]byte, error) &#123; // ... b.fill() // ... &#125;func (b *Reader) fill() &#123; // ... n, err := b.rd.Read(b.buf[b.w:]) // ...&#125;/src/net/http/transport.go: 1517func (pc *persistConn) Read(p []byte) (n int, err error) &#123; // ... n, err = pc.conn.Read(p) // ...&#125;// /src/net/net.go: 173func (c *conn) Read(b []byte) (int, error) &#123; // ... n, err := c.fd.Read(b) // ...&#125;func (fd *netFD) Read(p []byte) (n int, err error) &#123; n, err = fd.pfd.Read(p) // ...&#125;/src/internal/poll/fd_unix.go: func (fd *FD) Read(p []byte) (int, error) &#123; //... if err = fd.pd.waitRead(fd.isFile); err == nil &#123; continue &#125; // ...&#125;func (pd *pollDesc) waitRead(isFile bool) error &#123; return pd.wait(&#x27;r&#x27;, isFile)&#125;func (pd *pollDesc) wait(mode int, isFile bool) error &#123; // ... res := runtime_pollWait(pd.runtimeCtx, mode) return convertErr(res, isFile)&#125; 直到跟到 runtime_pollWait，这个可以简单认为是等待服务端数据返回。 12345678910111213//go:linkname poll_runtime_pollWait internal/poll.runtime_pollWaitfunc poll_runtime_pollWait(pd *pollDesc, mode int) int &#123; // 1.如果网络正常返回数据就跳出 for !netpollblock(pd, int32(mode), false) &#123; // 2.如果有出错情况也跳出 err = netpollcheckerr(pd, int32(mode)) if err != 0 &#123; return err &#125; &#125; return 0&#125; 整条链路跟下来，就是会一直等待数据，等待的结果只有两个 有可以读的数据 出现报错 这里面的报错，又有那么两种 连接关闭 超时 123456789func netpollcheckerr(pd *pollDesc, mode int32) int &#123; if pd.closing &#123; return 1 // errClosing &#125; if (mode == &#x27;r&#x27; &amp;&amp; pd.rd &lt; 0) || (mode == &#x27;w&#x27; &amp;&amp; pd.wd &lt; 0) &#123; return 2 // errTimeout &#125; return 0&#125; 其中提到的超时，就是指这里面返回的数字2，会通过下面的函数，转化为 ErrTimeout， 而 ErrTimeout.Error() 其实就是 i/o timeout。 123456789101112func convertErr(res int, isFile bool) error &#123; switch res &#123; case 0: return nil case 1: return errClosing(isFile) case 2: return ErrTimeout // ErrTimeout.Error() 就是 &quot;i/o timeout&quot; &#125; println(&quot;unreachable: &quot;, res) panic(&quot;unreachable&quot;)&#125; 那么问题来了。上面返回的超时错误，也就是返回2的时候的条件是怎么满足的？ 123if (mode == &#x27;r&#x27; &amp;&amp; pd.rd &lt; 0) || (mode == &#x27;w&#x27; &amp;&amp; pd.wd &lt; 0) &#123; return 2 // errTimeout&#125; 还记得刚刚提到的 netpollDeadline吗？ 这里面放了定时器3s到点时执行的逻辑。 123456789101112131415161718func timerproc(tb *timersBucket) &#123; // 计时器到设定时间点了，触发之前注册函数 f(arg, seq) // 之前注册的是 netpollDeadline&#125;func netpollDeadline(arg interface&#123;&#125;, seq uintptr) &#123; netpolldeadlineimpl(arg.(*pollDesc), seq, true, true)&#125;/src/runtime/netpoll.go: 428func netpolldeadlineimpl(pd *pollDesc, seq uintptr, read, write bool) &#123; //... if read &#123; pd.rd = -1 rg = netpollunblock(pd, &#x27;r&#x27;, false) &#125; //...&#125; 这里会设置pd.rd=-1，是指 poller descriptor.read deadline ，含义网络轮询器文件描述符的读超时时间， 我们知道在linux里万物皆文件，这里的文件其实是指这次网络通讯中使用到的socket。 这时候再回去看发生超时的条件就是if (mode == &#39;r&#39; &amp;&amp; pd.rd &lt; 0) 。 至此。我们的代码里就收到了 io timeout 的报错。 总结 不要在 http.Transport中设置超时，那是连接的超时，不是请求的超时。否则可能会出现莫名 io timeout报错。 请求的超时在创建client里设置。 如果文章对你有帮助，看下文章底部右下角，做点正能量的事情（点两下）支持一下。（疯狂暗示，拜托拜托，这对我真的很重要！） 我是小白，我们下期见。 文章推荐： 妙啊! 程序猿的第一本互联网黑话指南 程序员防猝死指南 我感觉，我可能要拿图灵奖了。。。 给大家丢脸了，用了三年golang，我还是没答对这道内存泄漏题 硬核！漫画图解HTTP知识点+面试题 TCP粘包 数据包：我只是犯了每个数据包都会犯的错 |硬核图解 硬核图解！30张图带你搞懂！路由器，集线器，交换机，网桥，光猫有啥区别？ 别说了，一起在知识的海洋里呛水吧关注公众号:【小白debug】","categories":[{"name":"golang面试题","slug":"golang面试题","permalink":"https://xiaobaidebug.top/categories/golang%E9%9D%A2%E8%AF%95%E9%A2%98/"}],"tags":[]},{"title":"妙啊！程序猿的第一本互联网黑话指南","slug":"程序人生/妙啊！程序猿的第一本互联网黑话指南","date":"2021-05-10T14:57:55.000Z","updated":"2022-10-30T02:25:54.028Z","comments":true,"path":"2021/05/10/程序人生/妙啊！程序猿的第一本互联网黑话指南/","link":"","permalink":"https://xiaobaidebug.top/2021/05/10/%E7%A8%8B%E5%BA%8F%E4%BA%BA%E7%94%9F/%E5%A6%99%E5%95%8A%EF%BC%81%E7%A8%8B%E5%BA%8F%E7%8C%BF%E7%9A%84%E7%AC%AC%E4%B8%80%E6%9C%AC%E4%BA%92%E8%81%94%E7%BD%91%E9%BB%91%E8%AF%9D%E6%8C%87%E5%8D%97/","excerpt":"文章持续更新，可以微信搜一搜「小白debug」第一时间阅读，回复【教程】获golang免费视频教程。本文已经收录在GitHub https://github.com/xiaobaiTech/golangFamily , 有大厂面试完整考点和成长路线，欢迎Star。 很烦，小侄子最近不给我打电话了。 放下作为叔叔的面子，拨通电话。","text":"文章持续更新，可以微信搜一搜「小白debug」第一时间阅读，回复【教程】获golang免费视频教程。本文已经收录在GitHub https://github.com/xiaobaiTech/golangFamily , 有大厂面试完整考点和成长路线，欢迎Star。 很烦，小侄子最近不给我打电话了。 放下作为叔叔的面子，拨通电话。 他说，他最近很烦。 我以为他长大了，谈恋爱了。 他说，最近他们学校，换了个校长。 喜欢在早上升国旗之后发表演讲。 “发表演讲挺好的啊，德智体美。” 他说他听不懂。比如校长今天早上提到说： “我们需要大力推进新型教育场景，尝试建立一些新的教学模型，用心打磨细节。 并重点关注其他教育形式的可能性。利用传统教育形式去驱动新型教育形式，打通底层逻辑，形成闭环。用传统教育理念赋能新型教育场景。让传统和新型教育形式作为一整套组合拳，加速学生更好更快的发展。” 好家伙，这么长的一句话，信息量竟然为0。 再仔细一想。 心里一惊，原来是同行啊，这老哥，一定是互联网出来的。 光听到赋能这个词，我就知道是哪个厂出来的了。 我劝小侄子，这个想听懂，得有一定的互联网阅历才行啊。 小侄子却表示：“叔叔，你不是在互联网公司上班吗？你教教我吧” 不行，这对于年幼的他，还太早了。 直到他告诉我，“我们班长现在已经学会这种超酷的说话方式了，现在班里的女生都超爱听他说话” 这？？？ 不，这能忍？就算是这样的我，也有想要守护的东西。我必须教会。 那晚我打了3小时视频电话，畅快淋漓，让我差点忘了手机还欠费47块这件事。 三天后，侄子跟我说，好是挺好的，就是有点废纸，现在班里的女同学都喜欢找他要签名。 嗯，不是很环保。 考虑到身边还有很多连互联网黑话都不会说的胖友们，在这里简单写一份程序员必知必会的互联网黑话指南。赠与有缘人。 诚实质朴如你，实在无法低下高傲的头颅的话，希望你也能听懂别人在不讲人话的时候，到底背后是几层意思。 我不允许我的胖友们听不懂！更不允许你们被蒙在鼓里！ 领导开口闭口都是商业模式，闭环？整个会听下来，就记住了赋能，抓住，推进，深入这些词？ 产品让你跟她对齐一下？ 其他部门同事说再不马上处理某个问题，她就要上升了，而这时候你以为她是要上天？ hr跟你说公司扁平化管理，一年有两次加薪机会的时候，你只听到了加薪，却听漏了这只是机会？ 看完下面，你会对上面的场景有不一样的认识。 首先对于国内互联网大厂，我们盘一下常说的一些话。 比如抓手，是指手可以抓得到的地方，一般是指项目的切入点。 当提到项目需要努力寻找抓手的时候，说明项目现在比较蒙圈，还没有好的切入点，还在各种试错。 划重点了，项目怎么做都没想清楚，建议各位老哥 LeetCode 刷起来吧。 当你在职级答辩的时候，也可能被问到某件事情的抓手是什么。 一般是问你这个问题的切入点在哪，从哪里开始解决， 一般是要你说下从现象到本质的判断过程。 比如，机器内存暴涨导致报警，这时候现象切入点是某个进程，再定位代码更新部分，最后定位问题。 而一般项目的抓手都是从某个垂直领域里的细分领域里发力， 垂直领域和细分领域的区别大概可以理解为编程和用golang编程之间的区别。 领域不够垂直，不够细分，大概就是说，啥都干了点，不够专，不够精。 赋能是个啥，第一次接触这个词的时候，我还去搜了一下定义 好家伙，竟然拿一堆别人看不懂的词去解释一个别人看不懂的词，属实让人意外了。 后来搞明白了。说白了，别人没有某个东西，而你有，你主动找他跟你合作。重点在于主动这个词，有忽悠内味了。 还有，如果运营产品们喜欢探讨项目的盈利模式，你就要知道，他们其实心里也没底这玩意到底能不能赚钱。如果赚钱了，就会找出各种理由解释“这个项目为什么能赚钱”，这就是所谓的各种方法论了。 当然，如果项目赚钱了，又不给你发钱，就可以说是延迟满足感。 类似的不讲人话的词还有很多。 开个会，叫对齐一下。 找你领导，叫上升。 最容易pian到投资的领域，叫风口。 同时用多种方法去搞钱，就叫组合拳。 跟别的公司产生了合作，那就出现了生态，合作的公司多了，就叫生态链。 生态链产生闭环，这里就划重点了，意思是开始赚钱了。 还有另外一个需要敲黑板，划重点的考点。 当老板提到要向社会输送人才，就是要开始解雇咸鱼了。。不管读多少遍，我还是觉得说这话的人是真的厉害，这才是语！言！艺！术！请各位老哥把牛皮打在公屏上。 作为不讲人话的高发场地，面试那张方寸小桌，经常会出现一些让人觉得高深莫测的词语。 比如当你听到hr介绍公司弹性工作制，不打卡，也就是指下班时间不定，也没有加班这一说。 扁平化管理，在公司层面可能有各种积极意义。但对你个人而言，基本上约等于一般没有晋升。 能独立完成工作任务，当然就是产品的开发全都你一个人干。 很多时候hr会看着招聘简介上的信息问你问题。 问你有没有做过高并发相关，如果你给机器扩容过，大胆说有。 用了主备机器，就说是高可用。 用了缓存，那就是高性能了。 用了 Mysql，妥了，持久化。 虽然我很普通，但我很自信。 这时候你可能就会产生疑问了，这是不是国内互联网大厂才有的通病？ 我去外企是不是就好了？ 那欢迎来到快乐星球了。 上班等电梯的时候，你会听到旁边的 Lucy 端着她的美式卡布奇诺很惊讶的对 Emily 说 “Emiliy 你知道吗？我跟你说，昨天，Alice 他的手机在 meeting 的时候摔得粉粉碎，真的粉粉碎哦” “哇哦，what a pity“ 早上，老板会让大家开个 daily meeting。说一下大家今天的 todo list。还有 project 的进展。 可能这个 project 的 schedule 有些问题，尤其是buffer不多。另外，cost也偏高。 项目组没法 confirm 手上的 resource 能完全 take 得了。 anyway，我们可以先 argue 一下，再 follow up 最终的 output，先 run 起来，看work 不 work。 more importantly ，我们要尝试 cover 掉所有的 difficulty。 瞧瞧，瞬间觉得抓手闭环亲切了许多。 在这里我要正能量一波，否则对不起我这全日制本科的学历。 本来一些类似hr，kindle专有名词用英语，可以提升沟通效率，但是大量在不必要的场景下用这些中英文混杂的话，真的让人难受。 沟通，最 important 的是 efficiency，understand？ 以前在网上看到过一个话题叫我想一巴掌扇si那个中英夹杂讲话的朋友！ 当初年轻，高低也想说上那么两句。 现在成熟了，只会努力克制不要拿百宝袋里的四次元大嘴巴子扇人。 让更不成熟的年轻人去扇吧，要带响的哦。 国内的大厂和外企都不爱讲人话？ 那我去小厂，总归可以了吧？ 小了， 格局小了。 你忘了大厂给社会输送的人才了吗？ 你猜他们都去哪了？ 还是没学会怎么说黑话？ 那就用数量堆叠的方式，让人在无数莫名其妙的动词名词形容词下沦陷。 让他一时之间眼花缭乱，抓不住任何重点。 反正，某厂周报，就是这么干的。 会说话就多说点吧。 我是小白，我们下期见。 文章推荐： 给大家丢脸了，用了三年golang，我还是没答对这道内存泄漏题 硬核！漫画图解HTTP知识点+面试题 程序员防猝死指南 TCP粘包 数据包：我只是犯了每个数据包都会犯的错 |硬核图解 硬核图解！30张图带你搞懂！路由器，集线器，交换机，网桥，光猫有啥区别？ 别说了，一起在知识的海洋里呛水吧关注公众号:【小白debug】","categories":[{"name":"骚话连篇","slug":"骚话连篇","permalink":"https://xiaobaidebug.top/categories/%E9%AA%9A%E8%AF%9D%E8%BF%9E%E7%AF%87/"}],"tags":[]},{"title":"聊聊我的大学是怎么过的","slug":"程序人生/聊聊我的大学是怎么过的","date":"2021-05-10T14:57:55.000Z","updated":"2022-10-30T02:28:13.643Z","comments":true,"path":"2021/05/10/程序人生/聊聊我的大学是怎么过的/","link":"","permalink":"https://xiaobaidebug.top/2021/05/10/%E7%A8%8B%E5%BA%8F%E4%BA%BA%E7%94%9F/%E8%81%8A%E8%81%8A%E6%88%91%E7%9A%84%E5%A4%A7%E5%AD%A6%E6%98%AF%E6%80%8E%E4%B9%88%E8%BF%87%E7%9A%84/","excerpt":"今天收拾房间把大学时候的旧电脑翻了出来。 毕业之后我就很少碰它了。 正好可以试试还能不能开机。 打开电脑，小风扇一阵咔咔咔转起来。 桌面也不知道从什么时候开始多了很多【传奇霸主，沙城争霸，复古奇迹之类的】的网页快捷方式。 当然，还有2345浏览器。。。 磁盘使用率也总是能轻而易举的到98%。 可能是当了肉鸡，也可能该进行一波磁盘碎片整理。 但想想还是算了。没必要。 翻文件夹的时候发现了很多陈年老照片和老资料。 很多回忆瞬间涌入，我才想起好多旧事情。","text":"今天收拾房间把大学时候的旧电脑翻了出来。 毕业之后我就很少碰它了。 正好可以试试还能不能开机。 打开电脑，小风扇一阵咔咔咔转起来。 桌面也不知道从什么时候开始多了很多【传奇霸主，沙城争霸，复古奇迹之类的】的网页快捷方式。 当然，还有2345浏览器。。。 磁盘使用率也总是能轻而易举的到98%。 可能是当了肉鸡，也可能该进行一波磁盘碎片整理。 但想想还是算了。没必要。 翻文件夹的时候发现了很多陈年老照片和老资料。 很多回忆瞬间涌入，我才想起好多旧事情。 回忆的小风扇也突然温情了起来。 刚上大学的时候选专业，那时候”码农“这个词很火，当时我身边的人都在说这个行业已经饱和了，等我毕业的时候肯定就不行了，而且码农还很辛苦，不要选计算机专业，我表示很认可。 于是，我大学时候选了电气工程及其自动化，如果非要说专业对口的工作的话，那应该是电气工程师。 如果运气好的话，能进某电网当个工程师，又或者会进到某个变电站里调调设备啥的。我已经能想象到我能像刘慈欣那样在变电站里一边划水一边写下一部《三体》的画面了。 为了不让自己以后成为码农，但凡是跟计算机沾边的选修课，我是能不选就不选。 这其中就包括数据结构，后来流的泪，确实是当初脑子进的水。 像每一个普普通通的大学生一样，我大学的时候也不知道未来会做什么，只能好好学习，课是一门都没翘过。 每天下课后身边的同学都在打当时很火的英雄联盟，成群结队开黑，而我当时，也沉迷电影动漫。 但凡有点目标，也不至于这样。 那个年纪，谁都迷茫。 这样的日子持续了好长时间，为了寻求改变，于是尝试参加各种校园活动。 学校里有很多标榜着”领导力”，”组织力”，”策划力”的社团和组织。 那个年纪的年轻人大都血气方刚，谁不想做管理者呢？看着学生会会长在讲台上慷慨激昂的演讲，相信台下的每个人多多少少也想象过自己会不会也有这么一天。 但我很清楚，我不会有这么一天，毕竟我那时候连普通话都说不标准，带着广东味的普通话，怎么听都不普通。 于是我早早就接受了自己”工具人“的定位，学PS画海报，做PPT，录视频剪视频。 学会了这些技能，课程小组作业里，总有人喜欢找我组队。学生会宣传部里，也总能有我一份苦差事。 甚至有个老哥，让我为他和他女朋友做了一个相恋周年视频集锦。 这么多年过去了，他们现在已经各自有了自己的家庭，而这部视频，还躺在我的硬盘上。 这感觉，大概就叫唏嘘。 而这些技能，打死你，我也想不到现在能在做公众号的时候用上。。 后来，遭遇了好几次海报改了五六版的事情之后，我也开始觉得没意思了。 这一晃时间也到了大二下学期。 我也通过各种渠道，参加到了学校的一些所谓的科创小团体中。像什么PLC自控相关的项目，飞思卡尔啥的我是一个没落下。 全都去水了一把。后来听说有家公司搞了个四旋翼无人机的科创项目，听说报销额度高达1k。 这我哪懂无人机啊，但有便宜不占王八蛋啊。 我本想水一下完事的，但这玩意接触下来确实有点意思。 于是我的大学生活开始正式进入正轨。 我开始自己尝试画PCB电路板，看网上的源码。当时看不懂源码，就用的最笨的方法，一行一行的照着敲。 一边敲一边就有新的理解。 抛开效率不谈，只要你花时间，任何事情的熬不住你一遍一遍的磨。 大概过了两三个月吧。 小飞机的第一个模块才终于跑起来了。 对那时候的我来说，做这玩意，挺费钱的，电机电池都是钱。 举个例子。立在最上头的那个诡异的芯片。叫MPU6050，是个6轴陀螺仪，用来计算偏移反馈控制电机，可以让小飞机保持平衡。就这玩意，要60，穷学生看了都流泪。 于是，我通过各种渠道参加了一些兼职，大二结束的那个夏天，还去上海游泳馆当了一个暑假的苦力。 那个时候，早上5点起床，7点上班，下午3点下班。 不知道你们有没有干过这种没有成长的纯苦力工作，每次做完这种工作，脑子里只会有一种想法：”我以后绝对不能继续做这种工作”。 于是回到学校4点半，我就开始调代码。只有吃学习的苦，才能不吃生活的苦，那段时间效率高的飞起。 这时候肯定有读者跳出来骂小白了，游泳馆不好吗？穿着泳装的姐姐们难道你不爱看？ 嘿嘿，别问了，贼爱看。 后来小飞机也做出来了。 我拿着它去参加了各种比赛。 然后到了大三夏天，凭着这份经历，进了一家车企实习。这时候，我做的是嵌入式软件开发。 我以为我会一直这样下去。 直到某一天我在图书馆，看到科创实验室里的研究生大佬，桌子上放了一本《HTML从入门到精通》。 我开始有些动摇，”为什么连我们实验室的科创大佬都开始学这个，难道它比嵌入式开发要好”？ 好不好我不知道。 但当时我还打开过拉勾网溜了一遍，发现互联网应届毕业生的工资确实要高不少。 于是我又开始了新的探索。 我不是计算机系的学生，并且只会C语言和简单的数据结构。如果我想进入互联网行业，有哪些是适合我的呢？ 当时我发现了不少游戏行业的服务端是用C/C++的，于是尝试了往这个方面去学习和做准备。 很幸运，秋招结束前，拿到了一家游戏公司的offer。 后面的事情，就是跟大部分人一样，在实习中等待着毕业。 可以了，我的大学生活就聊到这里吧。 之前面试的时候，终面面试官问了我一个问题。 “如果你有一天，物质和经济条件都自由了，你会做什么？” 在技术面试里被问这样一个问题，我有点意外。但我心里很快有了答案。 我之所以能走到今天，单纯是因为当时的那家公司提供了小飞机这样的科创机会，我从这样一个小小的项目开始，人生开始慢慢发生了改变，如果有一天我能有机会，我也希望能像当初别人帮助我那样，去帮助更多跟曾经的我一样的年轻人，去改变他们的人生。 满分满分。我自己都信了。虽然我并没有实现啥啥自由，也不知道自己能为现在的年轻人做点什么，但给个小建议还是可以的。 就只有一个建议。 去打一次工吧，打一次毫无技术含量的苦力工。在这之后，你就会明白，比起吃生活的苦，学习的苦都算甜的。 最后我本是某科技公司ceo权力被架空股份被清空现在我只想夺回我的公司现在只差一个 你的点赞和再看我就能东山再起点击关注《小白debug》 ，我有一套详细的复仇计划等待实施 别说了，一起在知识的海洋里呛水吧点击下方名片，关注公众号:【小白debug】 不满足于在留言区说骚话？ 加我，我们建了个划水吹牛皮群，在群里，你可以跟你下次跳槽可能遇到的同事或面试官聊点有意思的话题。就超！开！心！ 文章推荐： 程序员防猝死指南 TCP粘包 数据包：我只是犯了每个数据包都会犯的错 |硬核图解 动图图解！既然IP层会分片，为什么TCP层也还要分段？","categories":[{"name":"骚话连篇","slug":"骚话连篇","permalink":"https://xiaobaidebug.top/categories/%E9%AA%9A%E8%AF%9D%E8%BF%9E%E7%AF%87/"}],"tags":[]},{"title":"硬核！阿里面试就是不一样！30张图带你搞懂路由器，集线器，交换机，网桥，光猫有啥区别？","slug":"图解网络/硬核图解！30张图带你搞懂！路由器，集线器，交换机，网桥，光猫有啥区别？","date":"2021-04-25T14:57:55.000Z","updated":"2022-10-30T02:25:54.111Z","comments":true,"path":"2021/04/25/图解网络/硬核图解！30张图带你搞懂！路由器，集线器，交换机，网桥，光猫有啥区别？/","link":"","permalink":"https://xiaobaidebug.top/2021/04/25/%E5%9B%BE%E8%A7%A3%E7%BD%91%E7%BB%9C/%E7%A1%AC%E6%A0%B8%E5%9B%BE%E8%A7%A3%EF%BC%8130%E5%BC%A0%E5%9B%BE%E5%B8%A6%E4%BD%A0%E6%90%9E%E6%87%82%EF%BC%81%E8%B7%AF%E7%94%B1%E5%99%A8%EF%BC%8C%E9%9B%86%E7%BA%BF%E5%99%A8%EF%BC%8C%E4%BA%A4%E6%8D%A2%E6%9C%BA%EF%BC%8C%E7%BD%91%E6%A1%A5%EF%BC%8C%E5%85%89%E7%8C%AB%E6%9C%89%E5%95%A5%E5%8C%BA%E5%88%AB%EF%BC%9F/","excerpt":"文章持续更新，可以微信搜一搜「小白debug」第一时间阅读，回复【教程】获golang免费视频教程。本文已经收录在GitHub https://github.com/xiaobaiTech/golangFamily , 有大厂面试完整考点和成长路线，欢迎Star。 故事就从一个车轱辘说起吧。先来看一个车轱辘。","text":"文章持续更新，可以微信搜一搜「小白debug」第一时间阅读，回复【教程】获golang免费视频教程。本文已经收录在GitHub https://github.com/xiaobaiTech/golangFamily , 有大厂面试完整考点和成长路线，欢迎Star。 故事就从一个车轱辘说起吧。先来看一个车轱辘。 辐条从车轱辘边缘，一直汇聚到 中心的轴，这个轴在英文里叫hub。 而我们今天要讲到的集线器，英文里也叫hub。 都叫hub，多少有点关系，看下这面这个图大概能明白，其实两者有点像。 大概想表达的意思是，它是汇聚网线的中心，因此就叫集线器。 所以可以理解，大家常逛的 Github，Docker Hub, 还有P**hub ，都是为了表达它们是某类资源的中心了吧。 那么集线器是什么呢？那就要从电脑是怎么互联的这个话题说起。 小学的时候，有一种网吧，它其实是不能上外网的。也就是不能打开度娘，不能搜索资料。 不能上网的网吧还能叫网吧？ 能。虽然不能上外网，但网吧老板可以把很多台机子连起来，实现网吧内互联，形成一个局域网（Local Area Network，简称LAN）。 网吧内互联之后，就可以放上各种游戏，比如CS，实现网吧内对线。 这种网吧有种好处，没有那么多键盘侠。 毕竟你不知道什么时候键着键着，对方就顺着网线找过来了。 对战直接从线上转移到线下了。 因此大家打游戏都很和谐，客气，场面十分感人就是了。 那么网吧内的电脑是怎么互联呢？ 一根网线互联电脑从最简单的场景说起，假设网吧内只有两台电脑 随便连根网线就能实现互联吗？ 当然不是。 还记得网络分层吗? 数据如果要进行传输，会从A电脑经过这些网络分层把消息组装好，再到B电脑层层解包。 网线，只是代替了上面的灰色部分，实现物理层上互联。 如果想要两台电脑互联成功，还需要确保每一层所需要的步骤都要做到位，这样数据才能确保正确投送并返回。 我们自顶向下，从细节开始说一下实现互联需要做什么。 应用层该层的网络功能由应用本身保证。 假设两台电脑是打算用游戏进行联网，那么该应用层的功能由游戏程序保证。 传输层绝大部分游戏用的传输层协议都是TCP，我们可以看下TCP报头。 这里面我们需要关注的是源和目的端口，这个可以定位到这台电脑上哪个进程在收发数据。 这两个端口信息一般是游戏内部已经填好。 AB两台电脑，其中一台作为服务端启动，比如A，起了个服务器进程。 服务器会开放一个固定的端口，比如27015。这就是目的端口。 这时候A和B都可以搜索到这个服务器。启动一个客户端进程，连接进入A的服务器进程。 而源端口，则由A和B自己生成。 网络层上图除了端口，我们还看到一个192.168.0.105，这个就是A的IP地址。 我们看一下IP层的报文头。 这里面需要关注是源和目的IP地址。 如果两台电脑想通过一根网线进行消息通信，那么他们需要在一个局域网内。 这意味着，他们的子网掩码需要一致。局域网内，假设子网掩码是 225.225.225.0，会认为 192.168.0.x 这些IP都属于一个局域网。所以当A的IP地址是192.168.0.105 时，那么B的IP地址可以配成192.168.0.106 。 关于IP这一块是啥，后面会细讲，大家如果没明白我说的是啥，不要急。 组装好网络层报头后，数据包传入到数据链路据层。 数据链路层以上解决了网络层的互联，而在数据链路层，数据包里需要拼接上MAC报头。先看下MAC报头长什么样子。 其中需要关心的是标红的源和目的MAC地址。MAC地址可以粗略理解是这台电脑网卡的唯一标识。大概长这样 128:f9:d3:62:7d:31 源和目的地址，在发送消息的时候就会被填上。 但是A只知道自己的MAC地址，怎么才能知道B的MAC地址呢？ 这时候需要ARP协议。 ARP（Address Resolution Protocal），即地址解析协议。用于将IP地址解析为以太网的MAC地址的协议。 在局域网中，当主机A有数据要发送给主机B时，A必须知道B的IP地址。 但是仅仅有IP地址还是不够的，因为IP数据报文还需要在数据链路层封装成帧才能通过物理网络发送。因为发送端还必须有接收端的MAC地址，所以需要一个从IP地址到MAC地址的映射。ARP就是干这事情的协议。 A查本地ARP表发现B的IP和MAC映射关系不存在 A通过ARP广播的形式向局域网发出消息，询问某IP对应的MAC地址是多少。比如A此时知道B的IP，但并不知道B的MAC地址是多少，就会尝试在局域网内发起ARP广播，询问局域网下所有机器，哪个机器的IP与B的IP一致。 B收到这个ARP消息，发现A要问的IP与自己的IP一致，就会把自己的MAC地址作为应答返回给A。 此时A就知道了B的MAC地址，顺便把消息记录到本地ARP表里，下次直接用表里的关系就行，不需要每次都去问。 物理层从数据链路层到物理层，数据会被转为01比特流。 此时需要把比特流传到另一台电脑。 通过一根网线，两段水晶头插入网口，把两台电脑连起来。 但对网线有一些要求。 这根网线两端的水晶头需要采用交叉互联法。 水晶头里有8根线，注意上图里的颜色，是有顺序的。第1、2根线起着收信号的作用，而第3、6脚发信号的作用。将一端的1号和3号线、2号和6号线互换一下位置，就能够在物理层实现一端发送的信号，另一端能收到。 当然，现在有些网卡有自适应的功能，就算是直连互联法的线，也能有交叉互联法的效果。如果你用的是这种网卡，就当我物理层这块什么都没说吧。 互联此时，在确保关闭防火墙的前提下，可以尝试从A电脑中ping一下B，再从B电脑中ping一下A。如无意外，都能ping通。 A给B发个消息，从应用层到数据链路层，会分别加上A和B的各种’’身份信息”。比如在传输层会加上A和B的应用端口号，在网络层加上源和目的IP，在数据链路层会加上源和目的网卡的MAC头部信息。 B收到消息后逐层解包，验证，最后顺利到达应用层。实现AB两台机器消息互通。 至此游戏就能正常联机对线，两台电脑互联成功！ 什么是集线器两个人打cs，总会觉得无聊，但是每台电脑又只有一个网线口。 想要邀请更多的人一起玩，怎么办？ 那就要回到文章开头提到的集线器（hub）了。 这是个工作在物理层的设备。 有多个网口，很好的解决了电脑上只有一个网口的问题，可以做到多台电脑的网线都插入到集线器上。 同时工作原理也非常简单，会把某个端口收到的数据，输入到中继电路。 中继电路的基本功能是将输入的信号广播到集线器的所有端口上。 简单来说就是无脑复制N份到其余N个端口上。 数据复制到N个端口后。对应转发到N台机器里。 集线器内部结构说到这里，已经对集线器有个大概认识了。 接下来，我们看下集线器的内部结构。 从A网口进入集线器的消息，此时还是电信号。这里经过一个PHY模块。 要理解PHY模块的作用，首先要先了解每个网口，都可能接着网线（废话），而每根网线的传输的格式都是有可能不同的。而PHY的作用，就是把这些格式转化为一个通用的格式。 举个例子。PHY就好比一个翻译器，有的人说英文，有的人说日文。但是PHY，会把它统一转为普通话，给内部电路处理。内部电路处理完之后，再经过PHY模块，转为英语，或日文从对应网口里输出。 经过PHY的处理后，以电信号的形式输入到中继电路，被无脑广播，再次经过PHY模块后变成BCD网口的格式输出。 这里面的电信号，是会受噪声干扰，导致信号形变出错的。 但就算是错了，也还是会原封不动的广播出去，这就是上面提到无脑的精髓所在。 那信号如果出错了怎么办？ 只能让接收方收到消息后进行校验。 还记得上文里提到的数据链路层的MAC报头里最末尾有个FCS吗？ FCS里存放的是发送方通过循环冗余校验CRC计算得到的值。 接收方用收到的数据算一次CRC，与FCS里的值进行对比。 如果一致，那证明数据没问题。如果出错，则直接丢弃。 当然，丢弃包并不会影响数据的传输， 因为丢弃的包不会触发确认响应。因此协议栈的 TCP 模块会检测到丢包， 并对该包进行重传。 如果消息没出错，但是因为无脑广播，C也能收到A发给B的数据包。 此时 C 会在接受到数据包后一层层的”剥开”。 正常情况下，在数据链路层时，识别到目的 MAC 地址跟 C 的不一致时，也会把数据丢弃。 什么是交换机目前只有 ABC 三台机器，每次都是广播发消息倒还好。 如果机器越来越多，每台机器发一条消息，都会被广播，就有点顶不住了。 举个例子。 假设N台机器，其中两台机器A和B，A发到B和B发给A，共两条消息。 如果这N台机器，用的是集线器。还是AB之间互发消息，每条消息都是广播的话，就是(N-1)+(N-1)条消息，差距有些大，对网络资源浪费就有些严重了。 那么，有没有可能做到，A发给B的消息，就不要转发给C呢？ 可以的，把集线器换成交换机。 交换机，又叫switch，跟集线器长得很像。 但是功能更强一些，从网络分层上来说，属于数据链路层，比集线器所在的物理层还要高一层。 所有发到交换机的数据，都会先进入交换机的缓存区。接着消息再被转发到对应机器上。 注意这里用的是转发，而不是集线器的广播，交换机是怎么做到转发的呢？ MAC地址表交换机内部维护了一张MAC地址表。 记录了 端口号和MAC地址的对应关系。 这个表的数据是交换机不断学习的结果。 当A发消息到交换机时，交换机发现消息是从1号端口进来的，则会在MAC地址表上，记录A的MAC地址对应1号端口。 如果A没有很长时间没发消息到这个1号端口，那这条记录就会过期并被删除。 那么，当时间足够长，ABC 都发过消息给交换机后，地址表就会有完整的关系信息。 A准备发送消息给B，此时A会把B的MAC地址，放入要发送的数据里。数据顺着网线发出。 交换机从端口收到数据，会把数据里的源和目的MAC地址提出来，跟MAC地址表进行对比。 发现B的MAC地址正好在2号端口，那么就把数据转发给2号端口。 此时B电脑从网线收到来自交换机2号端口的数据。 两种特殊情况正常流程很清楚了，看两个特殊情况： 交换机查询地址表时，发现目的 MAC 地址的目标端口和这个包的源端口，是同一个端口，怎么办？ 先说结论，会直接丢弃这个包。 我们看下，假设它不丢弃，会发生什么情况。 A发了个消息给B，中间经过一个集线器，此时消息会被广播到B和交换机。 此时B收到第一条A发给它的消息 交换机从1号端口收到A的消息后，解包，获得目的MAC地址是BB-BB-BB-BB-BB-BB。查MAC地址表，发现要发到1号端口。此时，源和目的端口都是同一个，如果交换机不丢弃这个消息，B会收到第二条A发给它的消息。 A只发了一次消息，B却收到两条消息，明显不对。 因此，当交换机查询地址表时，发现目标端口和源端口，是同一个端口时，会丢弃这个包。 MAC地址表里找不到对应的MAC地址，怎么办？ 这可能是因为具有该地址的设备，还没有向交换机发送过包，或者这个设备一段时间没有工作，导致地址被从地址表中删除了。 这种情况下，交换机无法判断应该把包转发到哪个端口，只能将包转发到除了源端口之外的所有端口上，无论该设备连接在哪个端口上，都能收到这个包。 此时，交换机就会跟集线器一样进行广播。 发送了包之后目标设备会作出响应，只要返回了响应包，交换机就可以将它的地址写入地址表，下次也就不需要把包 发到所有端口了。 交换机内部结构再看下交换机内部结构。 其实对比可以发现，交换机和集线器内部结构很像。 重点需要提到的是MAC模块。消息以电信号的形式从网口进入，到了PHY会被转成通用格式的电信号。而MAC模块的作用是把这个电信号转为数字信号，这样就能提取出MAC包头，并通过MAC数据帧末尾的FCS校验这个包有没有问题，如果没问题，则把数据放到内存缓冲区里，否则直接丢弃。 另外，这个MAC模块，虽然这么叫。但其实交换机MAC模块不具有 MAC 地址。因此交换机的端口不核对接收方 MAC 地址，而是直接接收所有的包并存放到缓冲区中。 放入到内存缓冲区后，还会把MAC地址和端口号记录到MAC地址表中。同时检查目的MAC地址在不在MAC地址表中，在的话则会转发到对应端口。否则广播。 交换机与网桥的区别网桥，本质上可以理解为两个网线口的交换机，正好可以把两台电脑给连起来，也叫桥接。而交换机，则是多网线口的网桥，可以把多台电脑给连（桥接）起来。 其他功能方面，大差不差，不必太过纠结。 交换机和二层交换机和三层交换机有什么区别这一部分提到的交换机，其实就是二层交换机，也就是工作在第二层（数据链路层）的交换机，二者没区别。 而三层交换机，是工作在第三层（网络层）的交换机，其实就是接下来要提到的路由器。 什么是路由器有了交换机之后，小网吧里的电脑就都可以被连起来了。交换机网口不够？那就再接个交换机。 但世界上电脑这么多，交换机里的MAC地址表难道全都要记住吗? 显然做不到。为了解决这个问题。 于是就有了路由器，工作在网络层，比数据链路层更高一层。 网络层引入了IP的概念。 什么是IP比如前面提到的 192.168.0.105 就是一个IP，同一个局域网内还可能会有一个IP是192.168.0.106。有没有发现，它们都是192.168.0.xxx。 像极了 上海市.黄浦区.南京东路.105号，这样的地址。现实生活中，我们可以通过一个地址定位到要去哪。到了 上海市.黄浦区.南京东路.105号楼里，我们就可以再去找某个叫身份证为xiaobaixxxxx的人。 那互联网世界里，我们也就可以通过IP地址，定位到某个广域网段，再通过广域网内部的局域网的MAC地址定位到具体某个电脑。 上海市.黄浦区.南京东路.105号可以帮助我们定位到在南京东路上的第105号楼的位置。但还有些路，比如南京西路，可能不止105号，可能要到257号。 实际上一个IP由网络号和主机号组成，共32位组成。如果拿了前面24位做网络号，那主机号就剩8位了，2的8次方=256，最多表示表示256号楼。因此为了多表示几个楼，可以向网络号多挪几位过来作为主机号。 那么具体多少位作为网络号呢？可以在IP后面加一个数字，用来表明这一点。 于是就有了 192.168.0.105/24这种表示方法，表明前24位192.168.0.0是网络号，105是主机号。 有了网段，就可以一次性表示一大批地址。就不需要像交换机那样苦哈哈的一条一条MAC地址记录在表里。 路由表路由器的作用，可以帮助我们在互联网世界里转发消息到对应的IP。 对比一下。 交换机，是通过 MAC 头部中，接收方 MAC 地址，来判断转发目标的。 路由器，则是根据 IP 头部中， IP 地址来判断的。 由于使用的地址不同，记录转发信息的表也会不同。 类似交换机的MAC地址表，路由器也维护了一张路由表。 而路由表，是用于告诉路由器，什么样的消息该转发到什么端口。 假设A要发消息到D。也就是192.168.0.105/24要发消息到192.168.1.11/24。 那么A会把消息经过交换机发到路由器。 路由器通过192.168.0.105/24获得其网络号是 192.168.0.0 ，而目的地的网络号是192.168.1.0，二者网络号不同，处于不同局域网。 查路由表，发现192.168.1.0,在e2端口，那么就会把消息从e2端口发出，到达交换机，交换机发现MAC地址是它局域网下的D机器，就把消息打过去。 当然，如果路由表里找不到，那就打到默认网关吧，也就是从e1口发出，发到IP192.0.2.1。这个路由器的路由表不知道该去哪，说不定其他路由器知道。 路由器的内部结构 路由器内部，分为控制平面和数据平面，说白了就是对应软件部分和硬件部分。 硬件部分跟交换机很像。数据从A网口进入，此时数据还是网线上格式的电信号，会被PHY模块转为通用信号格式，再被MAC模块转为数字信号，通过FCS进行错误校验，同时校验MAC地址是否是自己，通过校验则进入内存缓冲区，否则丢弃。 再进入软件部分，由路由选择处理器，通过一定规则（软件逻辑），查询路由表判断转发目标和对应转发口，再经由硬件部分的交换结构转发出去。 如果路由表中无法找到匹配记录，路由器会丢弃这个包，并通过ICMP消息告知发送方。 路由器和交换机的主要区别MAC模块的区别路由器和交换机不同点在于，它的每个网口下，都有一个MAC地址和IP地址。 正因为路由器具有 MAC 地址，因此它能够成为数据链路层的的发送方和接收方。 怎么理解这句话？ 前面提到交换机，是不具备MAC地址的，而MAC报头是需要填上目的MAC地址的。因此交换机从来都不是数据的目的地，它只简单转发数据帧到目的地。 但路由器，是有MAC地址的，因此MAC报头就可以写上，下一站目的地就是xx路由。 到了路由器后，路由器可以再次组装下一站的目的MAC地址是再下一个路由，通过这一点，让数据在路由和路由之间传输。 而同时因为交换机不具有MAC地址，因此也不会校验收到的数据帧的MAC地址是不是自己的，全部收下做转发。而路由器则会校验数据帧的MAC报头里的目的MAC地址是不是自己，是的话才会收入内存缓冲区，否则丢弃。 找不到转发目的地时的处理方式有区别如果在路由表中无法找到匹配的记录，路由器会丢弃这个包，并通过 ICMP消息告知发送方。 而交换机在MAC地址表里找不到转发端口时会选择广播。 这里的处理方式两者是不同的，原因在于网络规模的大小。 交换机连接的网络最多也就是几千台设备的规模，这个规模并 不大。如果只有几千台设备，遇到不知道应该转发到哪里的包，交换机可以将包发送到所有的端口上，虽然这个方法很简单粗暴，但不会引发什么 问题。 但路由器工作的网络环境就是互联网，全世界所有的设备都连接在互联网上，规模非常大，并且这个规模还在持续扩大中。如果此时它的操作跟交换机一样，将不知道应该转发到哪里的包发送到整个网络上，那就会产生大量的网络包，造成网络拥塞。因此，路由器遇到不知道该转发到哪里的包， 就会直接丢弃。 路由器和光猫有什么区别不管是交换机还是路由器，前面都是提到网口输入的是电信号。但现在流行的是光纤传输，传输的是光信号。 而光猫（modem），是一种调制解调器，其实就是用于光电信号转换的设备。 接收数据时，可以将光纤里的光信号转化为电信号，发给路由器，路由器内部再转成数字信号，并在此基础上做各种处理。 相反，也会把路由器传来的电信号转为光信号，发到光纤，并进入互联网。 总结 两台电脑可以通过一根网线直接连接，进行通信。 机器一多，可以把网线都接到集线器（物理层）上，但是集线器会不管三七二十一进行广播。 不想广播，可以用（二层）交换机（数据链路层），又叫多端口网桥，它比较聪明，会自我学习生产MAC地址表，知道消息发到哪，那就不需要广播啦 互联网电脑这么多，交换机MAC地址表总不能全放下吧。改用路由器（网络层），也叫三层交换机，通过网段的方式定位要把消息转发到哪，就不需要像交换机那样苦哈哈一条条记录MAC地址啦。 路由器和光猫之间是好搭档，光猫负责把光纤里的光信号转换成电信号给路由器。 现在一般情况下，家里已经不用集线器和交换机了，大部分路由器也支持交换机的功能。所以可以看到，家里的台式机电脑一般就连到一个路由器，再连个光猫就够能快乐上网了。 最后以前整个班的同学家里都不见得有一台电脑，都喜欢偷偷跑去网吧玩电脑。改革开放的春风，把电脑吹进了每家每户，也把网吧给吹成了网咖。 从前的我晚上偷偷上网，现在的我，接到报警，也能在大半夜爬起来网上冲浪。 没想到我以这种方式保持了当初最纯粹的质朴。 我是小白，看下右下角，你懂我意思的。 夏天快来了，我们下期见。 参考资料网络是怎么连接的 - 户根勤 趣谈网络协议- 极客时间 文章推荐： 给大家丢脸了，用了三年golang，我还是没答对这道内存泄漏题 硬核！漫画图解HTTP知识点+面试题 程序员防猝死指南 硬核图解，TCP粘包是什么？为什么UDP不粘包？ 别说了，一起在知识的海洋里呛水吧关注公众号:【小白debug】","categories":[{"name":"图解网络","slug":"图解网络","permalink":"https://xiaobaidebug.top/categories/%E5%9B%BE%E8%A7%A3%E7%BD%91%E7%BB%9C/"}],"tags":[]},{"title":"TCP粘包  数据包：我只是犯了每个数据包都会犯的错 |硬核图解","slug":"图解网络/TCP粘包！数据包：我只是犯了每个数据包都会犯的错，硬核图解","date":"2021-03-26T14:57:55.000Z","updated":"2022-10-30T02:23:15.272Z","comments":true,"path":"2021/03/26/图解网络/TCP粘包！数据包：我只是犯了每个数据包都会犯的错，硬核图解/","link":"","permalink":"https://xiaobaidebug.top/2021/03/26/%E5%9B%BE%E8%A7%A3%E7%BD%91%E7%BB%9C/TCP%E7%B2%98%E5%8C%85%EF%BC%81%E6%95%B0%E6%8D%AE%E5%8C%85%EF%BC%9A%E6%88%91%E5%8F%AA%E6%98%AF%E7%8A%AF%E4%BA%86%E6%AF%8F%E4%B8%AA%E6%95%B0%E6%8D%AE%E5%8C%85%E9%83%BD%E4%BC%9A%E7%8A%AF%E7%9A%84%E9%94%99%EF%BC%8C%E7%A1%AC%E6%A0%B8%E5%9B%BE%E8%A7%A3/","excerpt":"事情从一个健身教练说起吧。","text":"事情从一个健身教练说起吧。 李东，自称亚健康终结者，尝试使用互联网+的模式拓展自己的业务。在某款新开发的聊天软件琛琛上发布广告。 键盘说来就来。疯狂发送”李东”，回车发送！，”亚健康终结者”，再回车发送！ 还记得四层网络协议长什么样子吗？ 四层网络模型每层各司其职，消息在进入每一层时都会多加一个报头，每多一个报头可以理解为数据报多戴一顶帽子。这个报头上面记录着消息从哪来，到哪去，以及消息多长等信息。比如，**mac头部记录的是硬件的唯一地址，IP头记录的是从哪来和到哪去，传输层头记录到是到达目的主机后具体去哪个进程**。 在从消息发到网络的时候给消息带上报头，消息和纷繁复杂的网络中通过这些信息在路由器间流转，最后到达目的机器上，接受者再通过这些报头，一步一步还原出发送者最原始要发送的消息。 为什么要将数据切片软件琛琛是属于应用层上的。 而”李东”，”亚健康终结者”这两条消息在进入传输层时使用的是传输层上的 TCP 协议。消息在进入传输层（TCP）时会被切片为一个个数据包。这个数据包的长度是MSS。 可以把网络比喻为一个水管，是有一定的粗细的，这个粗细由网络接口层（数据链路层）提供给网络层，一般认为是的MTU（1500），直接传入整个消息，会超过水管的最大承受范围，那么，就需要进行切片，成为一个个数据包，这样消息才能正常通过“水管”。 MTU 和 MSS 有什么区别 MTU: Maximum Transmit Unit，最大传输单元。 由网络接口层（数据链路层）提供给网络层最大一次传输数据的大小；一般 MTU=1500 Byte。假设IP层有 &lt;= 1500 byte 需要发送，只需要一个 IP 包就可以完成发送任务；假设 IP 层有&gt; 1500 byte 数据需要发送，需要分片才能完成发送，分片后的 IP Header ID 相同。 MSS：Maximum Segment Size 。 TCP 提交给 IP 层最大分段大小，不包含 TCP Header 和 TCP Option，只包含 TCP Payload ，MSS 是 TCP 用来限制应用层最大的发送字节数。假设 MTU= 1500 byte，那么 MSS = 1500- 20(IP Header) -20 (TCP Header) = 1460 byte，如果应用层有 2000 byte 发送，那么需要两个切片才可以完成发送，第一个 TCP 切片 = 1460，第二个 TCP 切片 = 540。 什么是粘包那么当李东在手机上键入”李东””亚健康终结者”的时候，在 TCP 中把消息分成 MSS 大小后，消息顺着网线顺利发出。 网络稳得很，将消息分片传到了对端手机 B 上。经过 TCP 层消息重组。变成”李东亚健康终结者”这样的字节流（stream）。 但由于聊天软件琛琛是新开发的，而且开发者叫小白，完了，是个臭名昭著的造 bug 工程师。经过他的代码，在处理字节流的时候消息从”李东”，”亚健康终结者”变成了”李东亚”，”健康终结者”。”李东”作为上一个包的内容与下一个包里的”亚”粘在了一起被错误地当成了一个数据包解析了出来。这就是所谓的粘包。 一个号称健康终结者的健身教练，大概运气也不会很差吧，就祝他客源滚滚吧。 为什么会出现粘包那就要从 TCP 是啥说起。 TCP，Transmission Control Protocol。传输控制协议，是一种面向连接的、可靠的、基于字节流的传输层通信协议。 其中跟粘包关系最大的就是基于字节流这个特点。 字节流可以理解为一个双向的通道里流淌的数据，这个数据其实就是我们常说的二进制数据，简单来说就是一大堆 01 串。这些 01 串之间没有任何边界。 应用层传到 TCP 协议的数据，不是以消息报为单位向目的主机发送，而是以字节流的方式发送到下游，这些数据可能被切割和组装成各种数据包，接收端收到这些数据包后没有正确还原原来的消息，因此出现粘包现象。 为什么要组装发送的数据上面提到 TCP 切割数据包是为了能顺利通过网络这根水管。相反，还有一个组装的情况。如果前后两次 TCP 发的数据都远小于 MSS，比如就几个字节，每次都单独发送这几个字节，就比较浪费网络 io 。 比如小白爸让小白出门给买一瓶酱油，小白出去买酱油回来了。小白妈又让小白出门买一瓶醋回来。小白前后结结实实跑了两趟，影响了打游戏的时间。 优化的方法也比较简单。当小白爸让小白去买酱油的时候，小白先等待，继续打会游戏，这时候如果小白妈让小白买瓶醋回来，小白可以一次性带着两个需求出门，再把东西带回来。 上面说的其实就是TCP的 Nagle 算法优化，目的是为了避免发送小的数据包。 在 Nagle 算法开启的状态下，数据包在以下两个情况会被发送： 如果包长度达到MSS（或含有Fin包），立刻发送，否则等待下一个包到来；如果下一包到来后两个包的总长度超过MSS的话，就会进行拆分发送； 等待超时（一般为200ms），第一个包没到MSS长度，但是又迟迟等不到第二个包的到来，则立即发送。 由于启动了Nagle算法， msg1 小于 mss ，此时等待200ms内来了一个 msg2 ，msg1 + msg2 &gt; MSS，因此把 msg2 分为 msg2(1) 和 msg2(2)，msg1 + msg2(1) 包的大小为MSS。此时发送出去。 剩余的 msg2(2) 也等到了 msg3， 同样 msg2(2) + msg3 &gt; MSS，因此把 msg3 分为 msg3(1) 和 msg3(2)，msg2(2) + msg3(1) 作为一个包发送。 剩余的 msg3(2) 长度不足mss，同时在200ms内没有等到下一个包，等待超时，直接发送。 此时三个包虽然在图里颜色不同，但是实际场景中，他们都是一整个 01 串，如果处理开发者把第一个收到的 msg1 + msg2(1) 就当做是一个完整消息进行处理，就会看上去就像是两个包粘在一起，就会导致粘包问题。 关掉 Nagle 算法就不会粘包了吗？Nagle 算法其实是个有些年代的东西了，诞生于 1984 年。对于应用程序一次发送一字节数据的场景，如果没有 Nagle 的优化，这样的包立马就发出去了，会导致网络由于太多的包而过载。 但是今天网络环境比以前好太多，Nagle 的优化帮助就没那么大了。而且它的延迟发送，有时候还可能导致调用延时变大，比如打游戏的时候，你操作如此丝滑，但却因为 Nagle 算法延迟发送导致慢了一拍，就问你难受不难受。 所以现在一般也会把它关掉。 看起来，Nagle 算法的优化作用貌似不大，还会导致**粘包”问题”。那么是不是关掉这个算法就可以解决掉这个粘包”问题”**呢？ 1TCP_NODELAY = 1 接受端应用层在收到 msg1 时立马就取走了，那此时 msg1 没粘包问题 **msg2 **到了后，应用层在忙，没来得及取走，就呆在 TCP Recv Buffer 中了 **msg3 **此时也到了，跟 msg2 和 msg3 一起放在了 TCP Recv Buffer 中 这时候应用层忙完了，来取数据，图里是两个颜色作区分，但实际场景中都是 01 串，此时一起取走，发现还是粘包。 因此，就算关闭 Nagle 算法，接收数据端的应用层没有及时读取 TCP Recv Buffer 中的数据，还是会发生粘包。 怎么处理粘包粘包出现的根本原因是不确定消息的边界。接收端在面对**”无边无际”的二进制流的时候，根本不知道收了多少 01 才算一个消息。一不小心拿多了就说是粘包**。其实粘包根本不是 TCP 的问题，是使用者对于 TCP 的理解有误导致的一个问题。 只要在发送端每次发送消息的时候给消息带上识别消息边界的信息，接收端就可以根据这些信息识别出消息的边界，从而区分出每个消息。 常见的方法有 加入特殊标志 可以通过特殊的标志作为头尾，比如当收到了0xfffffe或者回车符，则认为收到了新消息的头，此时继续取数据，直到收到下一个头标志0xfffffe或者尾部标记，才认为是一个完整消息。类似的像 HTTP 协议里当使用 chunked 编码 传输时，使用若干个 chunk 组成消息，最后由一个标明长度为 0 的 chunk 结束。 加入消息长度信息 这个一般配合上面的特殊标志一起使用，在收到头标志时，里面还可以带上消息长度，以此表明在这之后多少 byte 都是属于这个消息的。如果在这之后正好有符合长度的 byte，则取走，作为一个完整消息给应用层使用。在实际场景中，HTTP 中的Content-Length就起了类似的作用，当接收端收到的消息长度小于 Content-Length 时，说明还有些消息没收到。那接收端会一直等，直到拿够了消息或超时，关于这一点上一篇文章里有更详细的说明。 可能这时候会有朋友会问，采用0xfffffe标志位，用来标志一个数据包的开头，你就不怕你发的某个数据里正好有这个内容吗？ 是的，怕，所以一般除了这个标志位，发送端在发送时还会加入各种校验字段（校验和或者对整段完整数据进行 CRC 之后获得的数据）放在标志位后面，在接收端拿到整段数据后校验下确保它就是发送端发来的完整数据。 UDP 会粘包吗跟 TCP 同为传输层的另一个协议，UDP，User Datagram Protocol。用户数据包协议，是面向无连接，不可靠的，基于数据报的传输层通信协议。 基于数据报是指无论应用层交给 UDP 多长的报文，UDP 都照样发送，即一次发送一个报文。至于如果数据包太长，需要分片，那也是IP层的事情，大不了效率低一些。UDP 对应用层交下来的报文，既不合并，也不拆分，而是保留这些报文的边界。而接收方在接收数据报的时候，也不会像面对 TCP 无穷无尽的二进制流那样不清楚啥时候能结束。正因为基于数据报和基于字节流的差异，TCP 发送端发 10 次字节流数据，而这时候接收端可以分 100 次去取数据，每次取数据的长度可以根据处理能力作调整；但 UDP 发送端发了 10 次数据报，那接收端就要在 10 次收完，且发了多少，就取多少，确保每次都是一个完整的数据报。 我们先看下IP报头 注意这里面是有一个 16 位的总长度的，意味着 IP 报头里记录了整个 IP 包的总长度。接着我们再看下 UDP 的报头。 在报头中有16bit用于指示 UDP 数据报文的长度，假设这个长度是 n ，以此作为数据边界。因此在接收端的应用层能清晰地将不同的数据报文区分开，从报头开始取 n 位，就是一个完整的数据报，从而避免粘包和拆包的问题。 当然，就算没有这个位（16位 UDP 长度），因为 IP 的头部已经包含了数据的总长度信息，此时如果 IP 包（网络层）里放的数据使用的协议是 UDP（传输层），那么这个总长度其实就包含了 UDP 的头部和 UDP 的数据。 因为 UDP 的头部长度固定为 8 字节（ 1 字节= 8 位，8 字节= 64 位，上图中除了数据和选项以外的部分），那么这样就很容易的算出 UDP 的数据的长度了。因此说 UDP 的长度信息其实是冗余的。 1UDP Data 的长度 = IP 总长度 - IP Header 长度 - UDP Header 长度 可以再来看下 TCP 的报头 TCP首部里是没有长度这个信息的，跟UDP类似，同样可以通过下面的公式获得当前包的TCP数据长度。 1TCP Data 的长度 = IP 总长度 - IP Header 长度 - TCP Header 长度。 跟 UDP 不同在于，TCP 发送端在发的时候就不保证发的是一个完整的数据报，仅仅看成一连串无结构的字节流，这串字节流在接收端收到时哪怕知道长度也没用，因为它很可能只是某个完整消息的一部分。 为什么长度字段冗余还要加到 UDP 首部中关于这一点，查了很多资料，《 TCP-IP 详解（卷2）》里说可能是因为要用于计算校验和。也有的说是因为UDP底层使用的可以不是IP协议，毕竟 IP 头里带了总长度，正好可以用于计算 UDP 数据的长度，万一 UDP 的底层不是IP层协议，而是其他网络层协议，就不能继续这么计算了。 但我觉得，最重要的原因是，IP 层是网络层的，而 UDP 是传输层的，到了传输层，数据包就已经不存在IP头信息了，那么此时的UDP数据会被放在 UDP 的 Socket Buffer 中。当应用层来不及取这个 UDP 数据报，那么两个数据报在数据层面其实都是一堆 01 串。此时读取第一个数据报的时候，会先读取到 UDP 头部，如果这时候 UDP 头不含 UDP 长度信息，那么应用层应该取多少数据才算完整的一个数据报呢？ 因此 UDP 头的这个长度其实跟 TCP 为了防止粘包而在消息体里加入的边界信息是起一样的作用的。 面试的时候咱就把这些全说出去，显得咱好像经过了深深的思考一样，面试官可能会觉得咱特别爱思考，加分加分。 如果我说错了，请把我的这篇文章转发给更多的人，让大家记住这个满嘴胡话的人，在关注之后狠狠的私信骂我，拜托了！ IP 层有粘包问题吗IP 层会对大包进行切片，是不是也有粘包问题？ 先说结论，不会。首先前文提到了，粘包其实是由于使用者无法正确区分消息边界导致的一个问题。 先看看 IP 层的切片分包是怎么回事。 如果消息过长，IP层会按 MTU 长度把消息分成 N 个切片，每个切片带有自身在包里的位置（offset）和同样的IP头信息。 各个切片在网络中进行传输。每个数据包切片可以在不同的路由中流转，然后在最后的终点汇合后再组装。 在接收端收到第一个切片包时会申请一块新内存，创建IP包的数据结构，等待其他切片分包数据到位。 等消息全部到位后就把整个消息包给到上层（传输层）进行处理。 可以看出整个过程，IP 层从按长度切片到把切片组装成一个数据包的过程中，都只管运输，都不需要在意消息的边界和内容，都不在意消息内容了，那就不会有粘包一说了。 IP 层表示：我只管把发送端给我的数据传到接收端就完了，我也不了解里头放了啥东西。 听起来就像 “我不管产品的需求傻不傻X，我实现了就行，我不问，也懒得争了”，这思路值得每一位优秀的划水程序员学习，respect。 总结粘包这个问题的根因是由于开发人员没有正确理解 TCP 面向字节流的数据传输方式，本身并不是 TCP 的问题，是开发者的问题。 TCP 不管发送端要发什么，都基于字节流把数据发到接收端。这个字节流里可能包含上一次想要发的数据的部分信息。接收端根据需要在消息里加上识别消息边界的信息。不加就可能出现粘包问题。 TCP 粘包跟Nagle算法有关系，但关闭 Nagle 算法并不解决粘包问题。 UDP 是基于数据报的传输协议，不会有粘包问题。 IP 层也切片，但是因为不关心消息里有啥，因此有不会有粘包问题。 TCP 发送端可以发 10 次字节流数据，接收端可以分 100 次去取；UDP 发送端发了 10 次数据报，那接收端就要在 10 次收完。 数据包也只是按着 TCP 的方式进行组装和拆分，如果数据包有错，那数据包也只是犯了每个数据包都会犯的错而已。 最后，李东工作没了，而小白表示 文章推荐： 给大家丢脸了，用了三年golang，我还是没答对这道内存泄漏题 硬核！漫画图解HTTP知识点+面试题 程序员防猝死指南 别说了，一起在知识的海洋里呛水吧关注公众号:【小白debug】","categories":[{"name":"图解网络","slug":"图解网络","permalink":"https://xiaobaidebug.top/categories/%E5%9B%BE%E8%A7%A3%E7%BD%91%E7%BB%9C/"}],"tags":[]},{"title":"程序员划水指南","slug":"程序人生/程序员防猝死指南","date":"2021-03-10T14:57:55.000Z","updated":"2022-10-30T02:23:15.272Z","comments":true,"path":"2021/03/10/程序人生/程序员防猝死指南/","link":"","permalink":"https://xiaobaidebug.top/2021/03/10/%E7%A8%8B%E5%BA%8F%E4%BA%BA%E7%94%9F/%E7%A8%8B%E5%BA%8F%E5%91%98%E9%98%B2%E7%8C%9D%E6%AD%BB%E6%8C%87%E5%8D%97/","excerpt":"文章持续更新，可以微信搜一搜「小白debug」第一时间阅读，回复【教程】获golang免费视频教程。本文已经收录在GitHub https://github.com/xiaobaiTech/golangFamily , 有大厂面试完整考点和成长路线，欢迎Star。 快过年了，跟我可爱的小侄子通了个电话，上来就说，”叔叔你头发怎么变少了”，我很痛心，我的小侄子，年纪轻轻的，眼神已经这么不好使了。但转念一想，这也是他对我的一种关心，作为叔叔，也该回应一把，今年过年给他带一本《少儿编程》回去当礼物吧。","text":"文章持续更新，可以微信搜一搜「小白debug」第一时间阅读，回复【教程】获golang免费视频教程。本文已经收录在GitHub https://github.com/xiaobaiTech/golangFamily , 有大厂面试完整考点和成长路线，欢迎Star。 快过年了，跟我可爱的小侄子通了个电话，上来就说，”叔叔你头发怎么变少了”，我很痛心，我的小侄子，年纪轻轻的，眼神已经这么不好使了。但转念一想，这也是他对我的一种关心，作为叔叔，也该回应一把，今年过年给他带一本《少儿编程》回去当礼物吧。 但转念又一想，也许我真的头发变少了呢，我强壮的体魄不再足以支撑我肮脏的灵魂了呢，或许真的应了那句古语，程序员固有一死，要么骚死，要么累死？ 我好残忍，我竟然想让我的小侄走上这么一条不归路。 可是我这一身编程本领好想传授予人，我还想不想那么快一”猝”而就。我还想看着小侄子长大成人，然后在面试他的时候偷偷放水，再把他招进部门结对编程，我一定要活久一点。我想一定还有跟我一样有未了心愿的程序员，于是今天我将祭出所有划水技能，希望赠与有缘人。 换行业这是最直接的解决方案，那么问题来了，应该去哪个行业呢？程序员下岗后一般再就业的岗位不是送外卖就是送快递，这两个工作从工作强度和工作时长来说，丝毫不比程序员轻松。这就片面了。 有时间送快递和外卖的话，那不如老老实实考个公务员吧。程序员怎么成为公务员？这里正好有一个github项目，就教你如何成为一个公务员。 1https://github.com/coder2gwy/coder2gwy 连怎么安排学习时间，怎么请假都安排得明明白白，贼吉尔细心。 跳槽到965的公司从程序员跳槽到公务员或者是教师这条路子比较艰难，虽然我相信大部分程序员在考试上面都比常人要更擅长些。 一旦选择考公务员，等于放弃自己学习多年的技能，什么mysql，redis，java，设计模式这些，都将成为过眼云烟，选择成本巨大。就算成了，也可能会后悔，或许会在某个四下无人的下午三点，用当年的程序员杯子装着这周xx办主任送的茶叶泡的茶，写着 《下班总结》，感叹这个世界少了一个出色的程序员。 那么跳槽到一个965的公司，可能可以帮助你更好地划水。那么问题来了，怎么样找到995的公司？ 还记得n年前的那个996icu吗？ 1https://github.com/996icu/996.ICU 里面贴心地给出了一份996的公司名单，如果你坚决拒绝996，那么从拒绝这份名单里的公司offer开始。 1https://github.com/996icu/996.ICU/tree/master/blacklist 同时给出了这些公司996的证据，真正做到”拒绝张嘴就来”和有理有据，非常符合程序员讲事实摆道理的性格。 建议大家根据钱包厚度和身体承受能力进行选择，996下班不可怕，可怕的是，半夜一个报警就可以爬起来愉快网上冲浪了。以前高中的时候还要翻墙出去网吧通宵，现在在家里就能做到！ 同时也给出了一份965的公司名单。 1https://github.com/996icu/996.ICU/tree/master/whitelist 但是值得一提，这些公司都比较少，同时不排除哪一天不会变成996。毕竟制度是人定的，公司也是要盈利的，哪天换了个领导冲kpi，大家也只能一起冲冲冲了。 结论上来说，996的公司比965的公司多太多，大部分有志青年都在996的公司里，既然无法避免，那就要学会怎么在工作中划水。 学会划水如果你已经在996的公司里，同时你的钱包需要你通过这种方式出卖劳动，那么显然换行业，跳槽，都不太适合，毕竟轻松意味着钱少。那么怎么在996公司里防猝死呢？划水成为唯一答案，划水其实也是一种技术，是分等级的，下面分享几个实用的划水技巧。 初级划水技能初级划水技能是属于每个程序员都要学会的基础技能。 不要让自己看起来很闲不管是因为你是真的很闲，还是因为你效率高很快把活干完了。如果你看起来很闲，老板就容易会认为你工作不饱和，从而不断加活，直到你看起来一直在忙为止。既然如此，如果你一直看起来很忙，那么这样的问题可以被很好的避免。而vscode是程序员最常用的编辑器，我们可以在此基础上找到很多划水神器。 模拟写代码1https://github.com/zy445566/vscode-plugin-swimming 代码写的快，提早完工被压榨怎么办？你需要一个模拟写代码工具，让VSCode模拟写代码，划水、摸鱼神器，让代码自己重写一遍。 看小说工具上学那会偷偷摸摸看小说时会在小说本上套上一层课本封面，以此来掩盖上课划水的行为。同样的道理，下面这个插件感觉跟上课看小说的经历有点像，他让开发者可以在 VSCode 上边写代码边看小说。 下次等产品经理路过你身旁的时候，以为你写了一堆密密麻麻的的代码，都不好意思再给你加需求。 1https://github.com/zrk1993/read-vscode-e 听音乐插件做事做全套，还要在vscode装上听音乐的插件。 1https://github.com/nondanee/vsc-netease-music 炒股 1https://github.com/roblourens/vscode-stocks 中级划水技能项目时间预估 每次需求迭代，产品都会让开发给出一个开发时间。 我接触过的百分之90的程序员都是老实的小伙子，是多少就报多少，有些为了方便产品快速看效果，还会压缩自己的时间，这种情况在新人程序员里尤为明显。 但有些不讲武德的产品，会动不动做一点 小小的改动，同时因为改动较小，之前提到的时间一般不会更改。 如果你所在的项目中产品不止一个人，就可能出现多个产品给你提需求的情况，改动不大，但挺急。 一个程序员越老实，就越不会表达，选择闷头苦干，有些甚至牺牲节假日时间在家干活。 因此为了更好的应对这些非常常见的情况，建议再估计工时的时候，都多预估至少20~50%的时间当做buffer。 如果你提前做好需求，请务必不要提前给产品看，这只会方便他在看到实物后做出更多的变更。 如何巧妙的推掉需求 很多产品在做每一期迭代开发需求的时候，会有无穷无尽的想法，而且恨不得都全部实现，最好今天就能给到。 大部分老实的程序员，会选择尽可能满足这些可爱的需求。这些永远没办法做完的需求，才是耗尽程序员心力的重要因素。 你需要给每个需求和变更排期，给需求留足buffer，确保线上出问题的时候你还有时间去处理。 让产品给这些需求排优先级，从高到低，算好每个需求的人日，做不了一定要提出来，剩下的让不同产品去pk优先级，确保你不过劳。 减少不必要的沟通很多不明真相的产品、运营、其他部门的开发会通过各种途径找到你，大部分时候他们找你都是为了向你询问一些无关痛痒的问题。 有些时候当他们询问的问题触及技术细节的时候，新人程序员都会想要试图产生程序实现原理细节。 请记住一句话，千万不要跟不是搞技术的人聊实现细节，如果可以，最好别跟任何人聊技术实现细节，不仅会把他们的思路带跑偏，还会越解释越迷糊。 另外还有一些人遇到一些疑问，会用企业微信或钉钉找到你，如果这个人说的事情不是紧急的事情，同时没有直接找到你面前，尽量选择过半小时后再处理。 你要相信他们自己解决问题的能力，大部分不重要或跟你关系不大的问题，会因为你的延缓处理自动消失。 大部分真正需要你解决的问题，半小时后还会再找你一次。 另外，哪怕不听音乐，带上耳机，可以减少10%的无效沟通，懂的自然懂。 提升办事效率 提升办事效率是为了减少自己无用时间的支出，从而不至于让自己没有时间在工作之余锻炼休闲。 提升效率这个事情其实比较简单。 选择适合自己的办公软件。比如印象笔记或有道云笔记来记录工作要点和备忘，用番茄学习时间来强迫自己专心写代码，同时还能装个眼睛护士定时提醒自己要放松一下眼睛。 另外我个人强烈建议大家多喝水。 另外推荐几个 VSCode 效率插件 1https://www.infoq.cn/article/c4wbmkc7sslz28gyazll mac 效率神器 1https://github.com/Louiszhai/tool 高级划水技能划水的最高技巧是提升技术水平，可以减少排查问题的时间，提升工作效率，更好的预估时间（意味着可以更精确地给自己多估两天排期）。 只有提升自身硬实力，才能打破这个死循环。 下面介绍一个golang程序员学习提升的项目,里面有超全的golang面试问题整理，用问题驱动去学习。 同时还有一张完整的入门进阶知识图谱，值得star一个啊。关于其他编程语言的学习路线，欢迎各位私信我学习地址。 1https://github.com/xiaobaiTech/golangFamily 学会管理自己的时间要学习时间管理，就要像这个领域里最顶尖的大师学习。 而这个领域里我只认罗老师，罗老师去年荣获时间管理大师称号。在业务能力上罗老师绝对是个优秀的好歌手好演员，各领域开花，忙是不可避免的，工作强度不会比程序员弱。在此基础上，还能做到宛如影分身之术一般时间管理能力，除了熬出两个黑眼圈外，身体却十分硬朗。仔细一想，罗老师是在承受着身体和心理都在长时间承受高强度的压力，但却不影响他身心健康。 我们可以好好分析一下，罗老师为什么能在硬朗这件事情上做的如此出类拔萃。个人拙见，有三点 热爱自己的事业 我们可以看下，罗老师的日程表。 这工作强度映射到程序员身上，也差不多跟连续开会写代码997差不多了吧，然而他却硬朗得很。 他到底是怎么做到的呢？一言以蔽之，热爱。解bug的过程可能是难受压抑紧张的，但是解bug成功带来的成就感真的很爽。 如果不热爱这份工作，那么成就感没了，只剩下难受和压抑了，不快乐的人，说不定哪天说没就没了。 锻炼身体他热爱跳舞，被称为“亚洲舞王”。虽然这个称呼有点夸张，但是他不是天赋型选手，跳舞能力是花时间练出来的。 而跳舞这件事情，和健身类似，让身体动起来了，出汗了，你自然就爽了。 大家应该都有一种感觉，运动，会让你出汗，会让身体巨酸巨累，但是这个过程中，会让心情变得畅快不压抑，还能让你因为敲代码而变得瘦弱的肱二头肌变得粗壮一些。 事业之外还有自己的爱好这个世界上只有一种真正的英雄主义，就是在认清生活的真相之后，还能热爱生活。 很多程序员在大学刚毕业的时候，都想着自己以后能做一个牛逼哄哄的软件，然后跟乔布斯一样改变这个世界，但是往往又在几年后选择成为一条咸鱼，每天疲惫于跟产品经理斗智斗勇，只要能砍掉哪怕一个需求，那也是一次重大胜利。 我们都只是普通人，产品经理没错，程序猿也没错，当一条咸鱼也挺香的，但是在工作中当咸鱼可以，唯唯诺诺可以，但下了班，你必须重拳出击。 你得有自己的爱好，可以是爬山旅游，篮球游泳。如果这些都太索然无味，你还可以去酒吧跟各种臭妹妹坏弟弟喝上一杯。 最后要每天看一遍凉凉的新闻，坚定自己划水的信念。 鲁迅曾经说过，划水最好的时候两个时间，一个是十年前，一个是现在。你懂我意思吧？ 没懂? 点个在看，你的每一次扩散都可能拯救一个累垮边缘的程序猿！","categories":[{"name":"骚话连篇","slug":"骚话连篇","permalink":"https://xiaobaidebug.top/categories/%E9%AA%9A%E8%AF%9D%E8%BF%9E%E7%AF%87/"}],"tags":[]},{"title":"硬核！漫画图解HTTP基础+面试题","slug":"图解网络/硬核！漫画图解HTTP知识点+面试题","date":"2021-02-25T14:57:55.000Z","updated":"2022-10-30T02:23:15.273Z","comments":true,"path":"2021/02/25/图解网络/硬核！漫画图解HTTP知识点+面试题/","link":"","permalink":"https://xiaobaidebug.top/2021/02/25/%E5%9B%BE%E8%A7%A3%E7%BD%91%E7%BB%9C/%E7%A1%AC%E6%A0%B8%EF%BC%81%E6%BC%AB%E7%94%BB%E5%9B%BE%E8%A7%A3HTTP%E7%9F%A5%E8%AF%86%E7%82%B9+%E9%9D%A2%E8%AF%95%E9%A2%98/","excerpt":"文章持续更新，可以微信搜一搜「小白debug」第一时间阅读，回复【教程】获golang免费视频教程。本文已经收录在GitHub https://github.com/xiaobaiTech/golangFamily , 有大厂面试完整考点和成长路线，欢迎Star。","text":"文章持续更新，可以微信搜一搜「小白debug」第一时间阅读，回复【教程】获golang免费视频教程。本文已经收录在GitHub https://github.com/xiaobaiTech/golangFamily , 有大厂面试完整考点和成长路线，欢迎Star。 什么是HTTPHTTP 全称超⽂文本传输协议，也就是HyperText Transfer Protocol。其中我们常见的文本，图片，视频这些东西都可以用超文本进行表示，而我常看的猫片，也属于超文本，所以大家不要再说我偷偷看猫片了，我只是在看超文本。HTTP只是定义了一套传输超文本的规则，只要符合了这一套规则，不管你是用iphone，还是用老爷机，都可以实现猫片的传输。 七层网络 大概了解了HTTP后，给大家看看它在它们家族里的地位。HTTP位于应用层，跟它类似的协议还有常见的FTP协议，常见的某影天堂的下载链接曾经经常是以FTP开头的。 HTTP报文格式 有点抽象？不知道小白说的啥？那实操一下，用wireshark抓包看一下猫片里的请求报文和响应报文具体长什么样子吧 请求报文1234567891011121314GET /cmaskboss/164203142_30_1.enhance.webmask HTTP/1.1Host: upos-sz-staticks3.bilivideo.comConnection: keep-aliveUser-Agent: Mozilla/5.0 (Macintosh; Intel Mac OS X 10_14_3) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/88.0.4324.150 Safari/537.36Accept: */*Origin: https://www.bilibili.comSec-Fetch-Site: cross-siteSec-Fetch-Mode: corsSec-Fetch-Dest: emptyReferer: https://www.bilibili.com/Accept-Encoding: identityAccept-Language: zh-CN,zh;q=0.9Range: bytes=0-16 这上面第一行的GET 就是请求方法，/cmaskboss/164203142_30_1.enhance.webmask 则是 URL , 而HTTP/1.1则是协议版本。接下来从Host开始到最后一行Range，都是Headers头。 响应报文1234567891011121314151617181920212223HTTP/1.1 206 Partial ContentContent-Type: application/octet-streamContent-Length: 17Connection: keep-aliveServer: TengineETag: &quot;92086de1e6d1d4791fb950a0ac7e30ba&quot;Date: Sat, 30 Jan 2021 09:31:31 GMTLast-Modified: Sun, 04 Oct 2020 01:54:28 GMTExpires: Mon, 01 Mar 2021 09:31:31 GMTAge: 1018695Content-Range: bytes 0-16/353225Accept-Ranges: bytesX-Application-Context: applicationx-kss-request-id: 75bcbfa8ab194e3c825e89c81a912692x-kss-BucketOwner: MjAwMDAyMDEwNw==X-Info-StorageClass: -Content-MD5: kght4ebR1HkfuVCgrH4wug==X-Cache-Status: HIT from KS-CLOUD-JH-MP-01-03X-Cache-Status: HIT from KS-CLOUD-TJ-UN-14-13X-Cache-Status: HIT from KS-CLOUD-LF-UN-11-25Access-Control-Allow-Origin: https://www.bilibili.comAccess-Control-Allow-Headers: Origin,X-Requested-With,Content-Type,Accept,rangeX-Cdn-Request-ID: 7e2c783ca7d392624118593ec1dc66bc 类似请求报文，HTTP/1.1是协议版本，206是状态码，Partial Content 则是状态描述符。接下来从Content-Type开始到最后一行X-Cdn-Request-ID都是Headers信息。 报文信息解读其实上面的抓包信息，在浏览器里按F12就能看到，之所以要用wireshark可能只是装X效果比较好吧。按下F12看到的响应数据就跟下图展示的那样。 1.请求数据 2.响应数据 3.Request URLURL是什么URL 代表着是统一资源定位符（Uniform Resource Locator）。作用是为了告诉使用者 某个资源在 Web 上的地址。这个资源可以是一个 HTML 页面，一个 CSS 文档，一幅图像或一个猫片等等。上面我们请求猫片的URL就是 https://upos-sz-staticks3.bilivideo.com/cmaskboss/164203142_30_1.enhance.webmask 这里面细分，又可以分为好几个部分。 协议部分 表示该URL的协议部分为http还是https，会用//为分隔符。上面的URL表示网页用的是HTTPS协议，而上面提到的X影天堂用的则是ftp协议的下载链接。 域名部分 域名是upos-sz-staticks3.bilivideo.com，在发送请求前，会向DNS服务器解析IP，如果已经知道ip，还可以跳过DNS解析那一步，直接把IP当做域名部分使用。 端口部分 域名后面有些时候会带有端口，和域名之间用:分隔，端口不是一个URL的必须的部分。当网址为http://时，默认端口为80 当网址为https://时，默认端口为443，以上两种都可以省略端口号。上面的URL其实省略了443端口号。 虚拟目录 从域名的第一个/开始到最后一个/为止，是虚拟目录的部分。虚拟目录也不是URL必须的部分，本例中的虚拟目录是/cmaskboss/ 文件名部分 从域名最后一个/开始到?为止，是文件名部分；如果没有?，则是从域名最后一个/开始到#为止，是文件名部分；如果没有?和#，那么就从域名的最后一个/从开始到结束，都是文件名部分。本例中的文件名是164203142_30_1.enhance.webmask，文件名也不是一个URL的必须部分。 URL 和 URI 的区别 URL:Uniform Resource Locator 统一资源定位符； URI: Uniform Resource Identifier 统一资源标识符； 其实一直有个误解，很多人以为URI是URL的子集，其实应该反过来。URL是URI的子集才对。简单解释下。假设”小白”(URI)是一种资源，而”在迪丽亦巴的怀里”表明了一个位置。如果你想要找到（locate）小白，那么你可以到”在迪丽亦巴怀里”找到小白，而”在迪丽亦巴怀里的/小白”才是我们常说的URL。而”在迪丽亦巴怀里的/小白”（URL）显然是”小白”（URI）的子集，毕竟，”小白”还可能是”在牛亦菲怀里的/小白”（其他URL）。 4.Request MethodHTTP 定义了一组请求方法，以表明要对给定资源执行的操作。指示针对给定资源要执行的期望动作.。虽然他们也可以是名词，但这些请求方法有时被称为HTTP动词.。每一个请求方法都实现了不同的语义。 这次请求猫片的请求里用的是GET，意味着获取。但其实HTTP定义了多种请求方法，来满足各种需求。除了Get，还有几个POST、HEAD、OPTIONS、PUT、DELETE、TRACE 和 CONNECT。 常见的各个请求方法的具体功能如下： GET请求指定的页面信息，并返回消息主体(body)+头信息(header)。 HEAD：HEAD和GET本质是一样的，区别在于HEAD只返回头信息(header)，不返回消息主体(body)。大家不要以为它没用，它跟GET和POST一样，在http/1.0的时候就存在了，实属三元老之一了。主要用途 如果想要判断某个资源是否存在，虽然用GET也能做到，但这里用HEAD还省下拿body的消耗，返回状态码200就是有404就是无 如果请求的是一个比较大的资源，比如一个超大视频和文件，你只想知道它到底有多大，而不需要整个下载下来，这时候使用HEAD请求，返回的headers会带有文件的大小（content-lenght）。 POST向服务器提交数据。这个方法用途广泛，几乎目前所有的提交操作都是靠这个完成。POST跟GET最常用，但最大的区别在于，POST每次调用都可能会修改数据，是非幂等的，而GET类似于只读，是幂等的。 PUT：这个方法比较少见。在HTTP规范中POST是非等幂的，多次调用会产生不同的结果。比如：创建一个用户,由于网络原因或是其他原因多创建了几次,那么将会有多个用户被创建。而PUT id/xiaobai 则会创建一个id为 xiaobai 的用户，多次调用还是会创建的结果是一样的，所以PUT是等幂的。但是一般为了避免造成心智负担，实战中也会使用POST替代PUT。 DELETE：删除某一个资源。基本上这个也很少见，一般实战中如果是删除操作，也是使用POST来替代。 OPTIONS：options是什么它用于获取当前URL所支持的方法。若请求成功，则它会在HTTP响应头部中带上给各种“Allow”的头，表明某个请求在对应的服务器中都支持哪种请求方法。比如下图： 这里面需要关注的点有两个 Request Header里的关键字段 Response Header里的关键字段 Options堪称是网络协议中的老实人，就好像老实人刚谈了个女朋友，每次牵手前都要问下人家 “我可以牵你的手吗？”， “我可以抱你吗？”，得到了答应后才会下手。差点被这老实人气质感动得留下了不争气的泪水。 什么时候需要使用options在跨域（记住这个词，待会解释）的情况下，浏览器发起复杂请求前会自动发起 options 请求。跨域共享标准规范要求，对那些可能对服务器数据产生副作用的 HTTP 请求方法（特别是 GET 以外的 HTTP 请求，或者搭配某些 MIME 类型的 POST 请求），浏览器必须首先使用 options 方法发起一个预检请求，从而获知服务端是否允许该跨域请求。服务器确认允许之后，才发起实际的 HTTP 请求。 这里提到了两个关键词： 跨域 复杂请求 什么是简单请求和复杂请求。某些请求不会触发 CORS 预检请求，这样的请求一般称为”简单请求”，而会触发预检的请求则为”复杂请求”。 1.简单请求 请求方法为GET、HEAD、POST 只有以下Headers字段 Accept Accept-Language Content-Language Content-Type DPR/Downlink/Save-Data/Viewport-Width/Width (这些不常见，放在一起) Content-Type 只有以下三种 application/x-www-form-urlencoded multipart/form-data text/plain 请求中的任意 XMLHttpRequestUpload 对象均没有注册任何事件监听器； 请求中没有使用 ReadableStream 对象。 2.复杂请求 不满足简单请求的，都是复杂请求 由此可见，因为上述请求在获取网上资源的请求Headers里带有 Access-Control-Request-Headers: range , 而range正好不在简单请求的条件2中提到的Headers范围里，因此属于复杂请求，于是触发预检options请求。 什么是跨域刚刚提到了一个词叫跨域，那什么是跨域呢？在了解跨域之前，首先要了解一个概念：同源。所谓同源是指，域名、协议、端口均相同。 不明白没关系，举个例子。 需要特别注意的是，localhost和127.0.0.1虽然都指向本机，但也不属于同源。 而非同源之间网页调用就是我们所说的跨域。在浏览器同源策略限制下，向不同源发送XHR请求，浏览器认为该请求不受信任，禁止请求，具体表现为请求后不正常响应。 options带来什么问题由此可见，复杂请求的条件其实非常容易满足，而一旦满足复杂请求的条件，则浏览器便会发送2次请求（一次预检options，一次复杂请求），这一次options就一来一回（一个RTT），显然会导致延迟和不必要的网络资源浪费，高并发情况下则可能为服务器带来严重的性能消耗。 如何优化options每次复杂请求前都会调用一次options，这其实非常没有必要。因为大部分时候相同的请求，短时间内获得的结果是不会变的，是否可以通过浏览器缓存省掉这一次查询？ Access-Control-Max-Age就是优化这个流程中使用的一个Header。它的作用是当你每次请求options方法时，服务端返回调用支持的方法（Access-Control-Allow-Methods ）和Headers（Access-Control-Allow-Headers）有哪些，同时告诉你，它在接下来 Access-Control-Max-Age时间（单位是秒）里都支持，则这段时间内，不再需要使用options进行请求。特别注意的是，当Access-Control-Max-Age的值为-1时，表示禁用缓存，每一次请求都需要发送预检请求，即用OPTIONS请求进行检测。 5.Status Code状态码是什么HTTP Status Code是常说的HTTP状态码。当用户访问一个网页时，浏览器会向网页所在服务器发出请求。服务器则会根据请求作出响应，而状态码则是响应的一部分，代表着本次请求的结果。所有状态码的第一个数字代表了响应的大概含义，组合上第二第三个数字则可以表示更具体的原因。如果请求失败了，通过这个状态码，大概初步判断出这次请求失败的原因。以下是五类状态码的含义。 状态码流程可以根据以下流程图了解下各类状态码间的关系。 2xx和3xx之间的流程关系 4xx的状态流程 5xx的状态流程 常见状态码介绍 200 OK 这是最常见的状态码。代表请求已成功，数据也正常返回。而请求猫片虽然响应成功了，但却不是200，而是206，是为什么呢，接下去继续看看。 206 Partial Content 这个状态码在上面请求的响应结果。服务器已经成功处理了部分 GET 请求。类似于看视频或者迅雷这类的 HTTP下载工具都是使用此类响应实现断点续传或者将一个大文档分解为多个下载段同时下载。 307 Temporary Redirect 内部重定向。重定向的意思是，当你输入一个网址的时候，浏览器会自动帮你跳转到另外一个网址上。比如，当你在浏览器输入框输入http://www.baidu.com/时。由于使用http并不安全，百度会自动帮你跳转到它对应的https网页上。而此时，需要重定向的地址，会通过Response Headers的Location返回 404 Not Found 请求失败，请求所希望得到的资源未被在服务器上发现。出现这个错误的最有可能的原因是服务器端没有这个页面，或者是Request Method与注册URL的Method不一致，比如我有一个URL在服务端注册的Request Method 为 POST，但调用的时候却错误用了GET，则也会出现404错误。 499 Client has closed connection 网络请求过程中，由于服务端处理时间过长，客户端超时。一般常见于，后端服务器处理时间过长，而客户端也设置了一个超时等待时间，客户端等得“不耐烦”了，主动关掉连接时报出。 502 Bad Gateway 服务器方面无法给予正常的响应。一般常见于服务器崩溃后，nginx 无法正常收到服务端的响应，给客户端返回502状态码。 504 Gateway Timeout 网络请求过程中，由于服务端处理时间过长，网关超时。一般常见于，后端服务器逻辑处理时间过长，甚至长于 nginx设置的最长等待时间时报错。它跟 499 状态码非常像，区别在于499 表示的是客户端超时，504是网关超时。如果是499超时，可以考虑修改客户端的代码调整超时时间，如果是504，则考虑调整nginx的超时配置。 6. HeadersContent-LengthContent-Length是HTTP的消息长度, 用十进制数字表示。Content-Length首部指出报文中消息的当前实际字节大小。如果消息文本进行了gzip压缩的话， Content-Length指的就是压缩后的大小而不是原始大小。 正常情况下Content-Length是不需要手动去设置的，大部分语言的网络库都会自动封装好，但是如果在一些特殊情况下，出现Content-Length与实际要发送的消息大小不一致，就会出现一些问题。 如果Content-Length &lt; 实际长度 下面启动一个HTTP服务器，所有语言都一样，示例里使用了golang。 12345678910111213141516171819202122232425262728package mainimport ( &quot;fmt&quot; &quot;io/ioutil&quot; &quot;log&quot; &quot;net/http&quot;)// w表示response对象，返回给客户端的内容都在对象里处理// r表示客户端请求对象，包含了请求头，请求参数等等func index(w http.ResponseWriter, r *http.Request) &#123; b, _ := ioutil.ReadAll(r.Body) fmt.Printf(&quot;request body=%#v, content_length=%v \\nheaders=%v&quot;,string(b), r.ContentLength, r.Header) // 往w里写入内容，就会在浏览器里输出 fmt.Fprintf(w, string(b))&#125;func main() &#123; // 设置路由，如果访问/，则调用index方法 http.HandleFunc(&quot;/&quot;, index) // 启动web服务，监听9090端口 err := http.ListenAndServe(&quot;:9999&quot;, nil) if err != nil &#123; log.Fatal(&quot;ListenAndServe: &quot;, err) &#125;&#125; 在控制台输入 12345$ $ curl -L -X POST &#x27;http://127.0.0.1:9999&#x27; -H &#x27;Content-Type: application/json&#x27; -H &#x27;Content-Length: 5&#x27; -d &#x27;1234567&#x27; | jq % Total % Received % Xferd Average Speed Time Time Time Current Dload Upload Total Spent Left Speed100 12 100 5 100 7 828 1160 --:--:-- --:--:-- --:--:-- 140012345 输入的body是 1234567，共7个数字，但是输入的 Content-Length为 5。到了服务器那，收到了 12345，共5个数字，数量上跟输入的Content-Length一致。 由此可见当Content-Length &lt; 实际长度， 消息会被截断。 如果Content-Length &gt; 实际长度 还是上面的服务端代码，但是控制台输入以下命令 1234$ curl -L -X POST &#x27;http://127.0.0.1:9999&#x27; -H &#x27;Content-Type: application/json&#x27; -H &#x27;Content-Length: 100&#x27; -d &#x27;1234567&#x27; | jq % Total % Received % Xferd Average Speed Time Time Time Current Dload Upload Total Spent Left Speed100 7 0 0 0 7 0 0 --:--:-- 0:01:19 --:--:-- 0 这次情况不太一样，会发现请求一直阻塞没有返回。这是因为输入的body是 1234567，共7个数字，但是输入的 Content-Length为 100。也就是服务端一直认为这次的body长度为100，但是目前只收到了部分消息（长度为7），剩余的长度为93的消息由于各种原因还在路上，因此选择傻傻等待剩下的消息，就造成了上面提到的阻塞。 Range 视频播放需要支持用户调整播放进度，支持让用户选择直接跳到中间部分开始播放。为了实现这个功能，需要通过HTTP Range Requests 协议用于指定需要获取视频片段。而 Request Header里的range头则是用于指定要请求文件的起始和结束位置。 如果服务器不支持，直接忽略 Range 头，浏览器会正常按流式加载整个视频文件，以状态码 200 响应即可。另外，当我们在 html 中放一个 video 标签，浏览器会直接发起一个 Range: bytes=0- 的请求，向服务器请求从开始到结尾的完整文件。 如果服务器支持 Range Requests，会读取视频文件，并将他的第 162653～242638 字节提取出来，响应码为 206，则浏览器会在接收到足够字节（比如当前播放进度往后推20s）时结束掉请求，以节省网络流量；当播放进度继续往前，缓存不够时，浏览器会发起一个新的 Range Requests 请求，请求的 Range 直接从缓存结尾的字节开始，只加载剩余的部分文件。同时返回的Response Headers中有一个 content-range 的字段域，用于告诉了客户端发送了多少数据。content-range 描述了响应覆盖的范围和整个实体长度。一般格式：Content-Range：开始字节位置-结束字节位置／文件大小（byte）。 Connection长连接和短连接 Connection: close 表示请求响应完成之后立即关闭连接，这是HTTP/1.0请求的默认值。每次请求都经过“创建tcp连接 -&gt; 请求资源 -&gt; 响应资源 -&gt; 释放连接”这样的过程 Connection: keep-alive 表示连接不立即关闭，可以继续响应下一个请求。HTTP/1.1的请求默认使用一个持久连接。可以做到只建立一次连接，多次资源请求都复用该连接，完成后关闭。流程上是 建立tcp连接 -&gt; 请求资源 -&gt; 响应资源 -&gt; … （保持连接）… -&gt; 第n次请求资源 -&gt; 第n次响应资源 -&gt; 释放连接。 在http1.1中Request Header和Reponse Header中都有可能出现一个Connection: keep-alive 头信息。Request Header里的Connection: keep-alive 头是为了告诉服务端，客户端想要以长连接形式进行通信。而Response Header里的Connection: keep-alive 头是服务端告诉客户端，我的服务器支持以长连接的方式进行通信。如果不能使用长连接，会返回 Connection: close ，相当于告诉客户端“我不支持长连接，你死了这条心，老老实实用短连接吧” 。 HTTP为什么要使用长连接我们知道 HTTP 建立在 TCP 传输层协议之上，而 TCP 的建立需要三次握手，关闭需要四次挥手，这些步骤都需要时间，带给 HTTP 的就是请求响应时延。如果使用短连接，那么每次数据传输都需要经历一次上面提到的几个步骤，如果能只连接一次，保持住这个连接不断开，期间通信就可以省下建立连接和断开连接的过程，对于提升HTTP性能有很大的帮助。 可以看到，在使用 Connection: close 通信时，每次都需要重新经历一次握手挥手。可以通过 Connection: keep-alive 省下这部分的资源消耗。 长连接可以省去较多的TCP建立和关闭的操作，减少浪费，节约时间。对于频繁请求资源的客户来说，较适用长连接。但是在长连接的应用场景下，需要有一方主动关闭连接。如果客户端和服务端之间的连接一直不关闭的话，连接数则会越来越多，严重的时候会造成资源占用过高。 解决方案也比较简单。如果这些连接其实长时间内并没有任何数据传输的话，那其实属于空闲连接，这时候可以在服务端设置空闲连接的存活时间，超过一定时间后由服务端主动断掉，从而保证无用连接及时释放。 CookiesCookies是什么 Cookie 是浏览器访问服务器后，服务器传给浏览器的一段数据。里面一般带有该浏览器的身份信息。 浏览器需要保存这段数据，不得轻易删除。 此后每次浏览器访问该服务器，都必须带上这段数据。服务器用使用这段数据确认浏览器身份信息。 Cookie的作用Cookie 一般有两个作用。 1.识别用户身份。 举个例子。用户 A 用浏览器访问了“猫猫网”，“猫猫网”的服务器就会立刻给 A 返回一段Cookie数据，内含「uid=a」。 当 A 再次访问“猫猫网”下的其他页面时，比如跳转到“猫猫交友评论”，就会附带上「uid=a」这段数据。 同理，用户 B 用浏览器访问“猫猫网” 时，就给 B 分配了一段Cookie数据，内含「uid=b」。B 之后访问“猫猫网”的时候，就会一直带上「uid=b」这段数据。 因此“猫猫网”的服务器通过Cookie数据就能区分 A 和 B 两个用户了。 2.持久化用户信息。 因为cookies的数据会被用户浏览器保存到本地下。因此可以利用这一特点保持一些简单的用户数据。 比如一些博客网站，可以通过cookies记录下用户的性别年龄等信息，以此进行一些个性化展示。 当然上面提到的都是一些比较粗糙的场景，是为了方便大家理解cookies的功能。实际使用cookies会非常谨慎。 Referrer Policy 和 Referrer Referrer是什么Referrer 是HTTP请求header的报文头，用于指明当前流量的来源参考页面，常被用于分析用户来源等信息。通过这个信息，我们可以知道访客是怎么来到当前页面的。比如在上面的请求截图里，可以看出我是使用https://www.bilibili.com/访问的视频资源。 Referrer Policy 是什么 Referrer 字段，会用来指定该请求是从哪个页面跳转页来的，里面的信息是浏览器填的。 而 Referrer Policy 则是用于控制Referrer信息传不传、传哪些信息、在什么时候传的策略。 为什么要这么麻烦呢？因为有些网站一些用户敏感信息，比如 sessionid 或是 token 放在地址栏里，如果当做Referrer字段全部传递的话，那第三方网站就会拿到这些信息，会有一定的安全隐患。所以就有了 Referrer Policy，用于过滤 Referrer 报头内容。 比如在上面的请求截图里，可以看出我是使用strict-origin-when-cross-origin策略，含义是跨域时将当前页面URL过滤掉参数及路径部分，仅将协议、域名和端口（如果有的话）当作 Referrer。否则 Referrer 还是传递当前页的全路径。同时当发生降级（比如从 https:// 跳转到 http:// ）时，不传递 Referrer 报头。 Cache-control什么是cache-controlcache-control，用于控制浏览器缓存。简而言之，当某人访问网站时，其浏览器将在本地保存某些资源，例如图像和网站数据。当该用户重新访问同一网站时，缓存控制设置的规则会确定该用户是否从本地缓存中加载这些资源，或者浏览器是否必须向服务器发送新资源的请求。 什么是浏览器缓存浏览器缓存是指浏览器本地保存网站资源，以便不必再次通过网络从服务器获取它们。例如，“猫猫网”的背景图像可以保存到本地缓存中，这样在用户第二次访问该页面时，该图像将从用户的本地文件加载，剩下网络获取资源的时间，页面加载速度就会更快。 但是浏览器也不会永远把这些网站资源放在本地，否则本地磁盘就会炸，所以会限定保存资源的时间，这叫生存时间（TTL）。如果 TTL 过期后用户请求缓存的资源，浏览器必须再次通过网络与服务器建立连接并重新下载这个资源。 常见的缓存控制策略 cache-control: private具有“private”指令的响应只能由客户端缓存，不能由中间代理（例如 CDN或代理）缓存。这些资源通常是包含私密数据的资源，例如显示用户个人信息的网站。 cache-control: public相反，“public”指令表示资源可以由任何缓存存储。 cache-control: no-store带有“no-store”指令的响应无法缓存到任何位置，也永不缓存。也就是说，用户每次请求此数据时，都必须将请求发送到源站服务器以获取新副本。此指令通常保留给包含极其敏感数据的资源，例如银行帐户信息。 cache-control: max-age此指令指定了生存时间，也就是资源在下载后可以缓存多少秒钟。例如，如果将最大期限设置为 1800，则首次从服务器请求资源后的 1800 秒（30 分钟）内，后续请求都会向用户提供该资源的缓存版本。如果 30 分钟后用户再次请求资源，则客户端需要向服务器重新请求该资源。 cache-control: no-cache 从网页截图里可以看出，使用的缓存控制指令是cache-control: no-cache。它表示，只有先检查资源没有更新版本后，才可使用所请求资源的缓存版本。那么问题来了，怎么判断资源是否有更新版本呢？这就需要 ETag。 ETag Etag是 Entity tag的缩写，是服务端的一个资源版本的令牌标识。在 HTTP 响应头中将其传送到客户端。每当资源更新时，此令牌会更新。 比如，浏览器第一次请求资源的时候，服务端返回了这个资源的ETag: &quot;095933fff2323351d3b495f2f879616f1762f752&quot;。 当浏览器再次请求这个资源的时候，浏览器会将If-None-Match: &quot;095933fff2323351d3b495f2f879616f1762f752&quot; 传输给服务端，服务端拿到该ETAG，对比资源是否发生变化。 如果资源未发生改变，则返回304HTTP状态码，不返回具体的资源。 否则表示资源已经更新，浏览器需要下载新版本以提供给用户。 此过程可确保用户始终获得资源的最新版本，并且无需进行不必要的下载。 最后看个猫片都能学到这么多硬核知识。接下来我打算去舞蹈区看看有没有适合你们的知识点。 我是小白，有空？一起在知识的海洋里呛水啊，懂我意思？ 参考资料- [1] 计算机网络自动向下 - [2] 极客时间-趣谈网络协议 - [3] 极客时间-透视HTTP - [4] 图解HTTP - [5] 漫画形象-小肥柴","categories":[{"name":"图解网络","slug":"图解网络","permalink":"https://xiaobaidebug.top/categories/%E5%9B%BE%E8%A7%A3%E7%BD%91%E7%BB%9C/"}],"tags":[]},{"title":"给大家丢脸了，用了三年golang，我还是没答对这道内存泄漏题。","slug":"golang面试题/给大家丢脸了，用了三年golang，我还是没答对这道内存泄漏题","date":"2020-11-12T14:57:55.000Z","updated":"2022-04-19T12:18:17.480Z","comments":true,"path":"2020/11/12/golang面试题/给大家丢脸了，用了三年golang，我还是没答对这道内存泄漏题/","link":"","permalink":"https://xiaobaidebug.top/2020/11/12/golang%E9%9D%A2%E8%AF%95%E9%A2%98/%E7%BB%99%E5%A4%A7%E5%AE%B6%E4%B8%A2%E8%84%B8%E4%BA%86%EF%BC%8C%E7%94%A8%E4%BA%86%E4%B8%89%E5%B9%B4golang%EF%BC%8C%E6%88%91%E8%BF%98%E6%98%AF%E6%B2%A1%E7%AD%94%E5%AF%B9%E8%BF%99%E9%81%93%E5%86%85%E5%AD%98%E6%B3%84%E6%BC%8F%E9%A2%98/","excerpt":"","text":"问题123456789101112131415161718package mainimport ( &quot;fmt&quot; &quot;io/ioutil&quot; &quot;net/http&quot; &quot;runtime&quot;)func main() &#123; num := 6 for index := 0; index &lt; num; index++ &#123; resp, _ := http.Get(&quot;https://www.baidu.com&quot;) _, _ = ioutil.ReadAll(resp.Body) &#125; fmt.Printf(&quot;此时goroutine个数= %d\\n&quot;, runtime.NumGoroutine())&#125; 上面这道题在不执行resp.Body.Close()的情况下，泄漏了吗？如果泄漏，泄漏了多少个goroutine? 怎么答 不进行resp.Body.Close()，泄漏是一定的。但是泄漏的goroutine个数就让我迷糊了。由于执行了6遍，每次泄漏一个读和写goroutine，就是12个goroutine，加上main函数本身也是一个goroutine，所以答案是13. 然而执行程序，发现答案是3，出入有点大，为什么呢？ 解释 我们直接看源码。golang 的 http 包。 1234567891011121314http.Get()-- DefaultClient.Get----func (c *Client) do(req *Request)------func send(ireq *Request, rt RoundTripper, deadline time.Time)-------- resp, didTimeout, err = send(req, c.transport(), deadline) // 以上代码在 go/1.12.7/libexec/src/net/http/client:174 func (c *Client) transport() RoundTripper &#123; if c.Transport != nil &#123; return c.Transport &#125; return DefaultTransport&#125; 说明 http.Get 默认使用 DefaultTransport 管理连接。DefaultTransport 是干嘛的呢？ 12// It establishes network connections as needed// and caches them for reuse by subsequent calls. DefaultTransport 的作用是根据需要建立网络连接并缓存它们以供后续调用重用。那么 DefaultTransport 什么时候会建立连接呢？接着上面的代码堆栈往下翻 1234567891011func send(ireq *Request, rt RoundTripper, deadline time.Time) --resp, err = rt.RoundTrip(req) // 以上代码在 go/1.12.7/libexec/src/net/http/client:250func (t *Transport) RoundTrip(req *http.Request)func (t *Transport) roundTrip(req *Request)func (t *Transport) getConn(treq *transportRequest, cm connectMethod)func (t *Transport) dialConn(ctx context.Context, cm connectMethod) (*persistConn, error) &#123; ... go pconn.readLoop() // 启动一个读goroutine go pconn.writeLoop() // 启动一个写goroutine return pconn, nil&#125; 一次建立连接，就会启动一个读goroutine和写goroutine。这就是为什么一次http.Get()会泄漏两个goroutine的来源。 泄漏的来源知道了，也知道是因为没有执行close 那为什么不执行 close 会泄漏呢？ 回到刚刚启动的读goroutine 的 readLoop() 代码里 12345678910111213141516171819202122232425262728293031func (pc *persistConn) readLoop() &#123; alive := true for alive &#123; ... // Before looping back to the top of this function and peeking on // the bufio.Reader, wait for the caller goroutine to finish // reading the response body. (or for cancelation or death) select &#123; case bodyEOF := &lt;-waitForBodyRead: pc.t.setReqCanceler(rc.req, nil) // before pc might return to idle pool alive = alive &amp;&amp; bodyEOF &amp;&amp; !pc.sawEOF &amp;&amp; pc.wroteRequest() &amp;&amp; tryPutIdleConn(trace) if bodyEOF &#123; eofc &lt;- struct&#123;&#125;&#123;&#125; &#125; case &lt;-rc.req.Cancel: alive = false pc.t.CancelRequest(rc.req) case &lt;-rc.req.Context().Done(): alive = false pc.t.cancelRequest(rc.req, rc.req.Context().Err()) case &lt;-pc.closech: alive = false &#125; ... &#125;&#125; 简单来说readLoop就是一个死循环，只要alive为true，goroutine就会一直存在 select 里是 goroutine 有可能退出的场景： body 被读取完毕或body关闭 request 主动 cancel request 的 context Done 状态 true 当前的 persistConn 关闭 其中第一个 body 被读取完或关闭这个 case: 12345alive = alive &amp;&amp; bodyEOF &amp;&amp; !pc.sawEOF &amp;&amp; pc.wroteRequest() &amp;&amp; tryPutIdleConn(trace) bodyEOF 来源于到一个通道 waitForBodyRead，这个字段的 true 和 false 直接决定了 alive 变量的值（alive=true那读goroutine继续活着，循环，否则退出goroutine）。 那么这个通道的值是从哪里过来的呢？12345678910111213141516171819202122// go/1.12.7/libexec/src/net/http/transport.go: 1758 body := &amp;bodyEOFSignal&#123; body: resp.Body, earlyCloseFn: func() error &#123; waitForBodyRead &lt;- false &lt;-eofc // will be closed by deferred call at the end of the function return nil &#125;, fn: func(err error) error &#123; isEOF := err == io.EOF waitForBodyRead &lt;- isEOF if isEOF &#123; &lt;-eofc // see comment above eofc declaration &#125; else if err != nil &#123; if cerr := pc.canceled(); cerr != nil &#123; return cerr &#125; &#125; return err &#125;, &#125; 如果执行 earlyCloseFn ，waitForBodyRead 通道输入的是 false，alive 也会是 false，那 readLoop() 这个 goroutine 就会退出。 如果执行 fn ，其中包括正常情况下 body 读完数据抛出 io.EOF 时的 case，waitForBodyRead 通道输入的是 true，那 alive 会是 true，那么 readLoop() 这个 goroutine 就不会退出，同时还顺便执行了 tryPutIdleConn(trace) 。 123456// tryPutIdleConn adds pconn to the list of idle persistent connections awaiting// a new request.// If pconn is no longer needed or not in a good state, tryPutIdleConn returns// an error explaining why it wasn&#x27;t registered.// tryPutIdleConn does not close pconn. Use putOrCloseIdleConn instead for that.func (t *Transport) tryPutIdleConn(pconn *persistConn) error tryPutIdleConn 将 pconn 添加到等待新请求的空闲持久连接列表中，也就是之前说的连接会复用。 那么问题又来了，什么时候会执行这个 fn 和 earlyCloseFn 呢？12345678910111213func (es *bodyEOFSignal) Close() error &#123; es.mu.Lock() defer es.mu.Unlock() if es.closed &#123; return nil &#125; es.closed = true if es.earlyCloseFn != nil &amp;&amp; es.rerr != io.EOF &#123; return es.earlyCloseFn() // 关闭时执行 earlyCloseFn &#125; err := es.body.Close() return es.condfn(err)&#125; 上面这个其实就是我们比较收悉的 resp.Body.Close() ,在里面会执行 earlyCloseFn，也就是此时 readLoop() 里的 waitForBodyRead 通道输入的是 false，alive 也会是 false，那 readLoop() 这个 goroutine 就会退出，goroutine 不会泄露。 1234567891011121314b, err = ioutil.ReadAll(resp.Body)--func ReadAll(r io.Reader) ----func readAll(r io.Reader, capacity int64) ------func (b *Buffer) ReadFrom(r io.Reader)// go/1.12.7/libexec/src/bytes/buffer.go:207func (b *Buffer) ReadFrom(r io.Reader) (n int64, err error) &#123; for &#123; ... m, e := r.Read(b.buf[i:cap(b.buf)]) // 看这里，是body在执行read方法 ... &#125;&#125; 这个read，其实就是 bodyEOFSignal 里的 1234567891011121314151617181920func (es *bodyEOFSignal) Read(p []byte) (n int, err error) &#123; ... n, err = es.body.Read(p) if err != nil &#123; ... // 这里会有一个io.EOF的报错，意思是读完了 err = es.condfn(err) &#125; return&#125;func (es *bodyEOFSignal) condfn(err error) error &#123; if es.fn == nil &#123; return err &#125; err = es.fn(err) // 这了执行了 fn es.fn = nil return err&#125; 上面这个其实就是我们比较收悉的读取 body 里的内容。 ioutil.ReadAll() ,在读完 body 的内容时会执行 fn，也就是此时 readLoop() 里的 waitForBodyRead 通道输入的是 true，alive 也会是 true，那 readLoop() 这个 goroutine 就不会退出，goroutine 会泄露，然后执行 tryPutIdleConn(trace) 把连接放回池子里复用。总结 所以结论呼之欲出了，虽然执行了 6 次循环，而且每次都没有执行 Body.Close() ,就是因为执行了ioutil.ReadAll()把内容都读出来了，连接得以复用，因此只泄漏了一个读goroutine和一个写goroutine，最后加上main goroutine，所以答案就是3个goroutine。 从另外一个角度说，正常情况下我们的代码都会执行 ioutil.ReadAll()，但如果此时忘了 resp.Body.Close()，确实会导致泄漏。但如果你调用的域名一直是同一个的话，那么只会泄漏一个 读goroutine 和一个写goroutine，这就是为什么代码明明不规范但却看不到明显内存泄漏的原因。 那么问题又来了，为什么上面要特意强调是同一个域名呢？改天，回头，以后有空再说吧。 文章推荐： 连nil切片和空切片一不一样都不清楚？那BAT面试官只好让你回去等通知了。 昨天那个在for循环里append元素的同事，今天还在么？ golang面试官：for select时，如果通道已经关闭会怎么样？如果只有一个case呢？ golang面试官：for select时，如果通道已经关闭会怎么样？如果只有一个case呢？ golang面试题：对已经关闭的的chan进行读写，会怎么样？为什么？ golang面试题：对未初始化的的chan进行读写，会怎么样？为什么？ golang 面试题：reflect（反射包）如何获取字段 tag？为什么 json 包不能导出私有变量的 tag？ golang面试题：json包变量不加tag会怎么样？ golang面试题：怎么避免内存逃逸？ golang面试题：简单聊聊内存逃逸？ golang面试题：字符串转成byte数组，会发生内存拷贝吗？ golang面试题：翻转含有中文、数字、英文字母的字符串 golang面试题：拷贝大切片一定比小切片代价大吗？ golang面试题：能说说uintptr和unsafe.Pointer的区别吗？ 如果你想每天学习一个知识点，关注我的【公】【众】【号】【小白debug】。","categories":[{"name":"golang面试题","slug":"golang面试题","permalink":"https://xiaobaidebug.top/categories/golang%E9%9D%A2%E8%AF%95%E9%A2%98/"}],"tags":[]},{"title":"连nil切片和空切片一不一样都不清楚？那BAT面试官只好让你回去等通知了。","slug":"golang面试题/连nil切片和空切片一不一样都不清楚？那BAT面试官只好让你回去等通知了。","date":"2020-10-12T14:57:55.000Z","updated":"2022-10-30T02:23:15.271Z","comments":true,"path":"2020/10/12/golang面试题/连nil切片和空切片一不一样都不清楚？那BAT面试官只好让你回去等通知了。/","link":"","permalink":"https://xiaobaidebug.top/2020/10/12/golang%E9%9D%A2%E8%AF%95%E9%A2%98/%E8%BF%9Enil%E5%88%87%E7%89%87%E5%92%8C%E7%A9%BA%E5%88%87%E7%89%87%E4%B8%80%E4%B8%8D%E4%B8%80%E6%A0%B7%E9%83%BD%E4%B8%8D%E6%B8%85%E6%A5%9A%EF%BC%9F%E9%82%A3BAT%E9%9D%A2%E8%AF%95%E5%AE%98%E5%8F%AA%E5%A5%BD%E8%AE%A9%E4%BD%A0%E5%9B%9E%E5%8E%BB%E7%AD%89%E9%80%9A%E7%9F%A5%E4%BA%86%E3%80%82/","excerpt":"","text":"问题123456789101112131415161718package mainimport ( &quot;fmt&quot; &quot;reflect&quot; &quot;unsafe&quot;)func main() &#123; var s1 []int // nil切片 s2 := make([]int,0) // 空切片 s4 := make([]int,0) // 空切片 fmt.Printf(&quot;s1 pointer:%+v, s2 pointer:%+v, s4 pointer:%+v, \\n&quot;, *(*reflect.SliceHeader)(unsafe.Pointer(&amp;s1)),*(*reflect.SliceHeader)(unsafe.Pointer(&amp;s2)),*(*reflect.SliceHeader)(unsafe.Pointer(&amp;s4))) fmt.Printf(&quot;%v\\n&quot;, (*(*reflect.SliceHeader)(unsafe.Pointer(&amp;s1))).Data==(*(*reflect.SliceHeader)(unsafe.Pointer(&amp;s2))).Data) fmt.Printf(&quot;%v\\n&quot;, (*(*reflect.SliceHeader)(unsafe.Pointer(&amp;s2))).Data==(*(*reflect.SliceHeader)(unsafe.Pointer(&amp;s4))).Data)&#125; nil切片和空切片指向的地址一样吗？这个代码会输出什么？ 怎么答 nil切片和空切片指向的地址不一样。nil空切片引用数组指针地址为0（无指向任何实际地址） 空切片的引用数组指针地址是有的，且固定为一个值 123s1 pointer:&#123;Data:0 Len:0 Cap:0&#125;, s2 pointer:&#123;Data:824634207952 Len:0 Cap:0&#125;, s4 pointer:&#123;Data:824634207952 Len:0 Cap:0&#125;, false //nil切片和空切片指向的数组地址不一样true //两个空切片指向的数组地址是一样的，都是824634207952 解释 之前在前面的文章里提到过切片的数据结构为 12345type SliceHeader struct &#123; Data uintptr //引用数组指针地址 Len int // 切片的目前使用长度 Cap int // 切片的容量&#125; nil切片和空切片最大的区别在于指向的数组引用地址是不一样的。 所有的空切片指向的数组引用地址都是一样的 文章推荐： 昨天那个在for循环里append元素的同事，今天还在么？ 对已经关闭的的 chan 进行读写，会怎么样？为什么？ 对未初始化的的chan进行读写，会怎么样？为什么？ golang 面试题：reflect（反射包）如何获取字段 tag？为什么 json 包不能导出私有变量的 tag？ golang面试题：json包变量不加tag会怎么样？ golang面试题：怎么避免内存逃逸？？ golang面试题：简单聊聊内存逃逸？ golang面试题：字符串转成byte数组，会发生内存拷贝吗？ golang面试题：翻转含有中文、数字、英文字母的字符串 golang面试题：拷贝大切片一定比小切片代价大吗？ golang面试题：能说说uintptr和unsafe.Pointer的区别吗？ 如果你想每天学习一个知识点，关注我的【公】【众】【号】【小白debug】。","categories":[{"name":"golang面试题","slug":"golang面试题","permalink":"https://xiaobaidebug.top/categories/golang%E9%9D%A2%E8%AF%95%E9%A2%98/"}],"tags":[]},{"title":"昨天那个在for循环里append元素的同事，今天还在么？","slug":"golang面试题/昨天那个在for循环里append元素的同事，今天还在么？","date":"2020-09-12T14:57:55.000Z","updated":"2022-04-19T12:18:17.480Z","comments":true,"path":"2020/09/12/golang面试题/昨天那个在for循环里append元素的同事，今天还在么？/","link":"","permalink":"https://xiaobaidebug.top/2020/09/12/golang%E9%9D%A2%E8%AF%95%E9%A2%98/%E6%98%A8%E5%A4%A9%E9%82%A3%E4%B8%AA%E5%9C%A8for%E5%BE%AA%E7%8E%AF%E9%87%8Cappend%E5%85%83%E7%B4%A0%E7%9A%84%E5%90%8C%E4%BA%8B%EF%BC%8C%E4%BB%8A%E5%A4%A9%E8%BF%98%E5%9C%A8%E4%B9%88%EF%BC%9F/","excerpt":"","text":"问题1234567891011package mainimport &quot;fmt&quot;func main() &#123; s := []int&#123;1,2,3,4,5&#125; for _, v:=range s &#123; s =append(s, v) fmt.Printf(&quot;len(s)=%v\\n&quot;,len(s)) &#125;&#125; 这个代码会造成死循环吗？ 怎么答 不会死循环，for range其实是golang的语法糖，在循环开始前会获取切片的长度 len(切片)，然后再执行len(切片)次数的循环。 解释 for range的源码是123456789// The loop we generate:// for_temp := range// len_temp := len(for_temp)// for index_temp = 0; index_temp &lt; len_temp; index_temp++ &#123;// value_temp = for_temp[index_temp]// index = index_temp// value = value_temp// original body// &#125; 上面的代码会被编译器认为是 12345678910111213func main() &#123; s := []int&#123;1,2,3,4,5&#125; for_temp := s len_temp := len(for_temp) for index_temp := 0; index_temp &lt; len_temp; index_temp++ &#123; value_temp := for_temp[index_temp] _ = index_temp value := value_temp // 以下是 original body s =append(s, value) fmt.Printf(&quot;len(s)=%v\\n&quot;,len(s)) &#125;&#125; 代码运行输出12345len(s)=6len(s)=7len(s)=8len(s)=9len(s)=10 所以说，那个同事用的是golang吗？ 文章推荐： golang面试官：for select时，如果通道已经关闭会怎么样？如果只有一个case呢？ golang面试题：对已经关闭的的chan进行读写，会怎么样？为什么？ golang面试题：对未初始化的的chan进行读写，会怎么样？为什么？ golang 面试题：reflect（反射包）如何获取字段 tag？为什么 json 包不能导出私有变量的 tag？ golang面试题：json包变量不加tag会怎么样？ golang面试题：怎么避免内存逃逸？ golang面试题：简单聊聊内存逃逸？ golang面试题：字符串转成byte数组，会发生内存拷贝吗？ golang面试题：翻转含有中文、数字、英文字母的字符串 golang面试题：拷贝大切片一定比小切片代价大吗？ golang面试题：能说说uintptr和unsafe.Pointer的区别吗？ 如果你想每天学习一个知识点？","categories":[{"name":"golang面试题","slug":"golang面试题","permalink":"https://xiaobaidebug.top/categories/golang%E9%9D%A2%E8%AF%95%E9%A2%98/"}],"tags":[]},{"title":"怎么避免内存逃逸？","slug":"golang面试题/能说说uintptr和unsafe.Pointer的区别吗","date":"2020-09-12T14:57:55.000Z","updated":"2022-10-30T02:25:54.027Z","comments":true,"path":"2020/09/12/golang面试题/能说说uintptr和unsafe.Pointer的区别吗/","link":"","permalink":"https://xiaobaidebug.top/2020/09/12/golang%E9%9D%A2%E8%AF%95%E9%A2%98/%E8%83%BD%E8%AF%B4%E8%AF%B4uintptr%E5%92%8Cunsafe.Pointer%E7%9A%84%E5%8C%BA%E5%88%AB%E5%90%97/","excerpt":"","text":"问题怎么避免内存逃逸？ 怎么答在runtime/stubs.go:133有个函数叫noescape。noescape可以在逃逸分析中隐藏一个指针。让这个指针在逃逸分析中不会被检测为逃逸。 12345678910 // noescape hides a pointer from escape analysis. noescape is // the identity function but escape analysis doesn&#x27;t think the // output depends on the input. noescape is inlined and currently // compiles down to zero instructions. // USE CAREFULLY! //go:nosplit func noescape(p unsafe.Pointer) unsafe.Pointer &#123; x := uintptr(p) return unsafe.Pointer(x ^ 0)&#125; 举例 通过一个例子加深理解，接下来尝试下怎么通过 go build -gcflags=-m 查看逃逸的情况。1234567891011121314151617181920212223242526272829303132333435package mainimport ( &quot;unsafe&quot;)type A struct &#123; S *string&#125;func (f *A) String() string &#123; return *f.S&#125;type ATrick struct &#123; S unsafe.Pointer&#125;func (f *ATrick) String() string &#123; return *(*string)(f.S)&#125;func NewA(s string) A &#123; return A&#123;S: &amp;s&#125;&#125;func NewATrick(s string) ATrick &#123; return ATrick&#123;S: noescape(unsafe.Pointer(&amp;s))&#125;&#125;func noescape(p unsafe.Pointer) unsafe.Pointer &#123; x := uintptr(p) return unsafe.Pointer(x ^ 0)&#125;func main() &#123; s := &quot;hello&quot; f1 := NewA(s) f2 := NewATrick(s) s1 := f1.String() s2 := f2.String() _ = s1 + s2&#125; 执行go build -gcflags=-m main.go 123456789101112131415161718192021222324252627$go build -gcflags=-m main.go# command-line-arguments./main.go:11:6: can inline (*A).String./main.go:19:6: can inline (*ATrick).String./main.go:23:6: can inline NewA./main.go:31:6: can inline noescape./main.go:27:6: can inline NewATrick./main.go:28:29: inlining call to noescape./main.go:36:6: can inline main./main.go:38:14: inlining call to NewA./main.go:39:19: inlining call to NewATrick./main.go:39:19: inlining call to noescape./main.go:40:17: inlining call to (*A).String./main.go:41:17: inlining call to (*ATrick).String/var/folders/45/qx9lfw2s2zzgvhzg3mtzkwzc0000gn/T/go-build763863171/b001/_gomod_.go:6:6: can inline init.0./main.go:11:7: leaking param: f to result ~r0 level=2./main.go:19:7: leaking param: f to result ~r0 level=2./main.go:24:16: &amp;s escapes to heap./main.go:23:13: moved to heap: s./main.go:27:18: NewATrick s does not escape./main.go:28:45: NewATrick &amp;s does not escape./main.go:31:15: noescape p does not escape./main.go:38:14: main &amp;s does not escape./main.go:39:19: main &amp;s does not escape./main.go:40:10: main f1 does not escape./main.go:41:10: main f2 does not escape./main.go:42:9: main s1 + s2 does not escape 其中主要看中间一小段 1234./main.go:24:16: &amp;s escapes to heap //这个是NewA中的，逃逸了./main.go:23:13: moved to heap: s./main.go:27:18: NewATrick s does not escape // NewATrick里的s的却没逃逸./main.go:28:45: NewATrick &amp;s does not escape 解释 上段代码对A和ATrick同样的功能有两种实现：他们包含一个 string ，然后用 String() 方法返回这个字符串。但是从逃逸分析看ATrick 版本没有逃逸。 noescape() 函数的作用是遮蔽输入和输出的依赖关系。使编译器不认为 p 会通过 x 逃逸， 因为 uintptr() 产生的引用是编译器无法理解的。 内置的 uintptr 类型是一个真正的指针类型，但是在编译器层面，它只是一个存储一个 指针地址 的 int 类型。代码的最后一行返回 unsafe.Pointer 也是一个 int。 noescape() 在 runtime 包中使用 unsafe.Pointer 的地方被大量使用。如果作者清楚被 unsafe.Pointer 引用的数据肯定不会被逃逸，但编译器却不知道的情况下，这是很有用的。 面试中秀一秀是可以的，如果在实际项目中如果使用这种unsafe包大概率会被同事打死。不建议使用！ 毕竟包的名字就叫做 unsafe, 而且源码中的注释也写明了 USE CAREFULLY! 。 文章推荐： golang面试题：简单聊聊内存逃逸？ golang面试题：字符串转成byte数组，会发生内存拷贝吗？ golang面试题：翻转含有中文、数字、英文字母的字符串 golang面试题：拷贝大切片一定比小切片代价大吗？ golang面试题：能说说uintptr和unsafe.Pointer的区别吗？ 关注公众号:【小白debug】","categories":[{"name":"golang面试题","slug":"golang面试题","permalink":"https://xiaobaidebug.top/categories/golang%E9%9D%A2%E8%AF%95%E9%A2%98/"}],"tags":[]},{"title":"golang面试官：for select时，如果通道已经关闭会怎么样？如果select中只有一个case呢？","slug":"golang面试题/for select时，如果通道已经关闭会怎么样？如果只有一个case呢？","date":"2020-08-11T14:57:55.000Z","updated":"2022-04-19T12:18:17.478Z","comments":true,"path":"2020/08/11/golang面试题/for select时，如果通道已经关闭会怎么样？如果只有一个case呢？/","link":"","permalink":"https://xiaobaidebug.top/2020/08/11/golang%E9%9D%A2%E8%AF%95%E9%A2%98/for%20select%E6%97%B6%EF%BC%8C%E5%A6%82%E6%9E%9C%E9%80%9A%E9%81%93%E5%B7%B2%E7%BB%8F%E5%85%B3%E9%97%AD%E4%BC%9A%E6%80%8E%E4%B9%88%E6%A0%B7%EF%BC%9F%E5%A6%82%E6%9E%9C%E5%8F%AA%E6%9C%89%E4%B8%80%E4%B8%AAcase%E5%91%A2%EF%BC%9F/","excerpt":"","text":"问题for循环select时，如果通道已经关闭会怎么样？如果select中的case只有一个，又会怎么样？ 怎么答 for循环select时，如果其中一个case通道已经关闭，则每次都会执行到这个case。 如果select里边只有一个case，而这个case被关闭了，则会出现死循环。 解释1.for循环里被关闭的通道 c通道是一个缓冲为0的通道，在main开始时，启动一个协程对c通道写入10，然后就关闭掉这个通道。 在main中通过 x, ok := &lt;-c 接受通道c里的值，从输出结果里看出，确实从通道里读出了之前塞入通道的10，但是在通道关闭后，这个通道一直能读出内容。 2.怎么样才能不读关闭后通道 x, ok := &lt;-c 返回的值里第一个x是通道内的值，ok是指通道是否关闭，当通道被关闭后，ok则返回false，因此可以根据这个进行操作。读一个已经关闭的通道为什么会出现false，可以看我之前的 对已经关闭的的chan进行读写，会怎么样？为什么？ 。 当返回的ok为false时，执行c = nil 将通道置为nil，相当于读一个未初始化的通道，则会一直阻塞。至于为什么读一个未初始化的通道会出现阻塞，可以看我的另一篇 对未初始化的的chan进行读写，会怎么样？为什么？ 。select中如果任意某个通道有值可读时，它就会被执行，其他被忽略。则select会跳过这个阻塞case，可以解决不断读已关闭通道的问题。 3.如果select里只有一个已经关闭的case，会怎么样？ 可以看出只有一个case的情况下，则会死循环。 那如果像上面一个case那样，把通道置为nil就能解决问题了吗？ 4.select里只有一个已经关闭的case，置为nil，会怎么样？ 第一次读取case能读到通道里的10 第二次读取case能读到通道已经关闭的信息。此时将通道置为nil 第三次读取case时main协程会被阻塞，此时整个进程没有其他活动的协程了，进程deadlock 总结 select中如果任意某个通道有值可读时，它就会被执行，其他被忽略。 如果没有default字句，select将有可能阻塞，直到某个通道有值可以运行，所以select里最好有一个default，否则将有一直阻塞的风险。 文章推荐： golang面试题：对已经关闭的的chan进行读写，会怎么样？为什么？ golang面试题：对未初始化的的chan进行读写，会怎么样？为什么？ golang 面试题：​reflect（反射包）如何获取字段 tag​？为什么 json 包不能导出私有变量的 tag？ golang面试题：json包变量不加tag会怎么样？ golang面试题：怎么避免内存逃逸？ golang面试题：简单聊聊内存逃逸？ golang面试题：字符串转成byte数组，会发生内存拷贝吗？ golang面试题：翻转含有中文、数字、英文字母的字符串 golang面试题：拷贝大切片一定比小切片代价大吗？ golang面试题：能说说uintptr和unsafe.Pointer的区别吗？ 如果你想每天学习一个知识点？","categories":[{"name":"golang面试题","slug":"golang面试题","permalink":"https://xiaobaidebug.top/categories/golang%E9%9D%A2%E8%AF%95%E9%A2%98/"}],"tags":[]},{"title":"golang 面试题：reflect（反射包）如何获取字段 tag？为什么 json 包不能导出私有变量的 tag？","slug":"golang面试题/golang 面试题：reflect（反射包）如何获取字段 tag？为什么 json 包不能导出私有变量的 tag？","date":"2020-07-11T14:57:55.000Z","updated":"2022-06-03T14:11:08.442Z","comments":true,"path":"2020/07/11/golang面试题/golang 面试题：reflect（反射包）如何获取字段 tag？为什么 json 包不能导出私有变量的 tag？/","link":"","permalink":"https://xiaobaidebug.top/2020/07/11/golang%E9%9D%A2%E8%AF%95%E9%A2%98/golang%20%E9%9D%A2%E8%AF%95%E9%A2%98%EF%BC%9Areflect%EF%BC%88%E5%8F%8D%E5%B0%84%E5%8C%85%EF%BC%89%E5%A6%82%E4%BD%95%E8%8E%B7%E5%8F%96%E5%AD%97%E6%AE%B5%20tag%EF%BC%9F%E4%B8%BA%E4%BB%80%E4%B9%88%20json%20%E5%8C%85%E4%B8%8D%E8%83%BD%E5%AF%BC%E5%87%BA%E7%A7%81%E6%9C%89%E5%8F%98%E9%87%8F%E7%9A%84%20tag%EF%BC%9F/","excerpt":"","text":"问题json包里使用的时候，会结构体里的字段边上加tag，有没有什么办法可以获取到这个tag的内容呢？ 举例tag信息可以通过反射（reflect包）内的方法获取，通过一个例子加深理解。 123456789101112131415161718192021222324252627282930package mainimport ( &quot;fmt&quot; &quot;reflect&quot;)type J struct &#123; a string //小写无tag b string `json:&quot;B&quot;` //小写+tag C string //大写无tag D string `json:&quot;DD&quot; otherTag:&quot;good&quot;` //大写+tag&#125;func printTag(stru interface&#123;&#125;) &#123; t := reflect.TypeOf(stru).Elem() for i := 0; i &lt; t.NumField(); i++ &#123; fmt.Printf(&quot;结构体内第%v个字段 %v 对应的json tag是 %v , 还有otherTag？ = %v \\n&quot;, i+1, t.Field(i).Name, t.Field(i).Tag.Get(&quot;json&quot;), t.Field(i).Tag.Get(&quot;otherTag&quot;)) &#125;&#125;func main() &#123; j := J&#123; a: &quot;1&quot;, b: &quot;2&quot;, C: &quot;3&quot;, D: &quot;4&quot;, &#125; printTag(&amp;j)&#125; 输出 1234结构体内第1个字段 a 对应的json tag是 , 还有otherTag？ = 结构体内第2个字段 b 对应的json tag是 B , 还有otherTag？ = 结构体内第3个字段 C 对应的json tag是 , 还有otherTag？ = 结构体内第4个字段 D 对应的json tag是 DD , 还有otherTag？ = good 解释 printTag方法传入的是j的指针。 reflect.TypeOf(stru).Elem()获取指针指向的值对应的结构体内容。 NumField()可以获得该结构体含有几个字段。 遍历结构体内的字段，通过t.Field(i).Tag.Get(&quot;json&quot;)可以获取到tag为json的字段。 如果结构体的字段有多个tag，比如叫otherTag,同样可以通过t.Field(i).Tag.Get(&quot;otherTag&quot;)获得。 再补一句上篇文章 提到json包不能导出私有变量的tag是因为取不到反射信息的说法，但是直接取t.Field(i).Tag.Get(&quot;json&quot;)却可以获取到私有变量的json字段，是为什么呢？ 其实准确的说法是，json包里不能导出私有变量的tag是因为json包里认为私有变量为不可导出的Unexported，所以跳过获取名为json的tag的内容。具体可以看/src/encoding/json/encode.go:1070的代码。 1234567891011121314151617func typeFields(t reflect.Type) []field &#123; // 注释掉其他逻辑... // 遍历结构体内的每个字段 for i := 0; i &lt; f.typ.NumField(); i++ &#123; sf := f.typ.Field(i) isUnexported := sf.PkgPath != &quot;&quot; // 注释掉其他逻辑... if isUnexported &#123; // 如果是不可导出的变量则跳过 continue &#125; // 如果是可导出的变量（public），则获取其json字段 tag := sf.Tag.Get(&quot;json&quot;) // 注释掉其他逻辑... &#125; // 注释掉其他逻辑... &#125;","categories":[{"name":"golang面试题","slug":"golang面试题","permalink":"https://xiaobaidebug.top/categories/golang%E9%9D%A2%E8%AF%95%E9%A2%98/"}],"tags":[]},{"title":"golang面试题：对已经关闭的的chan进行读写，会怎么样？为什么？","slug":"golang面试题/golang面试题：对已经关闭的的chan进行读写，会怎么样？为什么？","date":"2020-06-11T14:57:55.000Z","updated":"2022-04-19T12:18:17.478Z","comments":true,"path":"2020/06/11/golang面试题/golang面试题：对已经关闭的的chan进行读写，会怎么样？为什么？/","link":"","permalink":"https://xiaobaidebug.top/2020/06/11/golang%E9%9D%A2%E8%AF%95%E9%A2%98/golang%E9%9D%A2%E8%AF%95%E9%A2%98%EF%BC%9A%E5%AF%B9%E5%B7%B2%E7%BB%8F%E5%85%B3%E9%97%AD%E7%9A%84%E7%9A%84chan%E8%BF%9B%E8%A1%8C%E8%AF%BB%E5%86%99%EF%BC%8C%E4%BC%9A%E6%80%8E%E4%B9%88%E6%A0%B7%EF%BC%9F%E4%B8%BA%E4%BB%80%E4%B9%88%EF%BC%9F/","excerpt":"","text":"问题对已经关闭的的chan进行读写，会怎么样？为什么？ 怎么答 读已经关闭的chan能一直读到东西，但是读到的内容根据通道内关闭前是否有元素而不同。 如果chan关闭前，buffer内有元素还未读,会正确读到chan内的值，且返回的第二个bool值（是否读成功）为true。 如果chan关闭前，buffer内有元素已经被读完，chan内无值，接下来所有接收的值都会非阻塞直接成功，返回 channel 元素的零值，但是第二个bool值一直为false。 写已经关闭的chan会panic 举例1.写已经关闭的chan 注意这个send on closed channel，待会会提到。 2.读已经关闭的chan 多问一句1.为什么写已经关闭的chan就会panic呢？ 当c.closed != 0则为通道关闭，此时执行写，源码提示直接panic，输出的内容就是上面提到的&quot;send on closed channel&quot;。 2. 为什么读已关闭的chan会一直能读到值？ c.closed != 0 &amp;&amp; c.qcount == 0指通道已经关闭，且缓存为空的情况下（已经读完了之前写到通道里的值） 如果接收值的地址ep不为空 那接收值将获得是一个该类型的零值 typedmemclr 会根据类型清理相应地址的内存 这就解释了上面代码为什么关闭的chan会返回对应类型的零值 文章推荐： 对未初始化的的chan进行读写，会怎么样？为什么？ golang 面试题：​reflect（反射包）如何获取字段 tag​？为什么 json 包不能导出私有变量的 tag？ golang面试题：json包变量不加tag会怎么样？ golang面试题：怎么避免内存逃逸？ golang面试题：简单聊聊内存逃逸？ golang面试题：字符串转成byte数组，会发生内存拷贝吗？ golang面试题：翻转含有中文、数字、英文字母的字符串 golang面试题：拷贝大切片一定比小切片代价大吗？ golang面试题：能说说uintptr和unsafe.Pointer的区别吗？ 如果你想每天学习一个知识点？","categories":[{"name":"golang面试题","slug":"golang面试题","permalink":"https://xiaobaidebug.top/categories/golang%E9%9D%A2%E8%AF%95%E9%A2%98/"}],"tags":[]},{"title":"golang面试题：对未初始化的的chan进行读写，会怎么样？为什么？","slug":"golang面试题/golang面试题：对未初始化的的chan进行读写，会怎么样？为什么？","date":"2020-06-11T14:57:55.000Z","updated":"2022-04-19T12:18:17.478Z","comments":true,"path":"2020/06/11/golang面试题/golang面试题：对未初始化的的chan进行读写，会怎么样？为什么？/","link":"","permalink":"https://xiaobaidebug.top/2020/06/11/golang%E9%9D%A2%E8%AF%95%E9%A2%98/golang%E9%9D%A2%E8%AF%95%E9%A2%98%EF%BC%9A%E5%AF%B9%E6%9C%AA%E5%88%9D%E5%A7%8B%E5%8C%96%E7%9A%84%E7%9A%84chan%E8%BF%9B%E8%A1%8C%E8%AF%BB%E5%86%99%EF%BC%8C%E4%BC%9A%E6%80%8E%E4%B9%88%E6%A0%B7%EF%BC%9F%E4%B8%BA%E4%BB%80%E4%B9%88%EF%BC%9F/","excerpt":"","text":"问题对未初始化的的chan进行读写，会怎么样？为什么？ 怎么答读写未初始化的chan都会阻塞。 举例1.写未初始化的chan123456package main// 写未初始化的chanfunc main() &#123; var c chan int c &lt;- 1&#125; 123456// 输出结果fatal error: all goroutines are asleep - deadlock!goroutine 1 [chan send (nil chan)]:main.main() /Users/admin18/go/src/repos/main.go:6 +0x36 注意这个chan send (nil chan)，待会会提到。 2.写读未初始化的chan12345678package mainimport &quot;fmt&quot;// 读未初始化的chanfunc main() &#123; var c chan int num, ok := &lt;-c fmt.Printf(&quot;读chan的协程结束, num=%v, ok=%v\\n&quot;, num, ok)&#125; 123456// 输出结果fatal error: all goroutines are asleep - deadlock!goroutine 1 [chan receive (nil chan)]:main.main() /Users/admin18/go/src/repos/main.go:6 +0x46 注意这个chan receive (nil chan)，待会也会提到。 多问一句关于chan的面试题非常多，这个是比较常见的其中一个。但多问一句：为什么对未初始化的chan就会阻塞呢？ 1.对于写的情况 123456789101112//在 src/runtime/chan.go中func chansend(c *hchan, ep unsafe.Pointer, block bool, callerpc uintptr) bool &#123; if c == nil &#123; // 不能阻塞，直接返回 false，表示未发送成功 if !block &#123; return false &#125; gopark(nil, nil, waitReasonChanSendNilChan, traceEvGoStop, 2) throw(&quot;unreachable&quot;) &#125; // 省略其他逻辑&#125; 未初始化的chan此时是等于nil，当它不能阻塞的情况下，直接返回 false，表示写 chan 失败 当chan能阻塞的情况下，则直接阻塞 gopark(nil, nil, waitReasonChanSendNilChan, traceEvGoStop, 2) , 然后调用throw(s string)抛出错误,其中waitReasonChanSendNilChan就是刚刚提到的报错&quot;chan send (nil chan)&quot; 2. 对于读的情况 123456789101112//在 src/runtime/chan.go中func chanrecv(c *hchan, ep unsafe.Pointer, block bool) (selected, received bool) &#123; //省略逻辑... if c == nil &#123; if !block &#123; return &#125; gopark(nil, nil, waitReasonChanReceiveNilChan, traceEvGoStop, 2) throw(&quot;unreachable&quot;) &#125; //省略逻辑...&#125; 未初始化的chan此时是等于nil，当它不能阻塞的情况下，直接返回 false，表示读 chan 失败 当chan能阻塞的情况下，则直接阻塞 gopark(nil, nil, waitReasonChanReceiveNilChan, traceEvGoStop, 2) , 然后调用throw(s string)抛出错误,其中waitReasonChanReceiveNilChan就是刚刚提到的报错&quot;chan receive (nil chan)&quot;","categories":[{"name":"golang面试题","slug":"golang面试题","permalink":"https://xiaobaidebug.top/categories/golang%E9%9D%A2%E8%AF%95%E9%A2%98/"}],"tags":[]},{"title":"golang面试题：json包变量不加tag会怎么样？","slug":"golang面试题/golang面试题：json包变量不加tag会怎么样？","date":"2020-05-18T14:57:55.000Z","updated":"2022-10-30T02:25:54.158Z","comments":true,"path":"2020/05/18/golang面试题/golang面试题：json包变量不加tag会怎么样？/","link":"","permalink":"https://xiaobaidebug.top/2020/05/18/golang%E9%9D%A2%E8%AF%95%E9%A2%98/golang%E9%9D%A2%E8%AF%95%E9%A2%98%EF%BC%9Ajson%E5%8C%85%E5%8F%98%E9%87%8F%E4%B8%8D%E5%8A%A0tag%E4%BC%9A%E6%80%8E%E4%B9%88%E6%A0%B7%EF%BC%9F/","excerpt":"","text":"问题json包里使用的时候，结构体里的变量不加tag能不能正常转成json里的字段？ 怎么答 如果变量首字母小写，则为private。无论如何不能转，因为取不到反射信息。 如果变量首字母大写，则为public。 不加tag，可以正常转为json里的字段，json内字段名跟结构体内字段原名一致。 加了tag，从struct转json的时候，json的字段名就是tag里的字段名，原字段名已经没用。 举例通过一个例子加深理解。 12345678910111213141516171819202122package mainimport ( &quot;encoding/json&quot; &quot;fmt&quot;)type J struct &#123; a string //小写无tag b string `json:&quot;B&quot;` //小写+tag C string //大写无tag D string `json:&quot;DD&quot;` //大写+tag&#125;func main() &#123; j := J &#123; a: &quot;1&quot;, b: &quot;2&quot;, C: &quot;3&quot;, D: &quot;4&quot;, &#125; fmt.Printf(&quot;转为json前j结构体的内容 = %+v\\n&quot;, j) jsonInfo, _ := json.Marshal(j) fmt.Printf(&quot;转为json后的内容 = %+v\\n&quot;, string(jsonInfo))&#125; 输出 12转为json前j结构体的内容 = &#123;a:1 b:2 C:3 D:4&#125;转为json后的内容 = &#123;&quot;C&quot;:&quot;3&quot;,&quot;DD&quot;:&quot;4&quot;&#125; 解释 结构体里定义了四个字段，分别对应 小写无tag，小写+tag，大写无tag，大写+tag。 转为json后首字母小写的不管加不加tag都不能转为json里的内容，而大写的加了tag可以取别名，不加tag则json内的字段跟结构体字段原名一致。 文章推荐： golang面试题：怎么避免内存逃逸？？ golang面试题：简单聊聊内存逃逸？ golang面试题：字符串转成byte数组，会发生内存拷贝吗？ golang面试题：翻转含有中文、数字、英文字母的字符串 golang面试题：拷贝大切片一定比小切片代价大吗？ golang面试题：能说说uintptr和unsafe.Pointer的区别吗？ 关注公众号:【小白debug】","categories":[{"name":"golang面试题","slug":"golang面试题","permalink":"https://xiaobaidebug.top/categories/golang%E9%9D%A2%E8%AF%95%E9%A2%98/"}],"tags":[]},{"title":"golang面试题：字符串转成byte数组，会发生内存拷贝吗？","slug":"golang面试题/golang面试题：字符串转成byte数组，会发生内存拷贝吗？","date":"2020-05-17T14:57:55.000Z","updated":"2022-10-30T02:25:54.158Z","comments":true,"path":"2020/05/17/golang面试题/golang面试题：字符串转成byte数组，会发生内存拷贝吗？/","link":"","permalink":"https://xiaobaidebug.top/2020/05/17/golang%E9%9D%A2%E8%AF%95%E9%A2%98/golang%E9%9D%A2%E8%AF%95%E9%A2%98%EF%BC%9A%E5%AD%97%E7%AC%A6%E4%B8%B2%E8%BD%AC%E6%88%90byte%E6%95%B0%E7%BB%84%EF%BC%8C%E4%BC%9A%E5%8F%91%E7%94%9F%E5%86%85%E5%AD%98%E6%8B%B7%E8%B4%9D%E5%90%97%EF%BC%9F/","excerpt":"","text":"问题字符串转成byte数组，会发生内存拷贝吗？ 怎么答字符串转成切片，会产生拷贝。严格来说，只要是发生类型强转都会发生内存拷贝。那么问题来了。频繁的内存拷贝操作听起来对性能不大友好。有没有什么办法可以在字符串转成切片的时候不用发生拷贝呢？ 代码实现123456789101112131415package mainimport ( &quot;fmt&quot; &quot;reflect&quot; &quot;unsafe&quot;)func main() &#123; a :=&quot;aaa&quot; ssh := *(*reflect.StringHeader)(unsafe.Pointer(&amp;a)) b := *(*[]byte)(unsafe.Pointer(&amp;ssh)) fmt.Printf(&quot;%v&quot;,b)&#125; 解释 StringHeader 是字符串在go的底层结构。 1234type StringHeader struct &#123; Data uintptr Len int&#125; SliceHeader 是切片在go的底层结构。 12345type SliceHeader struct &#123; Data uintptr Len int Cap int&#125; 那么如果想要在底层转换二者，只需要把 StringHeader 的地址强转成 SliceHeader 就行。那么go有个很强的包叫 unsafe 。 1.unsafe.Pointer(&amp;a)方法可以得到变量a的地址。 2.(*reflect.StringHeader)(unsafe.Pointer(&amp;a)) 可以把字符串a转成底层结构的形式。 3.(*[]byte)(unsafe.Pointer(&amp;ssh)) 可以把ssh底层结构体转成byte的切片的指针。 4.再通过 *转为指针指向的实际内容。 关注公众号:【小白debug】","categories":[{"name":"golang面试题","slug":"golang面试题","permalink":"https://xiaobaidebug.top/categories/golang%E9%9D%A2%E8%AF%95%E9%A2%98/"}],"tags":[]},{"title":"golang面试题：怎么避免内存逃逸？","slug":"golang面试题/golang面试题：怎么避免内存逃逸？","date":"2020-05-16T14:57:55.000Z","updated":"2022-10-30T02:25:54.093Z","comments":true,"path":"2020/05/16/golang面试题/golang面试题：怎么避免内存逃逸？/","link":"","permalink":"https://xiaobaidebug.top/2020/05/16/golang%E9%9D%A2%E8%AF%95%E9%A2%98/golang%E9%9D%A2%E8%AF%95%E9%A2%98%EF%BC%9A%E6%80%8E%E4%B9%88%E9%81%BF%E5%85%8D%E5%86%85%E5%AD%98%E9%80%83%E9%80%B8%EF%BC%9F/","excerpt":"","text":"问题怎么避免内存逃逸？ 怎么答在runtime/stubs.go:133有个函数叫noescape。noescape可以在逃逸分析中隐藏一个指针。让这个指针在逃逸分析中不会被检测为逃逸。 12345678910 // noescape hides a pointer from escape analysis. noescape is // the identity function but escape analysis doesn&#x27;t think the // output depends on the input. noescape is inlined and currently // compiles down to zero instructions. // USE CAREFULLY! //go:nosplit func noescape(p unsafe.Pointer) unsafe.Pointer &#123; x := uintptr(p) return unsafe.Pointer(x ^ 0)&#125; 举例 通过一个例子加深理解，接下来尝试下怎么通过 go build -gcflags=-m 查看逃逸的情况。1234567891011121314151617181920212223242526272829303132333435package mainimport ( &quot;unsafe&quot;)type A struct &#123; S *string&#125;func (f *A) String() string &#123; return *f.S&#125;type ATrick struct &#123; S unsafe.Pointer&#125;func (f *ATrick) String() string &#123; return *(*string)(f.S)&#125;func NewA(s string) A &#123; return A&#123;S: &amp;s&#125;&#125;func NewATrick(s string) ATrick &#123; return ATrick&#123;S: noescape(unsafe.Pointer(&amp;s))&#125;&#125;func noescape(p unsafe.Pointer) unsafe.Pointer &#123; x := uintptr(p) return unsafe.Pointer(x ^ 0)&#125;func main() &#123; s := &quot;hello&quot; f1 := NewA(s) f2 := NewATrick(s) s1 := f1.String() s2 := f2.String() _ = s1 + s2&#125; 执行go build -gcflags=-m main.go 123456789101112131415161718192021222324252627$go build -gcflags=-m main.go# command-line-arguments./main.go:11:6: can inline (*A).String./main.go:19:6: can inline (*ATrick).String./main.go:23:6: can inline NewA./main.go:31:6: can inline noescape./main.go:27:6: can inline NewATrick./main.go:28:29: inlining call to noescape./main.go:36:6: can inline main./main.go:38:14: inlining call to NewA./main.go:39:19: inlining call to NewATrick./main.go:39:19: inlining call to noescape./main.go:40:17: inlining call to (*A).String./main.go:41:17: inlining call to (*ATrick).String/var/folders/45/qx9lfw2s2zzgvhzg3mtzkwzc0000gn/T/go-build763863171/b001/_gomod_.go:6:6: can inline init.0./main.go:11:7: leaking param: f to result ~r0 level=2./main.go:19:7: leaking param: f to result ~r0 level=2./main.go:24:16: &amp;s escapes to heap./main.go:23:13: moved to heap: s./main.go:27:18: NewATrick s does not escape./main.go:28:45: NewATrick &amp;s does not escape./main.go:31:15: noescape p does not escape./main.go:38:14: main &amp;s does not escape./main.go:39:19: main &amp;s does not escape./main.go:40:10: main f1 does not escape./main.go:41:10: main f2 does not escape./main.go:42:9: main s1 + s2 does not escape 其中主要看中间一小段 1234./main.go:24:16: &amp;s escapes to heap //这个是NewA中的，逃逸了./main.go:23:13: moved to heap: s./main.go:27:18: NewATrick s does not escape // NewATrick里的s的却没逃逸./main.go:28:45: NewATrick &amp;s does not escape 解释 上段代码对A和ATrick同样的功能有两种实现：他们包含一个 string ，然后用 String() 方法返回这个字符串。但是从逃逸分析看ATrick 版本没有逃逸。 noescape() 函数的作用是遮蔽输入和输出的依赖关系。使编译器不认为 p 会通过 x 逃逸， 因为 uintptr() 产生的引用是编译器无法理解的。 内置的 uintptr 类型是一个真正的指针类型，但是在编译器层面，它只是一个存储一个 指针地址 的 int 类型。代码的最后一行返回 unsafe.Pointer 也是一个 int。 noescape() 在 runtime 包中使用 unsafe.Pointer 的地方被大量使用。如果作者清楚被 unsafe.Pointer 引用的数据肯定不会被逃逸，但编译器却不知道的情况下，这是很有用的。 面试中秀一秀是可以的，如果在实际项目中如果使用这种unsafe包大概率会被同事打死。不建议使用！ 毕竟包的名字就叫做 unsafe, 而且源码中的注释也写明了 USE CAREFULLY! 。 文章推荐： golang面试题：简单聊聊内存逃逸？ golang面试题：字符串转成byte数组，会发生内存拷贝吗？ golang面试题：翻转含有中文、数字、英文字母的字符串 golang面试题：拷贝大切片一定比小切片代价大吗？ golang面试题：能说说uintptr和unsafe.Pointer的区别吗？ 关注公众号:【小白debug】","categories":[{"name":"golang面试题","slug":"golang面试题","permalink":"https://xiaobaidebug.top/categories/golang%E9%9D%A2%E8%AF%95%E9%A2%98/"}],"tags":[]},{"title":"拷贝大切片一定比小切片代价大吗？","slug":"golang面试题/golang面试题：拷贝大切片一定比小切片代价大吗？","date":"2020-05-13T14:57:55.000Z","updated":"2022-10-30T02:25:54.158Z","comments":true,"path":"2020/05/13/golang面试题/golang面试题：拷贝大切片一定比小切片代价大吗？/","link":"","permalink":"https://xiaobaidebug.top/2020/05/13/golang%E9%9D%A2%E8%AF%95%E9%A2%98/golang%E9%9D%A2%E8%AF%95%E9%A2%98%EF%BC%9A%E6%8B%B7%E8%B4%9D%E5%A4%A7%E5%88%87%E7%89%87%E4%B8%80%E5%AE%9A%E6%AF%94%E5%B0%8F%E5%88%87%E7%89%87%E4%BB%A3%E4%BB%B7%E5%A4%A7%E5%90%97%EF%BC%9F/","excerpt":"","text":"问题拷贝大切片一定比小切片代价大吗？ 怎么答并不是，所有切片的大小相同；三个字段（一个 uintptr，两个int）。切片中的第一个字是指向切片底层数组的指针，这是切片的存储空间，第二个字段是切片的长度，第三个字段是容量。将一个 slice 变量分配给另一个变量只会复制三个机器字。所以 拷贝大切片跟小切片的代价应该是一样的。 解释 SliceHeader 是切片在go的底层结构。 12345type SliceHeader struct &#123; Data uintptr Len int Cap int&#125; 大切片跟小切片的区别无非就是 Len 和 Cap的值比小切片的这两个值大一些，如果发生拷贝，本质上就是拷贝上面的三个字段。 关注公众号:【小白debug】","categories":[{"name":"golang面试题","slug":"golang面试题","permalink":"https://xiaobaidebug.top/categories/golang%E9%9D%A2%E8%AF%95%E9%A2%98/"}],"tags":[]},{"title":"golang面试题：简单聊聊内存逃逸？","slug":"golang面试题/golang面试题：简单聊聊内存逃逸？","date":"2020-05-12T14:57:55.000Z","updated":"2022-04-19T12:18:17.479Z","comments":true,"path":"2020/05/12/golang面试题/golang面试题：简单聊聊内存逃逸？/","link":"","permalink":"https://xiaobaidebug.top/2020/05/12/golang%E9%9D%A2%E8%AF%95%E9%A2%98/golang%E9%9D%A2%E8%AF%95%E9%A2%98%EF%BC%9A%E7%AE%80%E5%8D%95%E8%81%8A%E8%81%8A%E5%86%85%E5%AD%98%E9%80%83%E9%80%B8%EF%BC%9F/","excerpt":"","text":"问题知道golang的内存逃逸吗？什么情况下会发生内存逃逸？ 怎么答```逃逸``` 了，必须在```堆上分配```。123456789101112131415161718192021222324252627282930 能引起变量逃逸到堆上的**典型情况**：- **在方法内把局部变量指针返回** 局部变量原本应该在栈中分配，在栈中回收。但是由于返回时被外部引用，因此其生命周期大于栈，则溢出。- **发送指针或带有指针的值到 channel 中。** 在编译时，是没有办法知道哪个 goroutine 会在 channel 上接收数据。所以编译器没法知道变量什么时候才会被释放。- **在一个切片上存储指针或带指针的值。** 一个典型的例子就是 []*string 。这会导致切片的内容逃逸。尽管其后面的数组可能是在栈上分配的，但其引用的值一定是在堆上。- **slice 的背后数组被重新分配了，因为 append 时可能会超出其容量( cap )。** slice 初始化的地方在编译时是可以知道的，它最开始会在栈上分配。如果切片背后的存储要基于运行时的数据进行扩充，就会在堆上分配。- **在 interface 类型上调用方法。** 在 interface 类型上调用方法都是动态调度的 —— 方法的真正实现只能在运行时知道。想像一个 io.Reader 类型的变量 r , 调用 r.Read(b) 会使得 r 的值和切片b 的背后存储都逃逸掉，所以会在堆上分配。## 举例- 通过一个例子加深理解，接下来尝试下怎么通过 ```go build -gcflags=-m``` 查看逃逸的情况。```gopackage mainimport &quot;fmt&quot;type A struct &#123; s string&#125;// 这是上面提到的 &quot;在方法内把局部变量指针返回&quot; 的情况func foo(s string) *A &#123; a := new(A) a.s = s return a //返回局部变量a,在C语言中妥妥野指针，但在go则ok，但a会逃逸到堆&#125;func main() &#123; a := foo(&quot;hello&quot;) b := a.s + &quot; world&quot; c := b + &quot;!&quot; fmt.Println(c)&#125; 执行go build -gcflags=-m main.go 123456789101112131415go build -gcflags=-m main.go# command-line-arguments./main.go:7:6: can inline foo./main.go:13:10: inlining call to foo./main.go:16:13: inlining call to fmt.Println/var/folders/45/qx9lfw2s2zzgvhzg3mtzkwzc0000gn/T/go-build409982591/b001/_gomod_.go:6:6: can inline init.0./main.go:7:10: leaking param: s./main.go:8:10: new(A) escapes to heap./main.go:16:13: io.Writer(os.Stdout) escapes to heap./main.go:16:13: c escapes to heap./main.go:15:9: b + &quot;!&quot; escapes to heap./main.go:13:10: main new(A) does not escape./main.go:14:11: main a.s + &quot; world&quot; does not escape./main.go:16:13: main []interface &#123;&#125; literal does not escape&lt;autogenerated&gt;:1: os.(*File).close .this does not escape ./main.go:8:10: new(A) escapes to heap 说明 new(A) 逃逸了,符合上述提到的常见情况中的第一种。 ./main.go:14:11: main a.s + &quot; world&quot; does not escape 说明 b 变量没有逃逸，因为它只在方法内存在，会在方法结束时被回收。 ./main.go:15:9: b + &quot;!&quot; escapes to heap 说明 c 变量逃逸，通过fmt.Println(a ...interface&#123;&#125;)打印的变量，都会发生逃逸，感兴趣的朋友可以去查查为什么。 以上操作其实就叫逃逸分析。下篇文章，跟大家聊聊怎么用一个比较trick的方法使变量不逃逸。方便大家在面试官面前秀一波。","categories":[{"name":"golang面试题","slug":"golang面试题","permalink":"https://xiaobaidebug.top/categories/golang%E9%9D%A2%E8%AF%95%E9%A2%98/"}],"tags":[]},{"title":"golang面试题：翻转含有中文、数字、英文字母的字符串","slug":"golang面试题/golang面试题：翻转含有中文、数字、英文字母的字符串","date":"2020-05-10T14:57:55.000Z","updated":"2022-10-30T02:25:54.159Z","comments":true,"path":"2020/05/10/golang面试题/golang面试题：翻转含有中文、数字、英文字母的字符串/","link":"","permalink":"https://xiaobaidebug.top/2020/05/10/golang%E9%9D%A2%E8%AF%95%E9%A2%98/golang%E9%9D%A2%E8%AF%95%E9%A2%98%EF%BC%9A%E7%BF%BB%E8%BD%AC%E5%90%AB%E6%9C%89%E4%B8%AD%E6%96%87%E3%80%81%E6%95%B0%E5%AD%97%E3%80%81%E8%8B%B1%E6%96%87%E5%AD%97%E6%AF%8D%E7%9A%84%E5%AD%97%E7%AC%A6%E4%B8%B2/","excerpt":"","text":"问题翻转含有中文、数字、英文字母的字符串&quot;你好abc啊哈哈&quot; 代码实现1234567891011121314151617package mainimport&quot;fmt&quot;func main() &#123; src := &quot;你好abc啊哈哈&quot; dst := reverse([]rune(src)) fmt.Printf(&quot;%v\\n&quot;, string(dst))&#125;func reverse(s []rune) []rune &#123; for i, j := 0, len(s)-1; i &lt; j; i, j = i+1, j-1 &#123; s[i], s[j] = s[j], s[i] &#125; return s&#125; 解释 rune关键字，从golang源码中看出，它是int32的别名（-2^31 ~ 2^31-1），比起byte（-128～127），可表示更多的字符。 由于rune可表示的范围更大，所以能处理一切字符，当然也包括中文字符。在平时计算中文字符，可用rune。 因此将字符串转为rune的切片，再进行翻转，完美解决。 关注公众号:【小白debug】","categories":[{"name":"golang面试题","slug":"golang面试题","permalink":"https://xiaobaidebug.top/categories/golang%E9%9D%A2%E8%AF%95%E9%A2%98/"}],"tags":[]}],"categories":[{"name":"骚话连篇","slug":"骚话连篇","permalink":"https://xiaobaidebug.top/categories/%E9%AA%9A%E8%AF%9D%E8%BF%9E%E7%AF%87/"},{"name":"图解网络","slug":"图解网络","permalink":"https://xiaobaidebug.top/categories/%E5%9B%BE%E8%A7%A3%E7%BD%91%E7%BB%9C/"},{"name":"图解mysql","slug":"图解mysql","permalink":"https://xiaobaidebug.top/categories/%E5%9B%BE%E8%A7%A3mysql/"},{"name":"golang面试题","slug":"golang面试题","permalink":"https://xiaobaidebug.top/categories/golang%E9%9D%A2%E8%AF%95%E9%A2%98/"},{"name":"图解操作系统","slug":"图解操作系统","permalink":"https://xiaobaidebug.top/categories/%E5%9B%BE%E8%A7%A3%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/"}],"tags":[]}